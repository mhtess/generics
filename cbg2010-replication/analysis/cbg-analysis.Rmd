---
title: "cgb2010-replication"
author: "mht"
date: "December 2, 2014"
output: html_document
---


Merge data sets for 2 experiments into a single .csv

```{r datamerge, echo=FALSE}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
d1<-read.table('cbgR-exp1_anonymized-trials.tsv',header=T)
#d2<-read.table('cbgR-exp2_anonymized-trials.tsv',header=T)
d3<-read.table('cbgR-exp3_anonymized-trials.tsv',header=T)

#d2$workerid<-d2$workerid+length(levels(factor(d1$workerid)))
#d3$workerid<-d3$workerid+length(levels(factor(d2$workerid)))+length(levels(factor(d1$workerid)))
d3$workerid<-d3$workerid+length(levels(factor(d1$workerid)))

all.experiments<-rbind(d1,d3)

#write.csv(all.experiments, file='cbgR-exp1_exp3_anonymized-trials.csv')
#write.csv(td1, file='cbgR-exp3_anonymized-trials.csv')

```

# Experiment 1: CBG (2010) Experiments 1 and 2

### Experimental conditions


+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False
+ **implied prevalence** = given a sentence (*generic*, *most*, *some*), answer with the percentage of *warfles that have purple feathers*


```{r exp1}
# library(ggplot2)
library(plyr)
# library(reshape2)
library(ggthemes)
# library(gridExtra)
# library(bootstrap)
# library(lme4)
# theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
# ci.low <- function(x,na.rm=T) {
#   mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
# ci.high <- function(x,na.rm=T) {
#   quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}

bool.tonum<-function(bool){abs(as.numeric(bool)*1-2)}
bootstrap.ci <- function(x){
  agr = aggregate(subj_prevalence ~ trial_type + stim_determiner, data=x, FUN=mean)
  agr$CILow = aggregate(subj_prevalence ~ trial_type + stim_determiner, data=x, FUN=ci.low)$subj_prevalence
  agr$CIHigh = aggregate(subj_prevalence ~ trial_type + stim_determiner, data=x, FUN=ci.high)$subj_prevalence
  agr$YMin = agr$subj_prevalence - agr$CILow
  agr$YMax = agr$subj_prevalence + agr$CIHigh
  return(agr)
}

bootstrap.ci.tc <- function(x){
  
  agr = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.low)$truth_num
  agr$CIHigh = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.high)$truth_num
  agr$YMin = agr$truth_num - agr$CILow
  agr$YMax = agr$truth_num + agr$CIHigh
  return(agr)
}



setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
turk.data<-read.table('cbgR-exp1_anonymized-trials.tsv',header=T)

turk.data$implied_prevalence <- as.numeric(levels(turk.data$response)[turk.data$response])
turk.data$truth_conditions <- factor(as.logical(levels(turk.data$response)[turk.data$response]), levels=c("TRUE","FALSE"))
turk.data$stim_prevalence <- factor(turk.data$stim_prevalence)
```

Some frequentists inferential statistics
```{r}

truth.conds<- subset(turk.data, trial_type=='truth_conditions')
truth.conds$truth_num <-bool.tonum(truth.conds$truth_conditions)
results<-glmer(truth_num ~ stim_prevalence*stim_determiner + (1 | workerid), data=truth.conds, family='binomial')
summary(results)

summary(aov(truth_num~(stim_prevalence*stim_determiner)+Error(workerid/(stim_prevalence*stim_determiner)),
    data=truth.conds))
```


Number of responses for each prevalence level (for truth conditions task)
```{r resp1Atab, echo=FALSE}
table(turk.data[,c("stim_determiner","stim_prevalence")])
```

Number of responses for implied prevalence task.
```{r resp2Btab, echo=FALSE}
table(subset(turk.data,trial_type=='implied_prevalence')[,c("stim_determiner")])
```


```{r anova1}
df<-ddply(subset(turk.data,trial_type=='truth_conditions' & truth_conditions==TRUE), 
      .(stim_prevalence, stim_determiner), summarise,
      count = sum(as.numeric(truth_conditions))

df<-rbind(df,c(10,'most',0))
df$count<-to.n(df$count)
```

Plot *implied prevalence* (top) and proportion of "true" responses at each stated prevalence level (bottom, replicated figure 3 from CGB 2010)

```{r}
df<-ddply(subset(turk.data,trial_type=='truth_conditions'), 
      .(stim_determiner, stim_prevalence), summarise, 
      true_responses= table(truth_conditions)[["TRUE"]]/length(truth_conditions))

a<-ggplot(subset(turk.data,trial_type=='implied_prevalence'),aes(x=implied_prevalence,fill=stim_determiner))+
  geom_density(alpha=.5)+
  facet_wrap(~stim_determiner)+
  theme_bw()+
  guides(fill=F)

b<-ggplot(df, aes(x=stim_prevalence,y=true_responses,colour=stim_determiner, group=stim_determiner))+
  geom_line(size=1)+
  facet_wrap(~stim_determiner)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  guides(colour=F)

grid.arrange(a,b)
```

Replicate figure 2 of CGB 2010 *asymmetry of truth_conditions and implied_prevalence*
```{r}


turk.data$stim_prevalence <- as.numeric(levels(turk.data$stim_prevalence)[turk.data$stim_prevalence])

df2<-ddply(subset(turk.data, truth_conditions%in%c("TRUE",NA)), 
       .(trial_type, stim_determiner, workerid), summarise, 
       subj_prevalence = mean(implied_prevalence),
       subj_truth_prevalence = mean(stim_prevalence))

df2$subj_prevalence[is.na(df2$subj_prevalence)] <- df2$subj_truth_prevalence[!is.na(df2$subj_truth_prevalence)]
df2.bs<-bootstrap.ci(df2)
df2.bs$trial_type <- factor(df2.bs$trial_type, levels=c("truth_conditions","implied_prevalence"))

ggplot(df2.bs, aes(x=stim_determiner,y=subj_prevalence,fill=trial_type, group=trial_type))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5)+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5),
                colour='black')+
  theme_bw()+
  ylab("average prevalence")+
  scale_fill_brewer(type='qual',palette=1)

```

Replicate figure 3 with CIs

```{r}

tc<-subset(turk.data,trial_type=='truth_conditions')
tc$truth_num <- 1*as.logical(tc$truth_conditions)

tc.bs<-bootstrap.ci.tc(tc[tc$trialNum<15,])
tc.bs<-bootstrap.ci.tc(tc[tc$trialNum>=15,])


tc.bs<-bootstrap.ci.tc(tc)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_determiner, group=stim_determiner))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_line()+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_determiner),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =element_text(size=14,color='black'))+
  guides(colour=F)

```


# Experiment 2 -- prior elicitation 2 ways

### Experimental conditions

**implied prevalence** only, with no quantifier sentence

+ **catprop** - subjects were given evidence that the category and the property were relevant ("recently discovered"); also the cover story was elaborated (you are a zoologist)
+ **plain** is the CBG paradigm without the quantifier/generic sentence for evidence (bare bones)


```{r exp2}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
turk.data<-read.table('cbgR-exp2_anonymized-trials.tsv',header=T)
summary(turk.data)
```


Reaction time histograms

```{r}
ggplot(turk.data,aes(x=rt/60000,fill=trial_prompt))+
  geom_histogram()+
  facet_wrap(~trial_prompt)+
  guides(fill=F)+
  xlab('rt in minutes')+
  theme_bw()
```


Prevalence histograms / densities, broken up by cover story (catprop vs plain)

```{r}
ggplot(turk.data,aes(x=response,fill=trial_prompt))+
  geom_histogram(binwidth=5, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_density()+
  facet_wrap(~trial_prompt)+
  guides(fill=F)+
  theme_bw()
```

Prevalence histograms / densities, collapsed across cover stories

```{r}
ggplot(turk.data,aes(x=response))+
  geom_histogram(binwidth=5, fill='blue', aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_density()+
  guides(fill=F)+
  theme_bw()
```

Histograms by subject, for each condition separately

```{r}
ggplot(subset(turk.data, trial_prompt=='catprop'),
       aes(x=response))+
  geom_histogram(binwidth=10,fill='blue')+
  facet_wrap(~workerid)+
  guides(fill=F)+
  scale_x_continuous(limits=c(0,110),breaks=c(0,25,50,75,100))+
  theme_bw()

ggplot(subset(turk.data, trial_prompt=='plain'),
       aes(x=response))+
  geom_histogram(binwidth=10,fill='red')+
  facet_wrap(~workerid)+
  guides(fill=F)+
  scale_x_continuous(limits=c(0,110),breaks=c(0,25,50,75,100))+
  theme_bw()
```

Average prior prevalence

```{r}

bootstrap.ci <- function(x){
  agr = aggregate(value ~ trial_prompt, data=x, FUN=mean)
  agr$CILow = aggregate(value ~ trial_prompt, data=x, FUN=ci.low)$value
  agr$CIHigh = aggregate(value ~ trial_prompt, data=x, FUN=ci.high)$value
  agr$YMin = agr$value - agr$CILow
  agr$YMax = agr$value + agr$CIHigh
  return(agr)
}
df.m<- melt(turk.data[,c("trial_prompt","response")],id.vars='trial_prompt')
df.b<-bootstrap.ci(df.m)

ggplot(df.b,aes(x=trial_prompt,y=value,fill=trial_prompt))+
  geom_bar(stat='identity',position=position_dodge(),width=0.4)+
    geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.1,
                size=1,
                position=position_dodge(0.5),
                colour='white')+
  guides(fill=F)+
  ylim(0,100)+
  theme_bw()
```


# Experiment 3 -- replicate experiment 4 of CBG

The idea now is to see if the generic theta differs across contexts, thus motivating a lifted variable model from a bayesian data analysis standpoint.

+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False
+ **implied prevalence** = given a sentence (*generic*, *most*, *some*), answer with the percentage of *warfles that have purple feathers*

The sentence is between subjects (subjects see only generics or mosts or somes).

Within-subject is the context:

+ **dangerous**
+ **distinctive**
+ **extra irrelevant**
+ **bare** (from experiment 1, above)

```{r exp3}

library(ggthemes)


setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
td0<-read.table('cbgR-exp1_anonymized-trials.tsv',header=T)

#td0$trialNum<-(1+as.numeric(rownames(td0))) %% 30
#write.csv(td0, file='cbgR-exp1_anonymized-trials.csv')
td1<-read.table('cbgR-exp3_anonymized-trials.tsv',header=T)
#td1$trialNum<-(1+as.numeric(rownames(td1))) %% 30
#write.csv(td1, file='cbgR-exp3_anonymized-trials.csv')
td1$item<-paste(td1$stim_color,td1$stim_part,sep='_')
#levels(factor(subset(td1,stim_type=='danger')$item))

td1$workerid<-td1$workerid+length(levels(factor(td0$workerid)))
td<-rbind(td0,td1)
td$workerid <- factor(td$workerid)
td$rt <- td$rt/1000
td$stim_prevalence <- factor(td$stim_prevalence)


td$implied_prevalence <- to.n(td$response)
td$truth_conditions <- factor(as.logical(levels(td$response)[td$response]), 
                              levels=c("TRUE","FALSE"))

```
Number of responses for each prevalence level (for truth conditions task)
```{r, echo=FALSE}
table(td1[,c("stim_determiner","stim_prevalence")])/6
```

Number of responses for implied prevalence task.
```{r, echo=FALSE}
table(subset(td1,trial_type=='implied_prevalence')[,c("stim_determiner")])/30
```



```{r}
df<-ddply(subset(td,trial_type=='truth_conditions'), 
      .(stim_determiner, stim_prevalence, stim_type), summarise, 
      true_responses= table(truth_conditions)[["TRUE"]]/length(truth_conditions))


a<-ggplot(subset(td,trial_type=='implied_prevalence'),
          aes(x=implied_prevalence,fill=stim_type))+
  geom_histogram(aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]),binwidth=10)+
  facet_grid(stim_type~stim_determiner)+
  theme_bw()+
  guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'),
        strip.text.y =       element_text(size=14,color='black'))

b<-ggplot(df, aes(x=stim_prevalence,y=true_responses,colour=stim_type, 
                  group=stim_determiner))+
  geom_line(size=1,alpha=0.90)+
  facet_grid(stim_type~stim_determiner)+
  theme_bw()+
  ylab("proportion of 'true' responses")

grid.arrange(a,b)
```

Replicate figure 3 from CGB 2010 (w CIs)

```{r exp3fig3}

bootstrap.ci.tc <- function(x){
  
  agr = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.low)$truth_num
  agr$CIHigh = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.high)$truth_num
  agr$YMin = agr$truth_num - agr$CILow
  agr$YMax = agr$truth_num + agr$CIHigh
  return(agr)
}

tc<-subset(td,trial_type=='truth_conditions')
tc$truth_num <- 1*as.logical(tc$truth_conditions)

tc.bs<-bootstrap.ci.tc(tc[tc$trialNum<15,])
tc.bs<-bootstrap.ci.tc(tc[tc$trialNum>=15,])



tc.bs<-bootstrap.ci.tc(tc)

tc.bs$stim_type<-factor(tc.bs$stim_type,labels=c("exp1-bare","exp3-danger","exp3-distinct", "exp3-irrelevant"))

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =element_text(size=14,color='black'))

```


Replicate figure 2 of CGB 2010
```{r}

bootstrap.ci <- function(x){
  
  agr = aggregate(subj_prevalence ~ trial_type + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(subj_prevalence ~ trial_type + stim_determiner + stim_type, data=x, FUN=ci.low)$subj_prevalence
  agr$CIHigh = aggregate(subj_prevalence ~ trial_type + stim_determiner + stim_type, data=x, FUN=ci.high)$subj_prevalence
  agr$YMin = agr$subj_prevalence - agr$CILow
  agr$YMax = agr$subj_prevalence + agr$CIHigh
  return(agr)
}

td$stim_prevalence <- to.n(td$stim_prevalence)

df2<-ddply(subset(td, truth_conditions%in%c("TRUE",NA)), 
       .(trial_type, stim_determiner, stim_type, workerid), summarise, 
       subj_prevalence = mean(implied_prevalence),
       subj_truth_prevalence = mean(stim_prevalence))

df2$subj_prevalence[is.na(df2$subj_prevalence)] <- df2$subj_truth_prevalence[!is.na(df2$subj_truth_prevalence)]

df2.bs<-bootstrap.ci(df2)
df2.bs$trial_type <- factor(df2.bs$trial_type, levels=c("truth_conditions","implied_prevalence"))

ggplot(df2.bs, aes(x=stim_determiner,y=subj_prevalence,fill=trial_type, group=trial_type))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5)+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5),
                colour='black')+
  theme_bw()+
  facet_wrap(~stim_type,nrow=1)+
  ylab("average prevalence")+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))

ggplot(df2.bs, aes(x=trial_type,y=subj_prevalence,fill=stim_type, group=stim_type))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5)+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5),
                colour='black')+
  theme_bw()+
  facet_wrap(~stim_determiner)+
  ylab("average prevalence")+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))
```

# Bayesian data analysis

## Infer thresholds for quantifiers from implied prevalence task

```{r tfbt.ip.1}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis')
d0<-read.csv('post_bare_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d0$quantifier<-'most'
d0$context<-'bare'
d1<-read.csv('post_danger_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d1$quantifier<-'most'
d1$context<-'danger'
d2<-read.csv('post_distinct_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d2$quantifier<-'most'
d2$context<-'distinct'
d3<-read.csv('post_irrelevant_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d3$quantifier<-'most'
d3$context<-'irrelevant'

e0<-read.csv('post_bare_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e0$quantifier<-'some'
e0$context<-'bare'
e1<-read.csv('post_danger_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e1$quantifier<-'some'
e1$context<-'danger'
e2<-read.csv('post_distinct_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e2$quantifier<-'some'
e2$context<-'distinct'
e3<-read.csv('post_irrelevant_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e3$quantifier<-'some'
e3$context<-'irrelevant'

f0<-read.csv('post_bare_generic_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f0$quantifier<-'generic'
f0$context<-'bare'
f1<-read.csv('post_danger_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f1$quantifier<-'generic'
f1$context<-'danger'
f2<-read.csv('post_distinct_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f2$quantifier<-'generic'
f2$context<-'distinct'
f3<-read.csv('post_irrelevant_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f3$quantifier<-'generic'
f3$context<-'irrelevant'

all.data<-rbind(f0,f1,f2,f3,e0,e1,e2,e3,d0,d1,d2,d3)

all.data$quantifier<- factor(all.data$quantifier)
all.data$context<-factor(all.data$context)

ggplot(data=all.data,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(context~quantifier)+
  theme_bw()

```


## Infer thresholds for quantifiers from truth conditions task

```{r tfbt.tc.1}
tfbt.dir <- '/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis/'

d0<-read.csv(paste(tfbt.dir,'post_bare_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d0$quantifier<-'most'
d0$context<-'bare'
d1<-read.csv(paste(tfbt.dir,'post_danger_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d1$quantifier<-'most'
d1$context<-'danger'
d2<-read.csv(paste(tfbt.dir,'post_distinct_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d2$quantifier<-'most'
d2$context<-'distinct'
d3<-read.csv(paste(tfbt.dir,'post_irrelevant_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d3$quantifier<-'most'
d3$context<-'irrelevant'

e0<-read.csv(paste(tfbt.dir,'post_bare_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e0$quantifier<-'some'
e0$context<-'bare'
e1<-read.csv(paste(tfbt.dir,'post_danger_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e1$quantifier<-'some'
e1$context<-'danger'
e2<-read.csv(paste(tfbt.dir,'post_distinct_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e2$quantifier<-'some'
e2$context<-'distinct'
e3<-read.csv(paste(tfbt.dir,'post_irrelevant_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e3$quantifier<-'some'
e3$context<-'irrelevant'

f0<-read.csv(paste(tfbt.dir,'post_bare_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f0$quantifier<-'generic'
f0$context<-'bare'
f1<-read.csv(paste(tfbt.dir,'post_danger_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f1$quantifier<-'generic'
f1$context<-'danger'
f2<-read.csv(paste(tfbt.dir,'post_distinct_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f2$quantifier<-'generic'
f2$context<-'distinct'
f3<-read.csv(paste(tfbt.dir,'../post_irrelevant_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f3$quantifier<-'generic'
f3$context<-'irrelevant'

all.data<-rbind(f0,f1,f2,f3,e0,e1,e2,e3,d0,d1,d2,d3)

all.data$quantifier<- factor(all.data$quantifier)
all.data$context<-factor(all.data$context)

ggplot(data=all.data,aes(x=value,fill=context))+
  geom_density()+
  facet_grid(context~quantifier)+
  theme_bw()+
  scale_x_continuous(breaks=c(10,30,50,70,90))

ddply(all.data, .(context, quantifier), summarise, mean(value))

```


Chain 2 (replication)

```{r tfbt.tc.2}
tfbt.dir <- '/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis/'

d0<-read.csv(paste(tfbt.dir,'postChain2_bare_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d0$quantifier<-'most'
d0$context<-'bare'
d1<-read.csv(paste(tfbt.dir,'postChain2_danger_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d1$quantifier<-'most'
d1$context<-'danger'
d2<-read.csv(paste(tfbt.dir,'postChain2_distinct_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d2$quantifier<-'most'
d2$context<-'distinct'
d3<-read.csv(paste(tfbt.dir,'postChain2_irrelevant_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d3$quantifier<-'most'
d3$context<-'irrelevant'

e0<-read.csv(paste(tfbt.dir,'postChain2_bare_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e0$quantifier<-'some'
e0$context<-'bare'
e1<-read.csv(paste(tfbt.dir,'postChain2_danger_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e1$quantifier<-'some'
e1$context<-'danger'
e2<-read.csv(paste(tfbt.dir,'postChain2_distinct_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e2$quantifier<-'some'
e2$context<-'distinct'
e3<-read.csv(paste(tfbt.dir,'postChain2_irrelevant_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e3$quantifier<-'some'
e3$context<-'irrelevant'

f0<-read.csv(paste(tfbt.dir,'postChain2_bare_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f0$quantifier<-'generic'
f0$context<-'bare'
f1<-read.csv(paste(tfbt.dir,'postChain2_danger_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f1$quantifier<-'generic'
f1$context<-'danger'
f2<-read.csv(paste(tfbt.dir,'postChain2_distinct_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f2$quantifier<-'generic'
f2$context<-'distinct'
f3<-read.csv(paste(tfbt.dir,'postChain2_irrelevant_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f3$quantifier<-'generic'
f3$context<-'irrelevant'

all.data2<-rbind(f0,f1,f2,f3,e0,e1,e2,e3,d0,d1,d2,d3)

all.data2$quantifier<- factor(all.data$quantifier)
all.data2$context<-factor(all.data$context)

ggplot(data=all.data2,aes(x=value,fill=context))+
  geom_density()+
  facet_grid(context~quantifier)+
  theme_bw()+
  scale_x_continuous(breaks=c(10,30,50,70,90))

ddply(all.data, .(context, quantifier), summarise, mean(value))

```


# Experiment 4 -- within-subjects effect of context on Generic

The idea now is to see if the generic theta differs across contexts, thus motivating a lifted variable model from a bayesian data analysis standpoint.

+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False

The sentence is between subjects (subjects see only generics or mosts or somes).

Within-subject is the context:

+ **distinctive**
+ **irrelevant**
+ **bare**

```{r exp4}

setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
td4<-read.table('cbgR-exp4-trials.tsv',header=T)
#write.csv(td4, file='cbgR-exp4_anonymized-trials.csv')


td4$rt <- td4$rt/1000
td4$truth_conditions <- factor(as.logical(levels(td4$response)[td4$response]), 
                              levels=c("TRUE","FALSE"))

td4$truth_num <- bool.tonum(td4$truth_conditions)


results<-glmer(truth_num ~ stim_prevalence*stim_type + (1 | workerid) + (1 | stim_category), data=td4, family='binomial')
summary(results)



tc<-subset(td4,trial_type=='truth_conditions')
tc<-subset(td4,workerid<30)
tc$truth_num <- 1*as.logical(tc$truth_conditions)

tc.bs<-bootstrap.ci.tc(tc[tc$trialNum<15,])
tc.bs<-bootstrap.ci.tc(tc[tc$trialNum>=15,])

tc.bs<-bootstrap.ci.tc(tc)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))


Number of responses for each prevalence level (for truth conditions task)
```{r, echo=FALSE}
table(td1[,c("stim_determiner","stim_prevalence")])/6
```

Subject-wise thresholds for generic across 3 contexts

```{r}
df<-ddply(subset(td4,trial_type=='truth_conditions' & truth_conditions==TRUE), 
      .(workerid, stim_type), summarise,
      mean_prev = mean(stim_prevalence),
      min_prev = min(stim_prevalence))

ggplot(data=df, aes(x=min_prev,fill=stim_type,group=stim_type))+
  geom_histogram()+
  facet_wrap(~stim_type)+
  theme_bw()

```


Recreate ANOVA from CBG Exp 4

```{r anova}
df<-ddply(subset(td4,trial_type=='truth_conditions' & truth_conditions==TRUE), 
      .(stim_prevalence, stim_type), summarise,
      count = sum(as.numeric(truth_conditions)))

td4$truth_num<-abs(as.numeric(td4$truth_conditions)*1-2)

results<-glmer(truth_num ~ stim_prevalence*stim_type + (1 | workerid), data=td4, family='binomial')
summary(results)


summary(aov(truth_num~(stim_prevalence*stim_type)+Error(workerid/(stim_prevalence*stim_type)),
    data=td4))

```


# Experiment 5 -- within-subjects effect of context on Generic (Replicate truth conditions of Exp 1 of CBG exactly)

+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False

The sentence is between subjects (subjects see only generics or mosts or somes).

Within-subject is the context:

+ **dangerous and distinctive**
+ **nondistinctive control**
+ **bare**

```{r exp5}
td5<-read.table('cbgR-exp5-trials.tsv',header=T)
td5$stim_type<-gsub("danger/distinct","dangerdistinct",td5$stim_type)
#write.csv(td5, file='cbgR-exp5_anonymized-trials.csv')

td5$item<-paste(td5$stim_color,td5$stim_part,sep='_')
levels(factor(subset(td5,stim_type=='bare')$item))

td5$rt <- td5$rt/1000
td5$truth_conditions <- factor(as.logical(levels(td5$response)[td5$response]), 
                              levels=c("TRUE","FALSE"))

td5$truth_num <- bool.tonum(td5$truth_conditions)

#split by first half/second half to look at order effects
#tc.bs<-bootstrap.ci.tc(td5[td5$trialNum>15,])

tc.bs<-bootstrap.ci.tc(td5)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))
```

### frequentist statistics

```{r exp4_5_stats}
cntxt.ef4<-ddply(td4, .(workerid), summarise,
      trialnum = trialNum,
      irrelevant_seen=cumsum(as.numeric(stim_type=='irrelevant')),
      distinct_seen=cumsum(as.numeric(stim_type=='distinct')),
      nonbare_seen=cumsum(as.numeric(stim_type!='bare')),
      context = stim_type,
      response = truth_num,
      prevlev = stim_prevalence,
      item = stim_category)


cntxt.ef5<-ddply(td5, .(workerid), summarise,
      trialnum = trialNum,
      nondistinct_seen=cumsum(as.numeric(stim_type=='nondistinctive')),
      dangdistinct_seen=cumsum(as.numeric(stim_type=='dangerdistinct')),
      nonbare_seen=cumsum(as.numeric(stim_type!='bare')),
      context = stim_type,
      response = truth_num,
      prevlev = stim_prevalence,
      item = stim_category)



rs4.mixed<-glmer(response ~ prevlev*context + (1 | workerid) + (1 | item), data=cntxt.ef4, family = 'binomial')
summary(rs4.mixed)

rs5.simple<-glm(response ~ prevlev*context,data=cntxt.ef5,family='binomial')
summary(rs5.simple)

rs5.mixed<-glmer(response ~ prevlev*context + (1 | workerid) + (1 | item), data=cntxt.ef5, family = 'binomial')
summary(rs5.mixed)


```

### bayesian statistics

## Infer thresholds for quantifiers from truth conditions task

```{r tfbt.tc.exp4.exp5}
tfbt.dir <- '/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis/'

f0<-read.csv(paste(tfbt.dir,'post_wPhi_exp5bare_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
f0$quantifier<-'generic'
f0$context<-'bare'
# ggplot(data=f0,aes(x=theta))+geom_histogram()+
#   scale_x_continuous(limits=c(0,100),breaks=c(10,30,50,70,90))
# ggplot(data=f0,aes(x=phi))+geom_histogram()+
#   scale_x_continuous(limits=c(0,1))

f1<-read.csv(paste(tfbt.dir,'post_wPhi_exp5nondistinctive_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
f1$quantifier<-'generic'
f1$context<-'nondistinctive-control'

f2<-read.csv(paste(tfbt.dir,'post_wPhi_exp5dangerdistinct_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
f2$quantifier<-'generic'
f2$context<-'danger-distinct'


all.data<-rbind(f0,f2,f1)
all.data$phi <- all.data$phi*100

all.data$quantifier<- factor(all.data$quantifier)
all.data$context<-factor(all.data$context)

exp5.tfbt<-melt(all.data[,c(1,2,4,5)],id.vars=c('quantifier','context'))
exp5.tfbt$variable<-factor(exp5.tfbt$variable,levels=c("theta","phi"))

ggplot(data=exp5.tfbt,aes(x=value,fill=context))+
  geom_density(alpha=0.8)+
  facet_grid(variable~context)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))


g0<-read.csv(paste(tfbt.dir,'post_wPhi_exp4bare_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
g0$quantifier<-'generic'
g0$context<-'bare'
g1<-read.csv(paste(tfbt.dir,'post_wPhi_exp4irrelevant_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
g1$quantifier<-'generic'
g1$context<-'irrelevant'
g2<-read.csv(paste(tfbt.dir,'post_wPhi_exp4distinct_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
g2$quantifier<-'generic'
g2$context<-'distinct'

a.data<-rbind(g0,g1,g2)
a.data$phi <- a.data$phi*100
a.data$quantifier<- factor(a.data$quantifier)
a.data$context<-factor(a.data$context)

exp4.tfbt<-melt(a.data[,c(1,2,4,5)],id.vars=c('quantifier','context'))
exp4.tfbt$variable<-factor(exp4.tfbt$variable,levels=c("theta","phi"))

ggplot(data=exp4.tfbt,aes(x=value,fill=context))+
  geom_density(alpha=0.8)+
  facet_grid(variable~context)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))



ddply(all.data, .(context, quantifier), summarise, mean(value))

```

Using a phi common across contexts
```{r tfbt.commonPhi} 
test0<-read.csv(paste(tfbt.dir,'post_wPhi_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,
                col.names=c("nondistinctive_phi","nondistinctive_theta","blank","bare_phi","bare_theta","blank","dangerdistinct_phi","dangerdistinct_theta","blank","blank"))[,c(1,2,4,5,7,8)]

test0$nondistinctive_phi<-test0$nondistinctive_phi*100
test0$bare_phi <- test0$bare_phi*100
test0$dangerdistinct_phi <- test0$dangerdistinct_phi*100
x<-melt(test0)

x1<-cbind(x,ldply(strsplit(as.character(x$variable),"_")))
x1$V2<-factor(x1$V2,levels=c("theta","phi"))
x1$V1<-factor(x1$V1, levels=c("dangerdistinct","nondistinctive","bare"))

a<-ggplot(data=subset(x1,V2=='theta'),aes(x=value,fill=V1))+
  geom_density(alpha=0.8)+
 # facet_grid(V2~V1)+
  theme_paper()+
#  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal')+
  guides(fill=guide_legend(title="Context"))+
  xlab("generic threshold")

b<-ggplot(data=subset(x1,V2=='phi'),aes(x=value))+
  geom_density(alpha=0.8,fill='grey69')+
 # facet_grid(V2~V1)+
  theme_paper()+
#  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))+
#  guides(fill=guide_legend(title="Context"))+
  xlab("phi (guessing parameter)")

grid.arrange(a,b,nrow=1)

```

### "Kinder" model

```{r tfbt.kinder.exp5}
#d<-read.csv(paste('kinder_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudIsLorch_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudWhoIsIt_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudUncertain_l0predictivepower_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudUncertain_justPrev_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
d<-read.csv(paste('kinder_qudUncertain_prevForGen_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)


d.tidy <- d %>%
  select(V1,V2,V3,V5,V6,V7,V9,V10,V11) %>%
  rename(nondistinct_phi = V1,
         nondistinct_theta = V2,
         nondistinct_other = V3,
         bare_phi = V5,
         bare_theta = V6,
         bare_other = V7,
         distinct_phi = V9, 
         distinct_theta = V10,
         distinct_other= V11) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

d.tidy$variable<-factor(d.tidy$variable,levels=c("theta","other","phi"))

ggplot(d.tidy,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(variable~context)+
  theme_bw()

```

### Listener model w/ beta hyperprior

```{r tfbt.hyperprio.exp5}
setwd('../models/bayesian_analysis/')
d<-read.csv(paste('listen_betaHyper2_exp5all_generic_truth_conditions_mh10000_3_alpha3.csv',sep=''),header=F)


d.tidy <- d %>%
  select(V1,V2,V3,V5,V6,V7,V9,V10,V11) %>%
  rename(nondistinct_phi = V1,
         nondistinct_gamma = V2,
         nondistinct_delta = V3,
         bare_phi = V5,
         bare_gamma = V6,
         bare_delta = V7,
         distinct_phi = V9, 
         distinct_gamma = V10,
         distinct_delta= V11) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

d.tidy$variable<-factor(d.tidy$variable,levels=c("gamma","delta","phi"))

ggplot(d.tidy,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(context~variable,scale='free')+
  theme_bw()

+
  xlim(0,1)

```



Are the alternative contexts having an effect on endorsements? One preliminary way to test this is to look at the endorsements for the bare, as the number of Nondistinct contexts have been seen.

First, I'll code the data for the number of nondistinct contexts seen by the participant.

```{r exp4_5contextEffect}

## effect of nondistinct seen
nondist_seen.df5<- ddply(cntxt.ef5, .(nondistinct_seen, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(nondist_seen.df5,context=='bare'), aes(x=nondistinct_seen,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
  scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10))+
  xlab("number of nondistinct seen")+
  ylab("proportion of true responses")+
  ggtitle("bare generic endorsements by nondistinct contexts seen and prevalence level")

## effect of dangerous and distinct seen
dangdist_seen.df5<- ddply(cntxt.ef5, .(dangdistinct_seen, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(dangdist_seen.df5,context=='bare'), aes(x=dangdistinct_seen,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
  scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10))+
  xlab("number of dangerous/distinct seen")+
  ylab("proportion of true responses")+
  ggtitle("bare generic endorsements by dangerous/distinct contexts seen and prevalence level")

## effect of other contexts seen (collapsed across dd & nd)
nonbare_seen.df5<- ddply(cntxt.ef5, .(nonbare_seen, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(nonbare_seen.df5,context=='bare'), aes(x=nonbare_seen,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("number of non-bare seen")+
  ylab("proportion of true responses")+
  ggtitle("bare generic endorsements vs. non-bare contexts seen and prevalence level")
```

Are there order effects in generic acceptability?

```{r order.effects}
## effect of trial --- exp 5
cntxt.ef5$trialCat<-(cntxt.ef5$trialnum<15)
cntxt.ef5$trialCat<-factor(cntxt.ef5$trialCat,levels=c(TRUE,FALSE),labels=c("early","late"))


rs5<-glm(response ~ prevlev*context*trialCat, data=cntxt.ef5, family='binomial')
summary(rs5)
with(cntxt.ef5,interaction.plot(context,trialCat,response))
with(cntxt.ef5,interaction.plot(prevlev,trialCat,response))


glmer(response ~prevlev*context*trialCat + (context*prevlev*trialCat| workerid), data=cntxt.ef5)

summary(rs5)

trials_seen.df5<- ddply(cntxt.ef5, .(trialnum, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(trials_seen.df5,context=='bare'), aes(x=trialnum,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("proportion of true responses")+
  ggtitle("exp 5 -- bare generic endorsements vs.trials seen and prevalence level")

ggplot(data=subset(trials_seen.df5,context=='bare'), aes(x=trialnum,y=n))+ 
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("number of responses")+
  ggtitle("bare generic endorsements vs.trials seen and prevalence level")


## effect of trial --- exp 4
trials_seen.df4<- ddply(cntxt.ef4, .(trialnum, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(trials_seen.df4,context=='bare'), aes(x=trialnum,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("proportion of true responses")+
  ggtitle("exp 4 - bare generic endorsements vs.trials seen and prevalence level")

ggplot(data=subset(trials_seen.df4,context=='bare'), aes(x=trialnum,y=n))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("number of responses")+
  ggtitle("exp 4-- bare generic endorsements vs.trials seen and prevalence level")
```

# Experiment 6: p(property | any-animal) elicitation


```{r exp6}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
turk.data<-read.table('cbgR-exp6-trials.tsv',header=T)
summary(turk.data)
```


Reaction time histograms

```{r}
ggplot(turk.data,aes(x=rt/60000,fill=stim_type))+
  geom_histogram()+
  facet_wrap(~stim_type)+
  guides(fill=F)+
  xlab('rt in minutes')+
  theme_bw()
```


Prevalence histograms / densities, broken up by context

and then by item and context

```{r}
ggplot(turk.data,aes(x=response,fill=stim_type))+
  #geom_histogram(binwidth=1, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  geom_histogram(binwidth=1)+
  #geom_density()+
  facet_wrap(~stim_type)+
  guides(fill=F)+
  theme_bw()


ddply(turk.data, .(stim_type), 
                  summarise,
                  pr.true=mean(response),
                  med = median(response),
                  variance = sqrt(var(response)))


ggplot(turk.data,aes(x=response,fill=stim_type))+
  geom_histogram(binwidth=5, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_density()+
  facet_grid(stim_type~item)+
  guides(fill=F)+
  theme_bw()

levels(factor(subset(turk.data,stim_type=='bare')$item))

ggplot(turk.data,aes(x=trial_num,y=response,color=stim_type))+
  geom_point()+
  theme_bw()


```

```{r exp6.stats}

turk.data$item<-paste(turk.data$stim_color,turk.data$stim_part,sep="_")

rs6.mixed<-lmer(response ~ trial_num+ stim_type + (1 | workerid) + (1 | item), data=turk.data)

summary(rs6.mixed)

d<-ddply(turk.data, .(stim_type, item), 
                  summarise,
                  mean = mean(response))

ggplot(d,aes(x=mean,fill='bare'))
```

# Experiment 7: finer grain

### Same as Exp 5 but with Prevalence levels = {5, 15, 25, 35, 45}

```{r exp7}
td7<-read.table('cbgR-exp7-trials.tsv',header=T)
td7$stim_type<-gsub("danger/distinct","dangerdistinct",td7$stim_type)
#write.csv(td7, file='cbgR-exp7_anonymized-trials.csv')

td7$rt <- td7$rt/1000
td7$truth_conditions <- factor(as.logical(levels(td7$response)[td7$response]), 
                              levels=c("TRUE","FALSE"))

td7$truth_num <- bool.tonum(td7$truth_conditions)

split by first half/second half to look at order effects
tc.bs<-bootstrap.ci.tc(td7[td7$trialNum<=15,])


tc.bs<-bootstrap.ci.tc(td7)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
 # geom_line(size=0.3,position=position_dodge(0.4))+
  geom_point(size=3, position=position_dodge(0.4))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.4))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))
```

Some stats
```{r exp7.stats}

cntxt.ef7<-ddply(td7, .(workerid), summarise,
      trialnum = trialNum,
      nondistinct_seen=cumsum(as.numeric(stim_type=='nondistinctive')),
      dangdistinct_seen=cumsum(as.numeric(stim_type=='dangerdistinct')),
      nonbare_seen=cumsum(as.numeric(stim_type!='bare')),
      context = stim_type,
      response = truth_num,
      prevlev = stim_prevalence,
      item = stim_category)


cntxt.ef7$trialCat<-(cntxt.ef7$trialnum<15)
cntxt.ef7$trialCat<-factor(cntxt.ef7$trialCat,levels=c(TRUE,FALSE),labels=c("early","late"))


rs7<-glm(response ~ prevlev*context*trialCat, data=cntxt.ef7, family='binomial')
summary(rs7)
with(cntxt.ef7,interaction.plot(context,trialCat,response))
with(cntxt.ef7,interaction.plot(prevlev,trialCat,response))


rs7.simple<-glm(response ~ prevlev*context,data=cntxt.ef7,family='binomial')
summary(rs7.simple)

rs7.mixed<-glmer(response ~ prevlev*context + (1 | workerid) + (1 | item), data=cntxt.ef7, family = 'binomial')
summary(rs7.mixed)
```

Using a phi common across contexts
```{r tfbt7.commonPhi} 
test0<-read.csv(paste(tfbt.dir,'post_wPhi_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,
                col.names=c("nondistinctive_phi","nondistinctive_theta","blank","bare_phi","bare_theta","blank","dangerdistinct_phi","dangerdistinct_theta","blank","blank"))[,c(1,2,4,5,7,8)]

test0$nondistinctive_phi<-test0$nondistinctive_phi*100
test0$bare_phi <- test0$bare_phi*100
test0$dangerdistinct_phi <- test0$dangerdistinct_phi*100
x<-melt(test0)

x1<-cbind(x,ldply(strsplit(as.character(x$variable),"_")))
x1$V2<-factor(x1$V2,levels=c("theta","phi"))


ggplot(data=x1,aes(x=value,fill=V1))+
  geom_density(alpha=0.8)+
  #geom_histogram(alpha=0.8)+
  facet_grid(V2~V1)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(5,15,25,35,45,75),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))
```

## TFBT on the "kinds" model
```{r tfbt7.kinds} 
test0<-read.csv(paste(tfbt.dir,'KindMod_post_wPhi_exp5all_generic_truth_conditions_mh2000_3_alpha3.csv',sep=''),header=F,
                col.names=c("nondistinctive_phi","nondistinctive_theta","nondistinctive_other",
                            "blank","bare_phi","bare_theta","bare_other","blank",
                            "dangerdistinct_phi","dangerdistinct_theta","dangerdistinct_other",
                            "blank","blank"))[,c(1,2,3,5,6,7,9,10,11)]

test0$nondistinctive_theta<-test0$nondistinctive_theta/100
test0$bare_theta <- test0$bare_theta/100
test0$dangerdistinct_theta <- test0$dangerdistinct_theta/100
x<-melt(test0)
x1<-cbind(x,ldply(strsplit(as.character(x$variable),"_")))
x1$V2<-factor(x1$V2,levels=c("theta","other","phi"))

ggplot(data=x1,aes(x=value,fill=V1))+
  #geom_density(alpha=0.8)+
  geom_histogram(alpha=0.8)+
  facet_grid(V2~V1)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(0.1,0.3,0.5,0.70,0.9),limits=c(0,1))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))
```


# Experiment 8 -- frequency elicitation


```{r exp8}
setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp8-trials.tsv',header=T)
d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)

d0<-subset(d,response<50000)
sketchy<-c(6,13,22,29)

d0<-subset(d,!(workerid%in%sketchy))

ggplot(d,aes(x=response,fill=stim_type))+
  geom_histogram()+
  facet_wrap(~workerid)

d0$stim_type<-factor(d0$stim_type,levels=c("danger-distinct","nondistinctive","bare"))


exp2<-ggplot(d0,aes(x=response/1000,fill=stim_type))+
  #geom_histogram(binwidth=1, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_histogram()+
  geom_density()+
  facet_wrap(~stim_type)+
  guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)+
  xlab("XX% of lorches have purple feathers")


ddply(d0, .(stim_type), 
                  summarise,
                  pr.true=mean(response),
                  med = median(response),
                  variance = sqrt(var(response)))


summary(lmer(response ~ stim_type*stim_prev + (1 | workerid) + (1 | stim_prev)+ (1 | item), data=d0))

qplot(data=d0, x = stim_prev, y = response, color=stim_type, geom='point')+
  facet_wrap(~stim_type)+
  scale_x_continuous(breaks=c(10,30,50,70,90))
d0%>%select(stim_type, stim_prev, response)

d.mean<-ddply(d0, .(stim_type,stim_prev), summarise, mean=mean(response))
ggplot(d.mean, aes(x = stim_prev,y=mean))+
  geom_bar(stat='identity')+
  facet_wrap(~stim_type)+
  scale_x_continuous(breaks=c(10,30,50,70,90))

```



# Experiment 9 -- replication (exp 5) with proper randomization


```{r exp9}
setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp9-trials.tsv',header=T)

#write.csv(d, file='cbgR-exp9-trials.csv')

d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)

levels(factor(subset(d,stim_type=='bare')$item))

d$rt <- d$rt/1000
d$truth_conditions <- factor(as.logical(levels(d$response)[d$response]), 
                              levels=c("TRUE","FALSE"))

d$truth_num <- bool.tonum(d$truth_conditions)
tc.bs<-bootstrap.ci.tc(d)

tc.bs$stim_type<-factor(tc.bs$stim_type,levels=c('danger-distinct','nondistinctive','bare'))
# ggplot(d,aes(x=factor(truth_num),fill=stim_type))+
#   geom_histogram()+
#   facet_wrap(~item)+
  #facet_wrap(~workerid)

#split by first half/second half to look at order effects
#tc.bs<-bootstrap.ci.tc(d[d$trialNum>15,])



ggplot(tc.bs, aes(x=stim_prevalence,y=truth_num,
                  colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=5,
              size=0.8,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("XX% of lorches have purple feathers")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)
```

### bayesian data of fixed threshold model


```{r tfbtexp9-fixedTheta}
d<-read.csv(paste('post_wPhi_exp9all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)


d.tidy <- d %>%
  select(V1,V2,V3,V4) %>%
  rename(phi = V1,
         danger_distinct = V2,
         nondistinct = V3,
         bare = V4) %>%
  gather(variable,value)

a<-ggplot(subset(d.tidy,variable!='phi'),aes(x=value,fill=variable))+
  geom_density(alpha=0.8)+
 # facet_grid(V2~V1)+
  theme_paper()+
#  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal')+
  guides(fill=guide_legend(title="Context"))+
  xlab("generic threshold")



b<- ggplot(subset(d.tidy,variable=='phi'),aes(x=value))+
  geom_density(alpha=0.8,fill='grey10')+
 # facet_grid(V2~V1)+
  theme_paper()+
#  guides(fill=F)+
  scale_x_continuous(breaks=c(0,.25,.50,.75,1),limits=c(0,1))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))+
#  guides(fill=guide_legend(title="Context"))+
  xlab("phi (guessing parameter)")

grid.arrange(a,b,nrow=1)
 # facet_grid(variable~context)+

```

Posterior predictive for fixed threshold

```{r post.pred.fixed.theta}
d.tidy <- d %>%
  select(V6,V11,V16, V21, V26,
         V32, V37, V42, V47, V52,
         V58, V63, V68, V73, V78
         ) %>%
  rename(dangerdistinct_10 = V6,
         dangerdistinct_30 = V11,
         dangerdistinct_50 = V16,
         dangerdistinct_70 = V21,
         dangerdistinct_90 = V26,
         nondistinct_10 = V32,
         nondistinct_30 = V37,
         nondistinct_50 = V42,
         nondistinct_70 = V47,
         nondistinct_90 = V52,
         bare_10 = V58,
         bare_30 = V63,
         bare_50 = V68,
         bare_70 = V73,
         bare_90 = V78) %>% 
  gather(evidence, response)%>%
  separate(evidence, into = c("context","prevalence"), sep="_")

d.tidy$value<-as.numeric(d.tidy$response=='generic')

ddply(d.tidy , .(context,prevalence), summarise,
      mean = sum(response=='generic') / length(response))

d.stats<-ddply(d.tidy, .(context,prevalence), summarise,
      mean = mean(value),
      CIlow=quantile(value,probs=0.025),
      CIhigh=quantile(value,probs=0.975))


d.stats$context<-factor(d.stats$context,levels=c('dangerdistinct','nondistinct','bare'), labels=c('danger_distinct','nondistinctive','bare'))
d.stats$prevalence<-as.numeric(d.stats$prevalence)

fixed<-ggplot(data=d.stats,aes(x=prevalence,y=mean,color=context,group=context))+
  geom_point(size=3, position=position_dodge(2))+
  geom_line(size=0.5,position=position_dodge(2))+
#       geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
#               width=0.5,
#               size=3)+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1.05))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("XX% of lorches have purple feathers")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)


tc.bs<-rename(tc.bs, prevalence=stim_prevalence, context=stim_type, pr.true=truth_num)  
tc.bs$context<-factor(tc.bs$context, labels=c("dangerdistinct","nondistinct","bare"))

m<-merge(d.stats,tc.bs, by=c("context", "prevalence"))
with(m, cor(pr.true,mean))

```


### TFBT on Listener1 model with $\Beta$ Hyperprior 


```{r tfbt.L1.betaHyper.exp9}
setwd('../models/bayesian_analysis/')
# d<-read.csv(paste('listen_betaHyper_exp9all_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=T)

d<-read.csv(paste('listen_betaHyper_discreteHyper_exp9all_generic_truth_conditions_mh100_50_alpha3.csv',sep=''),header=F)


# 
# params.tidy <- d %>%
#   select(danger_gamma,danger_delta,nondistinct_gamma,nondistinct_delta,
#          bare_gamma,bare_delta) %>%
#   gather(variable,value) %>%
#   separate(variable,into=c('context','variable') ,sep="_")

params.tidy <- d %>%
  select(V2,V3,V5,V6,V8,V9) %>%
  rename(dangerdistinct_gamma = V2,
         dangerdistinct_delta = V3,
         nondistinct_gamma = V5,
         nondistinct_delta = V6,
         bare_gamma=V8,
         bare_delta=V9) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

#phi.tidy <- d %>% select(phi)
phi.tidy <- d %>% select(V1) %>% rename(phi=V1)


params.tidy$variable<-factor(params.tidy$variable,levels=c("gamma","delta"))
params.tidy$context<-factor(params.tidy$context,
                            levels=c("dangerdistinct","nondistinct","bare"))

myBreaks <- list(a = seq(0,1,0.1), b=seq(0,5,0.5))
params.hist <- mapply(function(x, b) geom_histogram(data = x, breaks = b,position=position_dodge(), alpha=0.8), 
              dlply(params.tidy, .(variable)), myBreaks)

range_act <- c(0,1)

range(subset(params.tidy,variable=='gamma')$value)
  
  range(, 
                   range(subset(params.tidy,variable=='delta')$value))

dummy <- data.frame(value = range_act,
                    variable = "gamma", 
                    context = c("dangerdistinct","nondistinct","bare"),
                    stringsAsFactors=FALSE)

ggplot(params.tidy,aes(x=value,fill=context))+
   geom_histogram(alpha=0.8)+
#  geom_blank(data=dummy)+
  #geom_density(alpha=0.8)+
#  params.hist + 
  facet_grid(context~variable,scale='free')+
  theme_paper()+
  guides(fill=F)+
  xlab("inferred parameter value")+
  scale_fill_brewer(type='qual',palette=6)


ggplot(phi.tidy,aes(x=phi))+
  geom_density(alpha=0.8,fill='grey10')+
  theme_paper()+
  xlab("phi")
```

With posterior predictive.

```{r postpred.liftedvar.exp9}

pp.tidy<- d %>%
  select(V12,V13,V14,V15,V16,
         V18,V19,V20,V21,V22,
         V24,V25,V26,V27,V28) %>%
  rename(danger_10= V12,
         danger_30= V13,
         danger_50 = V14,
         danger_70 = V15,
         danger_90 = V16,
         nondistinct_10 = V18,
         nondistinct_30 = V19,
         nondistinct_50 = V20,
         nondistinct_70 = V21,
         nondistinct_90 = V22,
         bare_10 = V24,
         bare_30= V25,
         bare_50 = V26,
         bare_70 = V27,
         bare_90 = V28) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','prevalence') ,sep="_")

pp.stats<-ddply(pp.tidy, .(context,prevalence), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))


pp.stats$context<-factor(pp.stats$context,levels=c('danger','nondistinct','bare'), labels=c('danger-distinct','nondistinctive','bare'))
pp.stats$prevalence<-as.numeric(pp.stats$prevalence)

ggplot(data=pp.stats,aes(x=prevalence,y=mean,color=context,group=context))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh,colour=context),
              width=5,
              size=0.8,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("XX% of lorches have purple feathers")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)


# tc.bs<-rename(tc.bs, prevalence=stim_prevalence, context=stim_type, pr.true=truth_num)  

m<-merge(pp.stats,tc.bs, by=c("context", "prevalence"))
with(m, cor(mean,pr.true))

ggplot(data=m, aes(x=mean, y=pr.true,color=context))+
  geom_point(size=3)+
  geom_abline(intercept=0,slope=1,linetype=3)+
  geom_errorbarh(aes(xmin=CIlow,xmax=CIhigh),
              height=0.04,
              size=0.5)+
    geom_errorbar(aes(ymin=YMin,ymax=YMax),
              width=0.04,
              size=0.5)+
  theme_paper()+
    scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1.05))+
    scale_x_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1.05))+
  guides(color=guide_legend(title="Context"))+
  xlab("model posterior predictive")+
  ylab('experiment 1 data')+
  coord_fixed(1)+
    scale_colour_brewer(type='qual',palette=6)
```


### TFBT on Speaker2 model with $\Beta$ Hyperprior 


```{r tfbt.S2.betaHyper.exp9}
setwd('../models/bayesian_analysis/')
# d<-read.csv(paste('listen_betaHyper_exp9all_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=T)

d<-read.csv(paste('speak_listenDifAlt_betaHyper_discreteHyper_exp9all_generic_truth_conditions_mh1000_50_alpha1.csv',sep=''),header=F)

d<-read.csv('speak_listenDifAlt_condition2tasksChain2_betaHyper_discreteHyper_exp9all_generic_truth_conditions_mh1000_50_alpha1.csv',header=F)
d<-read.csv('speak_listenDifAlt_condition2tasksChain3_betaHyper_Hyper_exp9all_generic_truth_conditions_mh100_25_alpha3.csv',header=F)
#d<-read.csv(paste('speak_listen_betaHyper_discreteHyper_exp9all_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F)


# 
# params.tidy <- d %>%
#   select(danger_gamma,danger_delta,nondistinct_gamma,nondistinct_delta,
#          bare_gamma,bare_delta) %>%
#   gather(variable,value) %>%
#   separate(variable,into=c('context','variable') ,sep="_")

params.tidy <- d %>%
  select(V2,V3,V5,V6,V8,V9) %>%
  rename(dangerdistinct_gamma = V2,
         dangerdistinct_delta = V3,
         nondistinct_gamma = V5,
         nondistinct_delta = V6,
         bare_gamma=V8,
         bare_delta=V9) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

#phi.tidy <- d %>% select(phi)
phi.tidy <- d %>% select(V1) %>% rename(phi=V1)


params.tidy$variable<-factor(params.tidy$variable,levels=c("gamma","delta"))
params.tidy$context<-factor(params.tidy$context,
                            levels=c("dangerdistinct","nondistinct","bare"))

params.stats<-ddply(params.tidy, .(context,variable), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))

sample.beta<-function(n,gamma,delta){
  shape1 <- gamma*delta
  shape2 <- (1-gamma)*delta
  return(rbeta(n,shape1,shape2))
}

sb<-melt(data.frame(
  dangerdistinct=sample.beta(1000,params.stats[1,3],params.stats[2,3]),
  nondistinctive=sample.beta(1000,params.stats[3,3],params.stats[4,3]),
  bare=sample.beta(1000,params.stats[5,3],params.stats[6,3])
               ))


p<-ggplot(sb,aes(x=100*value,fill=variable))+
  #geom_density()+
  geom_histogram()+
  xlim(0,100)+
  facet_wrap(~variable)+
  guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)+
  xlab("mean inferred prior distribution, from RSA and exp1 & imp-prev exp")
grid.arrange(exp2,p)


ggplot(params.tidy,aes(x=value,fill=context))+
   geom_histogram(alpha=0.8)+
#  geom_blank(data=dummy)+
  #geom_density(alpha=0.8)+
#  params.hist + 
  facet_grid(context~variable,scale='free')+
  theme_paper()+
  guides(fill=F)+
  xlab("inferred parameter value")+
  scale_fill_brewer(type='qual',palette=6)

ggplot(subset(params.tidy,variable=='delta'),aes(x=value,fill=context))+
  # geom_histogram(alpha=0.8)+
#  geom_blank(data=dummy)+
  geom_density(alpha=0.8)+
#  params.hist + 
  facet_grid(.~context,scale='free')+
  theme_paper()+
  guides(fill=F)+
  xlab("inferred parameter value")+
  scale_fill_brewer(type='qual',palette=6)




ggplot(phi.tidy,aes(x=phi))+
  geom_density(alpha=0.8,fill='grey10')+
  theme_paper()+
  xlab("phi")+
  xlim(0,1)
```

With posterior predictive.

```{r postpred.S2.liftedvar.exp9}
# 
# pp.tidy<- d %>%
#   select(V12,V13,V14,V15,V16,
#          V18,V19,V20,V21,V22,
#          V24,V25,V26,V27,V28) %>%
#   rename(danger_10= V12,
#          danger_30= V13,
#          danger_50 = V14,
#          danger_70 = V15,
#          danger_90 = V16,
#          nondistinct_10 = V18,
#          nondistinct_30 = V19,
#          nondistinct_50 = V20,
#          nondistinct_70 = V21,
#          nondistinct_90 = V22,
#          bare_10 = V24,
#          bare_30= V25,
#          bare_50 = V26,
#          bare_70 = V27,
#          bare_90 = V28) %>%
#   gather(variable,value) %>%
#   separate(variable,into=c('context','prevalence') ,sep="_")


pp.tidy<- d %>%
  select(V15,V22,V29,V36,V43,
         V51,V58,V65,V72,V79,
         V87,V94,V101,V108,V115) %>%
  rename(danger_truth_10= V15,
         danger_truth_30= V22,
         danger_truth_50 = V29,
         danger_truth_70 = V36,
         danger_truth_90 = V43,
         nondistinct_truth_10 = V51,
         nondistinct_truth_30 = V58,
         nondistinct_truth_50 = V65,
         nondistinct_truth_70 = V72,
         nondistinct_truth_90 = V79,
         bare_truth_10 = V87,
         bare_truth_30= V94,
         bare_truth_50 = V101,
         bare_truth_70 = V108,
         bare_truth_90 = V115) %>%
    gather(variable,value) %>%
   separate(variable,into=c('context','qud','prevalence') ,sep="_")





pp.tidy<- d %>%
  select(V15,V22,V29,V36,V43,
         V51,V58,V65,V72,V79,
         V87,V94,V101,V108,V115,
         V131,V132,V133,V134,V135,V136,V137,V138,V139,
         V152,V153,V154,V155,V156,V157,V158,V159,V160,
         V173,V174,V175,V176,V177,V178,V179,V180,V181) %>%
  rename(danger_truth_10= V15,
         danger_truth_30= V22,
         danger_truth_50 = V29,
         danger_truth_70 = V36,
         danger_truth_90 = V43,
         nondistinct_truth_10 = V51,
         nondistinct_truth_30 = V58,
         nondistinct_truth_50 = V65,
         nondistinct_truth_70 = V72,
         nondistinct_truth_90 = V79,
         bare_truth_10 = V87,
         bare_truth_30= V94,
         bare_truth_50 = V101,
         bare_truth_70 = V108,
         bare_truth_90 = V115,
         danger_implied_10=V131,
         danger_implied_20=V132,
         danger_implied_30=V133,
         danger_implied_40=V134,
         danger_implied_50=V135,
         danger_implied_60=V136,
         danger_implied_70=V137,
         danger_implied_80=V138,
         danger_implied_90=V139,         
         nondistinct_implied_10 = V152,
         nondistinct_implied_20 = V153,
         nondistinct_implied_30 = V154,
         nondistinct_implied_40 = V155,
         nondistinct_implied_50 = V156,
         nondistinct_implied_60 = V157,
         nondistinct_implied_70 = V158,
         nondistinct_implied_80 = V159,
         nondistinct_implied_90 = V160,
         bare_implied_10 = V173,
         bare_implied_20 = V174,
        bare_implied_30 = V175,
        bare_implied_40 = V176,
        bare_implied_50 = V177,
        bare_implied_60 = V178,
        bare_implied_70 = V179,
        bare_implied_80 = V180,
        bare_implied_90 = V181)


pp.stats<-ddply(pp.tidy, .(context,prevalence), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))

#tc.bs<-rename(tc.bs, prevalence=stim_prevalence, context=stim_type)  
#tc.bs$context<-factor(tc.bs$context, labels=c("dangerdistinct","nondistinct","bare"))

m<-merge(pp.stats,tc.bs, by=c("context", "prevalence"))
with(m, cor(truth_num,mean))


pp.stats$context<-factor(pp.stats$context,levels=c('danger','nondistinct','bare'), labels=c('danger-distinct','nondistinctive','bare'))
pp.stats$prevalence<-as.numeric(pp.stats$prevalence)

lvrsa<-ggplot(data=pp.stats,aes(x=prevalence,y=mean,color=context,group=context))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh,colour=context),
              width=5,
              size=0.8,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("XX% of lorches have purple feathers")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)+
  ggtitle("lifted variable RSA model")

fixed1<-fixed+ggtitle('fixed threshold semantics')+guides(color=F)

grid.arrange(fixed1,lvrsa,nrow=1)
grid.draw(cbind(ggplotGrob(fixed1), ggplotGrob(lvrsa), size="last"))


pp.tidy$no<-row.names(pp.tidy)

pp.tidy<- pp.tidy %>%
  gather(variable,value, -no) %>%
  separate(variable,into=c('context','qud','prevalence') ,sep="_") 


pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,sum(value))

pp.tidy<-merge(pp.stats,pp.tidy, by=c("no",'context','qud'))
pp.tidy$prob<- pp.tidy$value/pp.tidy$sum
pp.tidy$expval <- pp.tidy$prob*as.numeric(pp.tidy$prevalence)

pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,
      prevalence_score = sum(expval))

pp.stats<-ddply(pp.stats, .(context,qud), summarise,
      median = median(prevalence_score),
      CIlow = quantile(prevalence_score,probs=0.025),
      CIhigh = quantile(prevalence_score,probs=0.975))


pp.stats$context<-factor(pp.stats$context,levels=c('danger','nondistinct','bare'), 
                         labels=c('danger-distinct','nondistinctive','bare'))

ggplot(data=pp.stats,aes(x=context,y=median,fill=qud,group=qud))+
  geom_bar(stat='identity',position=position_dodge(0.5),width=0.5)+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
              position=position_dodge(0.5),
              width=.2)+
  scale_fill_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
 ## scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  #scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))
#  xlab("XX% of lorches have purple feathers")+
#  ylab('proportion of "true" responses')+
 # coord_fixed(100)

```

### Asymmetry

```{r tfbt.asymmetry}
#setwd('../models/bayesian_analysis/')
# d<-read.csv(paste('listen_betaHyper_exp9all_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=T)

#d<-read.csv(paste('speak_listenDifAlt_betaHyper_discreteHyper_exp9all_generic_truth_conditions_mh1000_50_alpha1.csv',sep=''),header=F)

pp.tidy<- d %>%
  select(V15,V22,V29,V36,V43,
         V51,V58,V65,V72,V79,
         V87,V94,V101,V108,V115,
         V132,V133,V134,V135,V136,V137,V138,V139,V140,V141,
         V155,V156,V157,V158,V159,V160,V161,V162,V163,V164,
         V178,V179,V180,V181,V182,V183,V184,V185,V186,V187) %>%
  rename(danger_truth_10= V15,
         danger_truth_30= V22,
         danger_truth_50 = V29,
         danger_truth_70 = V36,
         danger_truth_90 = V43,
         nondistinct_truth_10 = V51,
         nondistinct_truth_30 = V58,
         nondistinct_truth_50 = V65,
         nondistinct_truth_70 = V72,
         nondistinct_truth_90 = V79,
         bare_truth_10 = V87,
         bare_truth_30= V94,
         bare_truth_50 = V101,
         bare_truth_70 = V108,
         bare_truth_90 = V115,
         danger_implied_10=V132,
         danger_implied_20=V133,
         danger_implied_30=V134,
         danger_implied_40=V135,
         danger_implied_50=V136,
         danger_implied_60=V137,
         danger_implied_70=V138,
         danger_implied_80=V139,
         danger_implied_90=V140,
         danger_implied_100=V141,         
         nondistinct_implied_10 = V155,
         nondistinct_implied_20 = V156,
         nondistinct_implied_30 = V157,
         nondistinct_implied_40 = V158,
         nondistinct_implied_50 = V159,
         nondistinct_implied_60 = V160,
         nondistinct_implied_70 = V161,
         nondistinct_implied_80 = V162,
         nondistinct_implied_90 = V163,
         nondistinct_implied_100 = V164,
         bare_implied_10 = V178,
         bare_implied_20 = V179,
        bare_implied_30 = V180,
        bare_implied_40 = V181,
        bare_implied_50 = V182,
        bare_implied_60 = V183,
        bare_implied_70 = V184,
        bare_implied_80 = V185,
        bare_implied_90 = V186,
        bare_implied_100 = V187        
        )





pp.tidy$no<-row.names(pp.tidy)

pp.tidy<- pp.tidy %>%
  gather(variable,value, -no) %>%
  separate(variable,into=c('context','qud','prevalence') ,sep="_") 


pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,sum(value))

pp.tidy<-merge(pp.stats,pp.tidy, by=c("no",'context','qud'))
pp.tidy$prob<- pp.tidy$value/pp.tidy$sum
pp.tidy$expval <- pp.tidy$prob*as.numeric(pp.tidy$prevalence)

pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,
      prevalence_score = sum(expval))

pp.stats<-ddply(pp.stats, .(context,qud), summarise,
      median = median(prevalence_score),
      CIlow = quantile(prevalence_score,probs=0.025),
      CIhigh = quantile(prevalence_score,probs=0.975))


pp.stats$context<-factor(pp.stats$context,levels=c('danger','nondistinct','bare'), 
                         labels=c('danger-distinct','nondistinctive','bare'))

ggplot(data=pp.stats,aes(x=context,y=median,fill=qud,group=qud))+
  geom_bar(stat='identity',position=position_dodge(0.5),width=0.5)+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
              position=position_dodge(0.5),
              width=.2)+
  scale_fill_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
 ## scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  #scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))
#  xlab("XX% of lorches have purple feathers")+
#  ylab('proportion of "true" responses')+
 # coord_fixed(100)
```

### Listener only for asymmetry

```{r tfbt.asymmetry.listen}
#setwd('../models/bayesian_analysis/')
d<-read.csv(paste('listen_betaHyper_discreteHyper_exp3distinct_generic_implied_prevalence_mh1000_50_alpha3.csv',sep=''),header=F)

pp.tidy<- d %>%
  select(V1,V2,V3) %>%
  rename(phi=V1, 
         gamma=V2,
         delta=V3) 

qplot(data=gather(pp.tidy,variable,value),
      x=value,geom='histogram')+facet_wrap(~variable)

qplot(data=pp.tidy,x=gamma,y=delta,geom='point')+
  geom_jitter()

```

Posterior predictive for listener only
```{r tfbt.asymmetry.listener.postpred}


pp.tidy<- d %>%
  select(V16,V17,V18,V19,V20,V21,V22,V23,V24,V25) %>%
  rename(p_10=V16,
         p_20=V17,
         p_30=V18,
         p_40=V19,
         p_50=V20,
         p_60=V21,
         p_70=V22,
         p_80=V23,
         p_90=V24,
         p_100=V25)

pp.tidy$no<-row.names(pp.tidy)
f<-melt(pp.tidy)
f<-f%>%separate(variable,into=c('blank','prevalence'), sep="_")

f$expval <- f$value*as.numeric(f$prevalence)

f.stats<-ddply(f, .(no), summarise,
      prevalence_score = sum(expval))

g<- data.frame(mean=mean(f.stats$prevalence_score),
                CIlow = quantile(f.stats$prevalence_score,probs=0.025),
                CIlow = quantile(f.stats$prevalence_score,probs=0.025))



```


# Experiment 10

```{r exp10}
setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp10-trials.tsv',header=T)

#write.csv(d, file='cbgR-exp9-trials.csv')

d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)

levels(factor(subset(d,stim_type=='bare')$item))

d$rt <- d$rt/1000
d$truth_conditions <- factor(as.logical(levels(d$response)[d$response]), 
                              levels=c("TRUE","FALSE"))

d$truth_num <- bool.tonum(d$truth_conditions)

ggplot(d,aes(x=factor(truth_num),fill=stim_type))+
  geom_histogram()+
 # facet_wrap(~item)
  facet_wrap(~workerid)

#split by first half/second half to look at order effects
#tc.bs<-bootstrap.ci.tc(d[d$trialNum>15,])

tc.bs<-bootstrap.ci.tc(d)

tc.bs$stim_type<-factor(tc.bs$stim_type,levels=c('danger','distinct','bare'))

ggplot(tc.bs, aes(x=stim_prevalence,y=truth_num,
                  colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=5,
              size=0.8,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("XX% of lorches have purple feathers")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)
```



# Experiment 11: prior again

```{r exp11}

setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp11-trials.tsv',header=T)
d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)


d.tidy<-d%>%   select(workerid,rt,
              response0,response1,response2,response3,response4,
              stim_type) %>%
  rename(context=stim_type) %>%
  gather(option,value,-workerid,-rt,-context)

#write.csv(d.tidy,'cbgR-exp11-trials-tidy.csv')

d.tidy$context<-factor(d.tidy$context,levels=c("danger-distinct","nondistinctive","bare"))

dip.test(subset(d.tidy,context=='plain')$value)
dip.test(subset(d.tidy,context=='irrelevant & nondistinctive')$value)
dip.test(subset(d.tidy,context=='dangerous & distinctive')$value)


contrasts(d.tidy$context)<-cbind(dd = c(-2,1,1), ni = c(0, 1, -1))
contrasts(d.tidy$context)<-cbind(dd = c(1,0,-1), ni = c(-1, 2, -1))

rs<-lmer(value ~ context + (1 | workerid), data=d.tidy)
summary(rs)


exp11<-ggplot(d.tidy,aes(x=value,fill=context))+
  geom_histogram()+
  facet_wrap(~context)+
  guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)+
  xlab('prevalence')+
  ggtitle('human elicited prior distribution')

p<-p+ggtitle("inferred prior distribution, from RSA & Exp1&2 data")+xlab('')
grid.arrange(p,exp11)

d.tidy$roundval<-round(d.tidy$value/10)*10

unnormed<-table(d.tidy[,c("context","roundval")])

normedexp2<-data.frame(dd=unnormed[1,]/sum(unnormed[1,]),
           ni=unnormed[2,]/sum(unnormed[2,]),
           pl=unnormed[3,]/sum(unnormed[3,]))
normedexp2$prevalence = row.names(normedexp2)

d.tidy$context<-factor(d.tidy$context,levels=c("danger-distinct","nondistinctive","bare"), 
                        labels=c("dangerous & distinctive", 
                                 "irrelevant & nondistinctive",
                                 "plain"))



exp2<-ggplot(d.tidy,aes(x=roundval,fill=context))+
  geom_histogram(binwidth=10)+
  facet_wrap(~context)+
 # guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)+
  #scale_x_continuous(breaks=c(0,20,40,60,80,100))+
  xlab('prevalence')+
    theme(strip.background = element_blank(),
       strip.text.x = element_blank(),
        legend.position='bottom',
        legend.direction='horizontal')


plotpath = "~/Documents/research/generics/cogsci-2015//paper/figures/"


ggsave(filename=paste(plotpath,'elicited_priors.png',sep=''),
       plot=exp2,
       width=12,
       height=4.5)




#d0<-subset(d.tidy,rt<50000)
#ggplot(d.tidy,aes(x=rt))+geom_histogram()

```


TFBT on Experiment 11

```{r exp11.tfbt}
setwd("~/Documents/research/generics/cbg2010-replication/analysis/")
d<-read.csv('exp11_betaHyperparamsCnts_wPhi_mh1000_10.csv',header=F)
m.tidy<-d %>% 
  select(V1,V2,V4,V5,V7,V8)%>%
  rename(pl_gamma=V1,
         pl_delta=V2,
         dd_gamma=V4,
         dd_delta=V5,
         ni_gamma=V7,
         ni_delta=V8)%>%
  gather(variable,value)%>%
  separate(variable,into=c("context","parameter"),by="_")

m.phi<- d%>%select(V11)%>%rename(phi=V11)

qplot(data=m.phi,x=phi,geom='histogram')

ggplot(subset(m.tidy,parameter=='gamma'),aes(x=value))+
  geom_histogram()+
  facet_grid(context~.)

m.tidy$context<-factor(m.tidy$context,levels=c('dd','ni','pl'))

ggplot(m.tidy,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(context~parameter,scales='free')+
    scale_fill_brewer(type='qual',palette=6)



ddply(m.tidy,.(context,parameter),summarise,mean(value))




```


#Using experiment 11 as an empirical prior

```{r tfbt.exp11prior}
#setwd('../models/bayesian_analysis/')
d<-read.csv(paste('lvRSAemp_2phis_condition2_expts9_12_generic_mh1000_10_alpha1.csv',sep=''),header=F)

m.phi<- d%>%select(V1,V182)%>%rename(phi_truthconditions=V1,
                                     phi_impliedprevalence=V182)%>%
  gather(variable,value)%>%separate(variable,into=c("parameter","task"))


guessing<-ggplot(data=m.phi,aes(x=value,fill=task))+
  facet_wrap(~task,scales='fixed')+
  geom_density()+
  guides(fill=F)+
  scale_fill_brewer(type='qual',palette=1)+
  xlab("phi")+
  scale_x_continuous(limits=c(0,1),breaks=c(0,0.25,0.50,0.75))

pp.tidy<- d %>%
  select(V5,V12,V19,V26,V33,
         V41,V48,V55,V62,V69,
         V77,V84,V91,V98,V105) %>%
  rename(danger_truth_10= V5,
         danger_truth_30= V12,
         danger_truth_50 = V19,
         danger_truth_70 = V26,
         danger_truth_90 = V33,
         nondistinct_truth_10 = V41,
         nondistinct_truth_30 = V48,
         nondistinct_truth_50 = V55,
         nondistinct_truth_70 = V62,
         nondistinct_truth_90 = V69,
         bare_truth_10 = V77,
         bare_truth_30= V84,
         bare_truth_50 = V91,
         bare_truth_70 = V98,
         bare_truth_90 = V105) %>%
    gather(variable,value) %>%
   separate(variable,into=c('context','qud','prevalence') ,sep="_")




pp.stats<-ddply(pp.tidy, .(context,prevalence), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))

# m<-merge(pp.stats,tc.bs, by=c("context", "prevalence"))
# with(m, cor(truth_num,mean))
pp.stats$context<-factor(pp.stats$context,
                         levels=c('danger','nondistinct','bare'), 
                         labels=c('danger-distinct','nondistinctive','bare'))
pp.stats$prevalence<-as.numeric(pp.stats$prevalence)

truthcond<-ggplot(data=pp.stats,aes(x=prevalence,y=mean,
                                    color=context,group=context))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh,colour=context),
              width=5,
              size=0.8,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("prevalence")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)+
  ggtitle("lifted variable RSA model using empirical priors")

```

### posterior predictive for asymmetry, using empirical priors

```{r tfbt.empPrior.asymmetry}

pp.tidy<- d %>%
  select(V5,V12,V19,V26,V33,
         V41,V48,V55,V62,V69,
         V77,V84,V91,V98,V105,
         V122,V123,V124,V125,V126,V127,V128,V129,V130,V131,
         V145,V146,V147,V148,V149,V150,V151,V152,V153,V154,
         V168,V169,V170,V171,V172,V173,V174,V175,V176,V177) %>%
  rename(danger_truth_10= V5,
         danger_truth_30= V12,
         danger_truth_50 = V19,
         danger_truth_70 = V26,
         danger_truth_90 = V33,
         nondistinct_truth_10 = V41,
         nondistinct_truth_30 = V48,
         nondistinct_truth_50 = V55,
         nondistinct_truth_70 = V62,
         nondistinct_truth_90 = V69,
         bare_truth_10 = V77,
         bare_truth_30= V84,
         bare_truth_50 = V91,
         bare_truth_70 = V98,
         bare_truth_90 = V105,
         danger_implied_10=V122,
         danger_implied_20=V123,
         danger_implied_30=V124,
         danger_implied_40=V125,
         danger_implied_50=V126,
         danger_implied_60=V127,
         danger_implied_70=V128,
         danger_implied_80=V129,
         danger_implied_90=V130,
         danger_implied_100=V131,         
         nondistinct_implied_10 = V145,
         nondistinct_implied_20 = V146,
         nondistinct_implied_30 = V147,
         nondistinct_implied_40 = V148,
         nondistinct_implied_50 = V149,
         nondistinct_implied_60 = V150,
         nondistinct_implied_70 = V151,
         nondistinct_implied_80 = V152,
         nondistinct_implied_90 = V153,
         nondistinct_implied_100 = V154,
         bare_implied_10 = V168,
         bare_implied_20 = V169,
        bare_implied_30 = V170,
        bare_implied_40 = V171,
        bare_implied_50 = V172,
        bare_implied_60 = V173,
        bare_implied_70 = V174,
        bare_implied_80 = V175,
        bare_implied_90 = V176,
        bare_implied_100 = V177        
        )





pp.tidy$no<-row.names(pp.tidy)

pp.tidy<- pp.tidy %>%
  gather(variable,value, -no) %>%
  separate(variable,into=c('context','qud','prevalence') ,sep="_") 


pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,sum(value))

pp.tidy<-merge(pp.stats,pp.tidy, by=c("no",'context','qud'))
pp.tidy$prob<- pp.tidy$value/pp.tidy$sum
pp.tidy$expval <- pp.tidy$prob*as.numeric(pp.tidy$prevalence)

pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,
      prevalence_score = sum(expval))

pp.stats<-ddply(pp.stats, .(context,qud), summarise,
      mean = mean(prevalence_score),
      CIlow = quantile(prevalence_score,probs=0.025),
      CIhigh = quantile(prevalence_score,probs=0.975))


pp.stats$context<-factor(pp.stats$context,levels=c('danger','nondistinct','bare'), 
                         labels=c('danger-distinct','nondistinctive','bare'))

asym<-ggplot(data=pp.stats,aes(x=context,y=mean,fill=qud,group=qud))+
  geom_bar(stat='identity',position=position_dodge(0.5),width=0.5)+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
              position=position_dodge(0.5),
              width=.2)+
  scale_fill_brewer(type='qual',palette=1)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,25,50,75,100),limits=c(0,100))+
  #scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))
#  xlab("XX% of lorches have purple feathers")+
#  ylab('proportion of "true" responses')+
 # coord_fixed(100)


grid.arrange(asym,guessing,truthcond,nrow=2)
grid.arrange(arrangeGrob(truthcond,guessing, heights=c(3/4, 1/4), ncol=1),asym, ncol=2)
```





# Experiment 12: implied prevalence with proper randomization

```{r exp12}
setwd("~/Documents/research/generics/cbg2010-replication/data/")
d<-read.table('cbgR-exp12-trials.tsv',header=T)
#write.csv(d,'cbgR-exp12-trials.csv')
d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)

d$stim_type<-factor(d$stim_type,levels=c("danger-distinct","nondistinctive","bare"))

qplot(data=d,x=response,fill=stim_type,geom='histogram')+
  facet_wrap(~stim_type)+
    guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)

```




Check to see if same turkers did Exp 9 and Exp 12? Nope.




# Begin stuff for cogsci paper

```{r cogsci.helpers}
bool.tonum<-function(bool){abs(as.numeric(bool)*1-2)}

bootstrap.ci.ip <- function(x){
  agr = aggregate(imp_subj ~ context, data=x, FUN=mean)
  agr$CILow = aggregate(imp_subj ~ context, data=x, FUN=ci.low)$imp_subj
  agr$CIHigh = aggregate(imp_subj ~ context, data=x, FUN=ci.high)$imp_subj
  agr$YMin = agr$imp_subj - agr$CILow
  agr$YMax = agr$imp_subj + agr$CIHigh
  return(agr)
}

bootstrap.ci.tc <- function(x){
  
  agr = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.low)$truth_num
  agr$CIHigh = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.high)$truth_num
  agr$YMin = agr$truth_num - agr$CILow
  agr$YMax = agr$truth_num + agr$CIHigh
  return(agr)
}
```

## Experiment 1 a & 1 b results

```{r cogsci.fig1}
setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp9-trials.tsv',header=T)

d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)


d$rt <- d$rt/1000
d$truth_conditions <- factor(as.logical(levels(d$response)[d$response]), 
                              levels=c("TRUE","FALSE"))

d$truth_num <- bool.tonum(d$truth_conditions)

d$prev_centered <- scale(d$stim_prevalence, scale=F)
contrasts(d$stim_type) = cbind(quad = c(-1,2,-1), lin = c(-1, 0, 1))
contrasts(d$stim_type) = cbind(dd = c(0,1,0), ni = c(0, 0, 1))


rs<-glmer(truth_num ~ prev_centered*stim_type + 
            (1 + stim_type | workerid) + 
            (1 | item), 
          data=d, family = 'binomial')

summary(rs)



tc.bs<-bootstrap.ci.tc(d)

tc.bs$context<-factor(tc.bs$stim_type,
                        levels=c('danger-distinct','nondistinctive','bare'),
                        labels=c("dangerous &\n distinctive", 
                                 "irrelevant &\n nondistinctive",
                                 "plain"))



fig1a<-ggplot(tc.bs, aes(x=stim_prevalence,y=truth_num,
                  colour=context, group=context))+
  geom_point(size=3, position=position_dodge(5))+
  geom_line(size=0.5,position=position_dodge(5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=context),
              width=5,
              size=0.9,
              position=position_dodge(5))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("prevalence (in %)")+
  ylab('proportion of "true" responses to generic')+
  coord_fixed(100)+
  theme(legend.key.size=unit(2, "lines"),
        legend.text.align=NULL)




```

Experiment 1b: asymmetry

```{r cogsci.fig1b}

setwd("~/Documents/research/generics/cbg2010-replication/data/")
f<-read.table('cbgR-exp12-trials.tsv',header=T)
f$item <- paste(f$stim_color,f$stim_part,sep="_")
table(f$stim_type,f$item)
table(f$stim_type,f$stim_part)

f.tidy <- f %>%
  select(workerid,rt,stim_type,response)%>%
  rename(context=stim_type)

f.stats<-ddply(f.tidy, 
       .(workerid,context), summarise, 
       imp_subj = mean(response),
       context=context[1])
f.stats$task<-'implied'


d.tidy <- d %>%
  select(workerid,rt,stim_type,stim_prevalence,truth_num)%>%
  rename(context=stim_type,
         prevalence=stim_prevalence,
         response=truth_num)

d.stats<-ddply(d.tidy,
      .(workerid,context), summarise,
      imp_subj = sum(prevalence*response)/sum(response),
      context=context[1])
d.stats$workerid <- d.stats$workerid+30
d.stats$task<-'truth'


both.stats<-rbind(f.stats,d.stats)
contrasts(both.stats$context)
both.stats$task<-factor(both.stats$task)
contrasts(both.stats$task)
rs<-lmer(imp_subj ~ context * task + (1 | workerid), data=both.stats)
summary(rs)


f.bs<-bootstrap.ci.ip(f.stats)
f.bs$task<-'impliedprevalence'
d.bs<-bootstrap.ci.ip(d.stats)
d.bs$task<-'truthconditions'

m<-rbind(f.bs,d.bs)

m$context<-factor(m$context,
                        levels=c('danger-distinct','nondistinctive','bare'),
                        labels=c("dangerous \n& distinctive", 
                                 "irrelevant \n& nondistinctive",
                                 "plain"))
m$task <- factor(m$task,
                 levels=c("truthconditions","impliedprevalence"),
                 labels=c("truth conditions", "implied prevalence"))

ggplot(m, aes(x=context,y=imp_subj,fill=context,alpha=task, group=task))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5,color='black')+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5))+
  theme_paper()+
  ylab("average prevalence")+
    scale_fill_brewer(type='qual',palette=6)+
  scale_alpha_manual(values=c(0.4,1))+
 # scale_fill_manual(values=c("#999999","#ef8a62"))+
  xlab("")+
  guides(fill=F)+
  theme(legend.position='bottom',
        legend.direction='horizontal',
        axis.text.x=element_blank())


#grid.arrange(fig1a,asym,nrow=1)

#arrangeGrob(fig1a,asym, widths=c(3/4, 1/4), nrow=1)
```



# TFBT on totally-fixed-threshold, two tasks at once
```{r tfbt.totally.ft.paper}
plotpath = "~/Documents/research/generics/cogsci-2015//paper/figures/"
setwd("~/Documents/research/generics/cbg2010-replication/models/bayesian_analysis")
#d<-read.csv('ft_conditionIP_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
#d<-read.csv('ft_conditionBoth_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
#d<-read.csv('ft_conditionBoth_2phis_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
d<-read.csv('ft_totallyFixed_conditionIndependenly_cnts_expts9_12_generic_mh10000_10_alpha1.csv',header=F)

#ft.phi <- d %>% select(V1) %>% rename(phi=V1)
ft.phi <- d %>% 
  select(V1,V2) %>% 
  rename(phi_tc=V1,phi_ip=V2) %>%
  gather(variable,value) %>% 
  separate(variable,into=c("parameter","task"),by="_")

ft.phi$task<-factor(ft.phi$task,
                    levels=c('tc','ip'),
                    labels=c("truth conditions","implied prevalence"))

#qplot(data=ft.phi,x=phi,geom='density')+xlim(0,1)
a<-ggplot(ft.phi,aes(x=value,alpha=task))+
  geom_density(fill='black')+
  theme_paper()+
  scale_alpha_manual(values=c(0.4,1))+
  scale_x_continuous(breaks=c(0,0.25,.5,0.75,1),limits=c(0,1))+
  scale_fill_brewer(type='qual',palette=1)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal')+
  guides(fill=guide_legend(title="Context"))+
  xlab("phi")



d.tidy <- d %>%
  select(V3,V4) %>%
  rename(theta_tc = V3,
         theta_ip = V4) %>%
  gather(variable,value) %>%
  separate(variable, into=c("parameter","task"))
#qplot(data=d.tidy,x=theta,geom='density')+xlim(0,100)

d.tidy$task<-factor(d.tidy$task,
                    levels=c('tc','ip'),
                    labels=c("truth conditions","implied prevalence"))



b<-ggplot(d.tidy,aes(x=value,alpha=task))+
  geom_density(fill='black')+
  theme_paper()+
  scale_alpha_manual(values=c(0.4,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=1)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal')+
  guides(fill=guide_legend(title="Context"))+
  xlab("generic threshold")

g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

mylegend<-g_legend(b)

p3 <- arrangeGrob(arrangeGrob(a + theme(legend.position="none"),
                         b + theme(legend.position="none"),
                         nrow=1),
             mylegend, nrow=2,heights=c(10, 1))

ggsave(filename=paste(plotpath,'trulyFixed_phis_thetas.png',sep=''),
       plot=p3,
       width=12,
       height=4.5)



```

# TFBT on relaxed but fixed-threshold, two tasks at once

```{r tfbt.ft.paper}

setwd("~/Documents/research/generics/cbg2010-replication/models/bayesian_analysis")
#d<-read.csv('ft_conditionIP_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
#d<-read.csv('ft_conditionBoth_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
d<-read.csv('ft_conditionTC_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
f<-read.csv('ft_conditionIP_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)


ft.phi <- d %>% select(V1) %>% rename(phi_tc=V1)
ft.phi2 <- f %>% select(V2) %>% rename(phi_ip=V2)
ft.phi<-cbind(ft.phi,ft.phi2)

phi.tidy <- ft.phi %>%
  gather(variable,value) %>%
  separate(variable, into=c('parameter','task'), by='_')

phi.tidy$task<-factor(phi.tidy$task,
                    levels=c('tc','ip'),
                    labels=c("truth conditions","implied prevalence"))

a<-ggplot(phi.tidy,aes(x=value,alpha=task))+
  geom_density(fill='black')+
  theme_paper()+
  scale_alpha_manual(values=c(0.4,1))+
  scale_x_continuous(breaks=c(0,0.25,.5,0.75,1),limits=c(0,1))+
  scale_fill_brewer(type='qual',palette=1)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal')+
  guides(fill=guide_legend(title="Context"))+
  xlab(expression(phi))+
  ylab("posterior density")

#ft.phi <- d %>% select(V1,V29) %>% rename(phi_tc=V1,phi_ip=V29) %>%
#  gather(variable,value) %>% separate(variable,into=c("parameter","task"),
#                                      by="_")

#qplot(data=ft.phi,x=phi,geom='density')+xlim(0,1)
#qplot(data=ft.phi,x=value,geom='histogram',fill=task)+xlim(0,1)+facet_wrap(~task)

d.tidy <- d %>%
  select(V3,V4,V5) %>%
  rename(dd_tc = V3,
         ni_tc = V4,
         pl_tc = V5) %>%
  gather(variable,value)

f.tidy <- f %>%
  select(V3,V4,V5) %>%
  rename(dd_ip = V3,
         ni_ip = V4,
         pl_ip = V5) %>%
  gather(variable,value)

theta.tidy<-rbind(d.tidy,f.tidy)

theta.tidy<- theta.tidy %>% 
  separate(variable, into=c("context","task"), by="_")

theta.tidy$task<-factor(theta.tidy$task,
                    levels=c('tc','ip'),
                    labels=c("truth conditions","implied prevalence"))

theta.tidy$context<-factor(theta.tidy$context,
                        levels=c('dd','ni','pl'), 
                        labels=c("dangerous &\n distinctive", 
                                 "irrelevant &\n nondistinctive",
                                 "plain"))

b<-ggplot(theta.tidy,aes(x=value,fill=context,alpha=task))+
  geom_density()+
  theme_paper()+
    scale_alpha_manual(values=c(0.4,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal',
        axis.title.x =       element_text(vjust = -0.5,size=30))+
  guides(fill=guide_legend(title="Context"))+
  xlab(expression(theta))+
  ylab("posterior density")+
  guides(alpha=F)

mylegend<-g_legend(a)

p3 <- arrangeGrob(arrangeGrob(a + theme(legend.position="none"),
                         b,
                         nrow=1),
             mylegend, nrow=2,heights=c(10, 1))

ggsave(filename=paste(plotpath,'fixed_phis_thetas.png',sep=''),
       plot=p3,
       width=12,
       height=4.5)


```

Posterior predictive for truth conditions

```{r postpred.truthcond.ft.paper}

d.tidy <- d %>%
  select(V7,V8, V9, V10,V11,
         V13, V14, V15, V16,V17,
         V19, V20, V21, V22, V23
         ) %>%
  rename(dangerdistinct_10 = V7,
         dangerdistinct_30 = V8,
         dangerdistinct_50 = V9,
         dangerdistinct_70 = V10,
         dangerdistinct_90 = V11,
         nondistinct_10 = V13,
         nondistinct_30 = V14,
         nondistinct_50 = V15,
         nondistinct_70 = V16,
         nondistinct_90 = V17,
         bare_10 = V19,
         bare_30 = V20,
         bare_50 = V21,
         bare_70 = V22,
         bare_90 = V23) %>% 
  gather(evidence, response)%>%
  separate(evidence, into = c("context","prevalence"), sep="_")


d.stats<-ddply(d.tidy, .(context,prevalence), summarise,
      mean = mean(response),
      CIlow=quantile(response,probs=0.025),
      CIhigh=quantile(response,probs=0.975))



d.stats$context<-factor(d.stats$context,
                        levels=c('dangerdistinct','nondistinct','bare'), 
                        labels=c("dangerous &\n distinctive", 
                                 "irrelevant &\n nondistinctive",
                                 "plain"))
d.stats$prevalence<-as.numeric(d.stats$prevalence)

#d.stats[12,4:5]<-c(0.03,0.97)

ggplot(data=d.stats,aes(x=prevalence,y=mean,color=context,group=context))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=1,position=position_dodge(4))+
    geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
               width=10,
               size=0.5,
               position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("prevalence (in %)")+
  ylab('proportion of "true" responses to generic')+
  coord_fixed(100)+
  theme(legend.key.size=unit(2, "lines"),
        legend.text.align=NULL)

```

Posterior predictive for asymmetry

```{r postpred.asymmetry.ft.paper}

pp.tc <- d %>%
  select(V6,V7,V8, V9, V10,
         V12, V13, V14, V15, V16,
         V18, V19, V20, V21, V22
         ) %>%
  rename(dangerdistinct_10 = V6,
         dangerdistinct_30 = V7,
         dangerdistinct_50 = V8,
         dangerdistinct_70 = V9,
         dangerdistinct_90 = V10,
         nondistinct_10 = V12,
         nondistinct_30 = V13,
         nondistinct_50 = V14,
         nondistinct_70 = V15,
         nondistinct_90 = V16,
         bare_10 = V18,
         bare_30 = V19,
         bare_50 = V20,
         bare_70 = V21,
         bare_90 = V22) 


pp.tc$no<-row.names(pp.tc)

pp.tc<- pp.tc %>%
  gather(variable,value, -no) %>%
  separate(variable,into=c('context','prevalence') ,sep="_") 

check.zero <- function(prev,val){
  if (sum(val)==0){
    v = 100
  } else {
    v = sum(prev*val)/sum(val)
  }
  return(v)
}
pp.stats<-ddply(pp.tc, .(no,context), summarise,
                value.tc = check.zero(as.numeric(prevalence),value))
                  

tc.stats<-ddply(pp.stats, .(context), summarise,
      mean = mean(value.tc),
      CIlow = quantile(value.tc,probs=0.025),
      CIhigh = quantile(value.tc,probs=0.975))

tc.stats$task<-'truth'


pp.ip <- d %>%
  select(V25,V26,V27) %>%
  rename(dangerdistinct_implied = V25,
         nondistinct_implied=V26,
         bare_implied=V27 )%>%
  gather(variable,value) %>%
  separate(variable,into=c('context','task') ,sep="_")

ip.stats<-ddply(pp.ip, .(context,task), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))

c.tidy<-rbind(tc.stats,ip.stats)

c.tidy$context<-factor(c.tidy$context,
                        levels=c('dangerdistinct','nondistinct','bare'),
                        labels=c("dangerous \n& distinctive", 
                                 "irrelevant \n& nondistinctive",
                                 "plain"))
c.tidy$task <- factor(c.tidy$task,
                 levels=c("truth","implied"),
                 labels=c("truth conditions", "implied prevalence"))
# 


ggplot(c.tidy, aes(x=context,y=mean,fill=context,alpha=task, group=task))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5,color='black')+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
                width=0.2,
                size=1,
                position=position_dodge(0.5))+
  theme_paper()+
  ylab("average prevalence")+
  ylim(0,100)+
  scale_fill_brewer(type='qual',palette=6)+
  scale_alpha_manual(values=c(0.4,1))+
 # scale_fill_manual(values=c("#999999","#ef8a62"))+
  xlab("")+
  guides(fill=F)+
  theme(legend.position='bottom',
        legend.direction='horizontal',
        axis.text.x=element_blank())

```


# TFBT on lvRSA, streamlined

```{r tfbt.lvRSA.paper}

setwd("~/Documents/research/generics/cbg2010-replication/models/bayesian_analysis")
#d<-read.csv('ft_conditionIP_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
#d<-read.csv('ft_conditionBoth_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
#d<-read.csv('lvRSA_condition2_dscFine_2phis_expts9_12_generic_mh10000_10_alpha1.csv',header=F)

#d<-read.csv('lvRSA_c1_expts9_12_generic_mh10000_100_alpha1.csv',header=F)
#f<-read.csv('lvRSA_c2_expts9_12_generic_mh10000_100_alpha1.csv',header=F)
#d<- read.csv('lvRSA_c1_rds_expts9_12_generic_mh1000_10_alpha1.csv',header=F)
#d<- read.csv('lvRSA_rds_c2_expts9_12_generic_mh5000_10_alpha1.csv',header=F)
#d<- read.csv('lvRSA_rds_c3_expts9_12_generic_mh1000_100_alpha1.csv',header=F)
#d<-read.csv('lvRSA_cnts_expts9_12_generic_mh1000_10_alpha1.csv',header=F)

d<-read.csv('lvRSA_cnts_c1_expts9_12_generic_mh1000_50_alpha1.csv',header=F)
f<-read.csv('lvRSA_cnts_c2_expts9_12_generic_mh1000_50_alpha1.csv',header=F)
g<-read.csv('lvRSA_cnts_c3_expts9_12_generic_mh1000_50_alpha1.csv',header=F)
d<-rbind(d,f,g)


#d<-read.csv('lvRSA_cnts_c1_expts9_12_generic_mh1000_100_alphaPrior.csv',header=F)
#f<-read.csv('lvRSA_cnts_c2_expts9_12_generic_mh1000_100_alphaPrior.csv',header=F)
#g<-read.csv('lvRSA_cnts_c3_expts9_12_generic_mh1000_100_alphaPrior.csv',header=F)
#d<-rbind(d,f,g)


#d<-read.csv('lvRSA_condition2_dscFine_2phis_expts9_12_generic_mh10000_10_alpha1.csv',header=F)
#f<-read.csv('lvRSA_condition2_c2_dscFine_2phis_expts9_12_generic_mh10000_10_alpha1.csv',header=F)


#d<-f
#ft.phi <- d %>% select(V1) %>% rename(phi=V1)
ft.phi <- d %>% select(V1,V2) %>% 
  rename(phi_tc=V1,phi_ip=V2) %>%
  gather(variable,value) %>% 
  separate(variable,into=c("parameter","task"), by="_")

ddply(ft.phi, .(parameter, task), summarise,
      mean=mean(value),
      CIlow=quantile(value,probs=0.025),
      CIhigh=quantile(value,probs=0.975))

#qplot(data=ft.phi,x=phi,geom='density')+xlim(0,1)
qplot(data=ft.phi,x=value,geom='histogram',fill=task)+xlim(0,1)+facet_wrap(~task)



lv.alpha<-d %>% select(V36) %>% rename(alpha=V36)
qplot(data=lv.alpha,x=alpha,geom='histogram')

d.tidy <- d %>%
  select(V3,V4, V6, V7, V9, V10) %>%
  rename(dd_gamma = V3,
         dd_delta = V4,
         ni_gamma = V6,
         ni_delta = V7,
         pl_gamma = V9,
         pl_delta = V10) %>%
  gather(variable,value) %>%
  separate(variable, into=c("context","parameter"), by="_")

params.stats<-ddply(d.tidy, .(context,parameter), summarise,
      mean = mean(value),
      CIlow=quantile(value,probs=0.025),
      CIhigh=quantile(value,probs=0.975))

d.tidy$context<-factor(d.tidy$context,
                        levels=c('dd','ni','pl'), 
                        labels=c("dangerous & distinctive", 
                                 "nondistinctive & irrelevant",
                                 "plain"))

d.tidy$parameter<-factor(d.tidy$parameter, levels=c("gamma","delta"))
                      #   labels(expression(gamma),expression(delta)))

plotpath = "~/Documents/research/generics/cogsci-2015//paper/figures/"


c<-ggplot(d.tidy,aes(x=value,fill=context))+
  geom_density(alpha=0.4)+
  #geom_histogram(binwidth=0.01, alpha = 0.8)+
  theme_paper()+
 scale_x_continuous(limits=c(0,0.5))+
  scale_fill_brewer(type='qual',palette=6)+
  facet_grid(parameter~.,scales='free',labeller= label_parsed)+
  theme(strip.text.x = element_text(size=14,color='black'),
        legend.position='bottom',
        legend.direction='horizontal',
        strip.text.y = element_text(size=22,angle=0))+
  guides(fill=guide_legend(title="Context"))+
  xlab("inferred value")+
  ylab("posterior density")

ggsave(filename=paste(plotpath,'inferred_hyperpriors.png',sep=''),
       plot=c,
       width=8,
       height=6)






discretize_beta<- function(gamma,delta,bins = c(0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99)) {
  s_alpha<- gamma*delta
  s_beta <- (1 - gamma) * delta
  beta_pdf<- function(x){
    return((x^(s_alpha-1))*((1-x)^(s_beta-1)))
  }
  return(sapply(bins,beta_pdf))
}

bns<-c(0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99)

d.tidy <- d %>%
  select(V3,V4, V6, V7, V9, V10) %>%
  rename(dd_gamma = V3,
         dd_delta = V4,
         ni_gamma = V6,
         ni_delta = V7,
         pl_gamma = V9,
         pl_delta = V10)

d.tidy$s<- row.names(d.tidy)

d.tidy<- d.tidy %>% gather(variable,value,-s) %>% 
  separate(variable, into=c("parameter","context"), by="_") %>% 
  spread(context,value)

x = with(d.tidy, discretize_beta(gamma, delta))
colnames(x) <- bns
d.tidy2 <- cbind(d.tidy, x)

d.tidy3<-d.tidy2 %>% 
  rename(context=parameter) %>%
  gather(bin, prob, -s, -parameter, -delta, -gamma)

db.stats<- d.tidy3 %>% 
  ddply(.(parameter, bin),summarise,
        mean=mean(prob),
      CIlow=quantile(prob,probs=0.025),
      CIhigh=quantile(prob,probs=0.975))

db.norm <- data.frame(
  dd_mean = with(subset(db.stats, parameter=='dd'), mean / sum(mean)),
  ni_mean = with(subset(db.stats, parameter=='ni'), mean / sum(mean)),
  pl_mean = with(subset(db.stats, parameter=='pl'), mean / sum(mean)),
  dd_CIlow = with(subset(db.stats, parameter=='dd'), CIlow / sum(CIlow)),
  ni_CIlow = with(subset(db.stats, parameter=='ni'), CIlow / sum(CIlow)),
  pl_CIlow = with(subset(db.stats, parameter=='pl'), CIlow / sum(CIlow)),
  dd_CIhigh = with(subset(db.stats, parameter=='dd'),  CIhigh / sum(CIhigh)),
  ni_CIhigh = with(subset(db.stats, parameter=='ni'), CIhigh / sum(CIhigh)),
  pl_CIhigh = with(subset(db.stats, parameter=='pl'), CIhigh / sum(CIhigh)))

db.norm$bin <- to.n(bns)

db.norm.tidy <- db.norm %>%
  gather(variable,value,-bin) %>%
  separate(variable,into=c('context','statistic'), by ="_")%>%
  spread(statistic, value)

a<-ggplot(db.norm.tidy,aes(x=100*bin,y=mean,fill=context))+
  geom_bar(stat='identity',position=position_dodge())+
  #xlim(0,100)+
  facet_wrap(~context)+
  guides(fill=F)+
  scale_x_continuous(breaks=c(0,20,40,60,80,100))+
  scale_fill_brewer(type='qual',palette=6)+
  xlab("prevalence level")+
  ylab("inferred prior probability")+
  theme(strip.background = element_blank(),
       strip.text.x = element_blank(),
        legend.position='bottom',
        legend.direction='horizontal')

ggsave(filename=paste(plotpath,'inferred_marginalized_priors.png',sep=''),
       plot=a,
       width=12,
       height=4.5)


#prob = subset(db.norm.tidy,context=='pl')$mean[c(1,11,2,3,4,5,6,7,8,9,10)],

mosquitos.prior<- data.frame(bin = to.n(bns),
                             prob = c(0.53,0.22,0.0058,0.0032,0.0024,0.0020,0.0018,0.0018,0.002,0.002,0.0032),
                            context = 'mosquito')

accidental.prior<- data.frame(bin = to.n(bns),
                             prob = discretize_beta(0.4,3),
                            context = 'accidental')
mosquitos.prior$prob<-mosquitos.prior$prob/sum(mosquitos.prior$prob)
accidental.prior$prob<-accidental.prior$prob/sum(accidental.prior$prob)

schematic.priors<-rbind(mosquitos.prior,accidental.prior)


a<-ggplot(schematic.priors,aes(x=100*bin,y=prob,fill=context))+
  geom_bar(stat='identity',position=position_dodge())+
  #xlim(0,100)+
#  facet_wrap(~context)+
 # guides(fill=F)+
  scale_x_continuous(breaks=c(0,20,40,60,80,100))+
  scale_fill_manual(values=c('#984ea3','#ff7f00'))+
  xlab("prevalence level")+
  ylab("schematic prior probability")+
  theme(strip.background = element_blank(),
       strip.text.x = element_blank(),
        legend.position='bottom',
        legend.direction='horizontal')


ggsave(filename=paste(plotpath,'schematic_priors.png',sep=''),
       plot=a,
       width=5,
       height=5)
```


Simulations of theoretical interest (e.g. mosquitos carry west niel virus)

```{r mosqutios}
accidental<-data.frame(tasks = c('tc','ip'),
          prevalence = c(63.41008611540007,50.05101669894225))


accidental$tasks<-factor(accidental$tasks, levels=c('tc','ip'),
                         labels=c('truth conditions','implied prevalence'))

ggplot(accidental,aes(x=tasks,y=prevalence,alpha=tasks))+
  geom_bar(stat='identity',width=0.5,position=position_dodge(), fill='#ff7f00')+
  scale_alpha_manual(values=c(0.4,1))+
    ylab("average prevalence")+
  ylim(0,100)+
  xlab("")+
  guides(alpha=guide_legend(order=2))+
  theme(legend.position='bottom',
        legend.direction='horizontal',
        legend.box= 'horizontal',
        axis.text.x=element_blank())


mosquitos<- data.frame(prevalence=c(10,30,50,70,90),
                       response = c(0.5961676991787926,0.7974369474622407,0.898555969744128,0.9593832867224066,1))

ggplot(data=mosquitos,aes(x=prevalence,y=response))+
    geom_point(size=3, color='#984ea3')+
  geom_line(size=0.5,color='#984ea3',position=position_dodge(4))+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
 # guides(color=guide_legend(title="Context"))+
  xlab("prevalence (in %)")+
  ylab('proportion of "true" responses to generic')+
  coord_fixed(100)+
  theme(legend.key.size=unit(2, "lines"),
        legend.text.align=NULL)
```

Reconstructing the prior using the mean infered parameter

```{r meaninferredpriorreconstruction}
### mean inferred prior

discreet_beta<-data.frame( vals = bns,
  dd=discretize_beta(params.stats[2,3],params.stats[1,3], bns),
  ni=discretize_beta(params.stats[4,3],params.stats[3,3], bns),
  pl=discretize_beta(params.stats[6,3],params.stats[5,3],bns))

discreet_beta$dd_n <- discreet_beta$dd / sum(discreet_beta$dd)
discreet_beta$ni_n <- discreet_beta$ni / sum(discreet_beta$ni)
discreet_beta$pl_n <- discreet_beta$pl / sum(discreet_beta$pl)

db.tidy<- discreet_beta %>% 
  select(vals,dd_n,ni_n,pl_n) %>%
    gather(key,probs, -vals)

db.tidy$context<-factor(db.tidy$key,levels=c('dd_n','ni_n','pl_n'), 
                        labels=c("dangerous & distinctive", 
                                 "irrelevant & nondistinctive",
                                 "plain"))
experiment2.data<-normedexp2 %>% rename(dd_n=dd,ni_n=ni,pl_n=pl)%>%
  gather(key,elicited,-prevalence)

experiment2.data[experiment2.data$prevalence==0,"prevalence"]<- 1
experiment2.data[experiment2.data$prevalence==100,"prevalence"]<- 99
experiment2.data$vals = as.numeric(experiment2.data$prevalence)/100

exp2.modeldata<-merge(experiment2.data,db.tidy, by=c("key","vals"))
qplot(data=exp2.modeldata,x=probs,y=elicited,geom='point')
with(exp2.modeldata,cor(probs,elicited))

a<-ggplot(db.tidy,aes(x=100*vals,y=probs,fill=context))+
  geom_bar(stat='identity',position=position_dodge())+
  #xlim(0,100)+
  facet_wrap(~context)+
  guides(fill=F)+
  scale_x_continuous(breaks=c(0,20,40,60,80,100))+
  scale_fill_brewer(type='qual',palette=6)+
  xlab("prevalence level")+
  ylab("inferred prior probability")+
  theme(strip.background = element_blank(),
       strip.text.x = element_blank(),
        legend.position='bottom',
        legend.direction='horizontal')

plotpath = "~/Documents/research/generics/cogsci-2015//paper/figures/"


ggsave(filename=paste(plotpath,'inferred_mean_priors.png',sep=''),
       plot=a,
       width=12,
       height=4.5)

```


Posterior predictive for truth conditions

```{r postpred.truthcond.lvRSA.paper}

d.tidy <- d %>%
  select(V13, V14, V15, V16, V17,
         V19, V20, V21, V22, V23,
         V25, V26, V27, V28, V29) %>%
  rename(dd_10 = V13,
         dd_30 = V14,
         dd_50 = V15,
         dd_70 = V16,
         dd_90 = V17,
         ni_10 = V19,
         ni_30 = V20,
         ni_50 = V21,
         ni_70 = V22,
         ni_90 = V23,
         pl_10 = V25,
         pl_30 = V26,
         pl_50 = V27,
         pl_70 = V28,
         pl_90 = V29) %>% 
  gather(evidence, response)%>%
  separate(evidence, into = c("context","prevalence"), sep="_")


d.stats<-ddply(d.tidy, .(context,prevalence), summarise,
      mean = mean(response),
      CIlow=quantile(response,probs=0.025),
      CIhigh=quantile(response,probs=0.975))



d.stats$context<-factor(d.stats$context,
                        levels=c('dd','ni','pl'), 
                        labels=c("dangerous &\n distinctive", 
                                 "irrelevant &\n nondistinctive",
                                 "plain"))
d.stats$prevalence<-as.numeric(d.stats$prevalence)

## append mosquitos
mosquitos<-rename(mosquitos, mean=response)
mosquitos$context <- 'mosquitos'
mosquitos$CIlow<-mosquitos$mean
mosquitos$CIhigh<-mosquitos$mean

d.stats<-rbind(d.stats,mosquitos)
####
#d.stats[12,4:5]<-c(0.03,0.97)

a<-ggplot(data=d.stats,aes(x=prevalence,y=mean,color=context,group=context))+
    geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh,colour=context),
              width=3,
              size=0.9,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("prevalence (in %)")+
  ylab('proportion of "true" responses to generic')+
  coord_fixed(100)+
  theme(legend.key.size=unit(2, "lines"),
        legend.text.align=NULL)


# scatterplot

h.tidy<-tc.bs %>% select(stim_prevalence,stim_type,truth_num,YMin,YMax) %>%
  rename(prevalence=stim_prevalence,
         context=stim_type,
         response = truth_num,
         CIlow=YMin,
         CIhigh=YMax)

h.tidy$context<-factor(h.tidy$context,
                        levels=c("danger-distinct", 
                                 "nondistinctive",
                                 "bare"),
                        labels=c("dangerous &\n distinctive", 
                                 "irrelevant &\n nondistinctive",
                                 "plain"))

mgd<- merge(h.tidy, d.stats, by=c("context","prevalence"))

with(mgd, cor(response,mean))

ggplot(data=mgd, aes(x=mean,y=response,color=context))+
  geom_point(size=3)+
 geom_errorbarh(aes(y=response,xmin=CIlow.y,xmax=CIhigh.y),
             height=0.04,
             size=0.5)+
   geom_errorbar(aes(r=response,ymin=CIlow.x,ymax=CIhigh.x),
             width=0.04,
             size=0.5)+
    geom_abline(intercept=0,slope=1,linetype=3)+
    scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1.05))+
    scale_x_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1.05))+
  guides(color=guide_legend(title="Context"))+
  xlab("model posterior predictive")+
  ylab('truth conditions (Exp. 1a) data')+
  coord_fixed(1)+
    scale_colour_brewer(type='qual',palette=6)


```

lvRSA Post pred on asymmetry (clean)

```{r postpred.asym.lvrsa}

d.tidy <- d %>%
  select(V13, V14, V15, V16, V17,
         V19, V20, V21, V22, V23,
         V25, V26, V27, V28, V29) %>%
  rename(dd_10 = V13,
         dd_30 = V14,
         dd_50 = V15,
         dd_70 = V16,
         dd_90 = V17,
         ni_10 = V19,
         ni_30 = V20,
         ni_50 = V21,
         ni_70 = V22,
         ni_90 = V23,
         pl_10 = V25,
         pl_30 = V26,
         pl_50 = V27,
         pl_70 = V28,
         pl_90 = V29) 

d.tidy$no<-row.names(d.tidy)

d.tidy <- d.tidy %>%
  gather(variable,value, -no) %>%
  separate(variable,into=c('context','prevalence') ,sep="_") 

check.zero <- function(prev,val){
  if (sum(val)==0){
    v = 100
  } else {
    v = sum(prev*val)/sum(val)
  }
  return(v)
}

pp.stats<-ddply(d.tidy, .(no,context), summarise,
                value.tc = check.zero(as.numeric(prevalence),value))
                  

tc.stats<-ddply(pp.stats, .(context), summarise,
      mean = mean(value.tc),
      CIlow = quantile(value.tc,probs=0.025),
      CIhigh = quantile(value.tc,probs=0.975))

tc.stats$task<-'truth'


pp.ip <- d %>%
  select(V32,V33,V34) %>%
  rename(dd_implied = V32,
         ni_implied=V33,
         pl_implied=V34 )%>%
  gather(variable,value) %>%
  separate(variable,into=c('context','task') ,sep="_")

ip.stats<-ddply(pp.ip, .(context,task), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))

c.tidy<-rbind(tc.stats,ip.stats)

c.tidy$context<-factor(c.tidy$context,
                        levels=c('dd','ni','pl'),
                        labels=c("dangerous \n& distinctive", 
                                 "irrelevant \n& nondistinctive",
                                 "plain"))
c.tidy$task <- factor(c.tidy$task,
                 levels=c("truth","implied"),
                 labels=c("truth conditions", "implied prevalence"))
# 
### append accidental simluation
accidental<-rename(accidental, task=tasks, mean=prevalence)
accidental$CIlow<-accidental$mean
accidental$CIhigh<-accidental$mean
accidental$context<-'accidental'

c.tidy<-rbind(c.tidy,accidental)
c.tidy$context<-factor(c.tidy$context, 
                       levels=c("dangerous \n& distinctive",'irrelevant \n& nondistinctive',
                                'plain','mosquito','accidental'))


b<-ggplot(c.tidy, aes(x=context,y=mean,fill=context,alpha=task, group=task))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5,color='black')+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
                width=0.2,
                size=1,
                position=position_dodge(0.5))+
  theme_paper()+
  ylab("average prevalence")+
  ylim(0,100)+
  scale_fill_brewer(type='qual',palette=6, drop=F)+
  scale_alpha_manual(values=c(0.4,1))+
  #scale_fill_manual(values=c("#e41a1c","#377eb8",'#4daf4a','#984ea3','#ff7f00'),
  #                  breaks=c("dangerous \n& distinctive",'irrelevant \n& nondistinctive',
  #                              'plain','mosquitos','accidental'),
  #                  labels=c("dangerous \n& distinctive",'irrelevant \n& nondistinctive',
  #                              'plain','mosquitos','accidental'))+
  xlab("")+
  guides(fill=guide_legend(order=1),
         alpha=guide_legend(order=2))+
  theme(legend.position='bottom',
        legend.direction='horizontal',
        legend.box= 'horizontal',
        axis.text.x=element_blank())

mylegend<-g_legend(b)

p3 <- arrangeGrob(arrangeGrob(a + theme(legend.position="none"),
                         b + theme(legend.position='none'),
                         nrow=1),
             mylegend, nrow=2,heights=c(10, 1))

ggsave(filename=paste(plotpath,'lvRSA_postpreds_wSims.png',sep=''),
       plot=p3,
       width=14,
       height=6)



# scatter plot


```




# TFBT on lvRSA, 2 ways

```{r tfbt.lvRSA.paper}
#setwd('../models/bayesian_analysis/')

d<-read.csv('lvRSAemp_condition2_expts9_12_generic_mh1000_100_alpha1.csv',
  header=F)

phi.tidy <- d %>% select(V1,V192) %>% 
  rename(phi_truthconditions=V1,
         phi_impliedprevalence=V192) %>%
      gather(variable,value) %>%
    separate(variable,into=c("parameter","task"),sep="_")


ggplot(phi.tidy,aes(x=value,fill=task))+
  geom_density(alpha=0.8)+
  theme_paper()+
  facet_wrap(~task)+
  xlab("phi")+
  xlim(0,1)

params.tidy <- d %>%
  select(V2,V3,V5,V6,V8,V9) %>%
  rename(dangerdistinct_gamma = V2,
         dangerdistinct_delta = V3,
         nondistinct_gamma = V5,
         nondistinct_delta = V6,
         bare_gamma=V8,
         bare_delta=V9) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

params.tidy$variable<-factor(params.tidy$variable,levels=c("gamma","delta"))
params.tidy$context<-factor(params.tidy$context,
                            levels=c("dangerdistinct","nondistinct","bare"))

ggplot(params.tidy,aes(x=value,fill=context))+
   geom_histogram(alpha=0.8)+
  facet_grid(context~variable,scale='free')+
  theme_paper()+
  guides(fill=F)+
  xlab("inferred parameter value")+
  scale_fill_brewer(type='qual',palette=6)




params.stats<-ddply(params.tidy, .(context,variable), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))




discretize_beta<- function(gamma,delta,bins){
  s_alpha<- gamma*delta
  s_beta <- (1 - gamma) * delta
  beta_pdf<- function(x){
    return((x^(s_alpha-1))*((1-x)^(s_beta-1)))
  }
  return(sapply(bins,beta_pdf))
}

bns<-c(0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99)


discreet_beta<-data.frame(probs = discretize_beta(0.1,0.01,bns),
                    vals = bns)

discreet_beta$normed_probs <- discreet_beta$probs / sum(discreet_beta$probs)

ggplot(discreet_beta,aes(x=100*vals,y=normed_probs))+
  #geom_density()+
#  geom_histogram()+
  geom_bar(stat='identity')+
  xlim(0,100)+
#  facet_wrap(~variable)+
#  guides(fill=F)+
#  scale_fill_brewer(type='qual',palette=6)+
  xlab("mean inferred prior distribution, from RSA and exp1 & imp-prev exp")

```


Posterior predictives
```{r pp.lvrsa.paper}
pp.tidy<- d %>%
  select(V15,V22,V29,V36,V43,
         V51,V58,V65,V72,V79,
         V87,V94,V101,V108,V115) %>%
  rename(danger_truth_10= V15,
         danger_truth_30= V22,
         danger_truth_50 = V29,
         danger_truth_70 = V36,
         danger_truth_90 = V43,
         nondistinct_truth_10 = V51,
         nondistinct_truth_30 = V58,
         nondistinct_truth_50 = V65,
         nondistinct_truth_70 = V72,
         nondistinct_truth_90 = V79,
         bare_truth_10 = V87,
         bare_truth_30= V94,
         bare_truth_50 = V101,
         bare_truth_70 = V108,
         bare_truth_90 = V115) %>%
    gather(variable,value) %>%
   separate(variable,into=c('context','qud','prevalence') ,sep="_")


pp.stats<-ddply(pp.tidy, .(context,prevalence), summarise,
      mean = mean(value),
      CIlow = quantile(value,probs=0.025),
      CIhigh = quantile(value,probs=0.975))


#m<-merge(pp.stats,tc.bs, by=c("context", "prevalence"))
#with(m, cor(truth_num,mean))
pp.stats$context<-factor(pp.stats$context,
                         levels=c('danger','nondistinct','bare'), 
                         labels=c('danger-distinct','nondistinctive','bare'))
pp.stats$prevalence<-as.numeric(pp.stats$prevalence)

ggplot(data=pp.stats,aes(x=prevalence,y=mean,color=context,group=context))+
  geom_point(size=3, position=position_dodge(4))+
  geom_line(size=0.5,position=position_dodge(4))+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh,colour=context),
              width=5,
              size=0.8,
              position=position_dodge(4))+
  scale_colour_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("prevalence")+
  ylab('proportion of "true" responses')+
  coord_fixed(100)+
  ggtitle("lifted variable RSA model")
```


Asymmetry

```{r pp.asym.lvrsa}


pp.tidy<- d %>%
  select(V15,V22,V29,V36,V43,
         V51,V58,V65,V72,V79,
         V87,V94,V101,V108,V115,
         V132,V133,V134,V135,V136,V137,V138,V139,V140,V141,
         V155,V156,V157,V158,V159,V160,V161,V162,V163,V164,
         V178,V179,V180,V181,V182,V183,V184,V185,V186,V187) %>%
  rename(danger_truth_10= V15,
         danger_truth_30= V22,
         danger_truth_50 = V29,
         danger_truth_70 = V36,
         danger_truth_90 = V43,
         nondistinct_truth_10 = V51,
         nondistinct_truth_30 = V58,
         nondistinct_truth_50 = V65,
         nondistinct_truth_70 = V72,
         nondistinct_truth_90 = V79,
         bare_truth_10 = V87,
         bare_truth_30= V94,
         bare_truth_50 = V101,
         bare_truth_70 = V108,
         bare_truth_90 = V115,
         danger_implied_10=V132,
         danger_implied_20=V133,
         danger_implied_30=V134,
         danger_implied_40=V135,
         danger_implied_50=V136,
         danger_implied_60=V137,
         danger_implied_70=V138,
         danger_implied_80=V139,
         danger_implied_90=V140,
         danger_implied_100=V141,         
         nondistinct_implied_10 = V155,
         nondistinct_implied_20 = V156,
         nondistinct_implied_30 = V157,
         nondistinct_implied_40 = V158,
         nondistinct_implied_50 = V159,
         nondistinct_implied_60 = V160,
         nondistinct_implied_70 = V161,
         nondistinct_implied_80 = V162,
         nondistinct_implied_90 = V163,
         nondistinct_implied_100 = V164,
         bare_implied_10 = V178,
         bare_implied_20 = V179,
        bare_implied_30 = V180,
        bare_implied_40 = V181,
        bare_implied_50 = V182,
        bare_implied_60 = V183,
        bare_implied_70 = V184,
        bare_implied_80 = V185,
        bare_implied_90 = V186,
        bare_implied_100 = V187        
        )


pp.tidy$no<-row.names(pp.tidy)

pp.tidy<- pp.tidy %>%
  gather(variable,value, -no) %>%
  separate(variable,into=c('context','qud','prevalence') ,sep="_") 


pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,sum(value))

pp.tidy<-merge(pp.stats,pp.tidy, by=c("no",'context','qud'))
pp.tidy$prob<- pp.tidy$value/pp.tidy$sum
pp.tidy$expval <- pp.tidy$prob*as.numeric(pp.tidy$prevalence)

pp.stats<-ddply(pp.tidy, .(no,context,qud), summarise,
      prevalence_score = sum(expval))

pp.stats<-ddply(pp.stats, .(context,qud), summarise,
      median = median(prevalence_score),
      CIlow = quantile(prevalence_score,probs=0.025),
      CIhigh = quantile(prevalence_score,probs=0.975))


pp.stats$context<-factor(pp.stats$context,levels=c('danger','nondistinct','bare'), 
                         labels=c('danger-distinct','nondistinctive','bare'))

ggplot(data=pp.stats,aes(x=context,y=median,fill=qud,group=qud))+
  geom_bar(stat='identity',position=position_dodge(0.5),width=0.5)+
  geom_errorbar(aes(ymin=CIlow,ymax=CIhigh),
              position=position_dodge(0.5),
              width=.2)+
  scale_fill_brewer(type='qual',palette=6)+
  #theme(strip.text.x = element_text(size=14,color='black'))+
 ## scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  #scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  theme_paper()+ 
  guides(color=guide_legend(title="Context"))

```


