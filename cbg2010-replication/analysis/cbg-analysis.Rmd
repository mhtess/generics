---
title: "cgb2010-replication"
author: "mht"
date: "December 2, 2014"
output: html_document
---


Merge data sets for 2 experiments into a single .csv

```{r datamerge, echo=FALSE}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
d1<-read.table('cbgR-exp1_anonymized-trials.tsv',header=T)
#d2<-read.table('cbgR-exp2_anonymized-trials.tsv',header=T)
d3<-read.table('cbgR-exp3_anonymized-trials.tsv',header=T)

#d2$workerid<-d2$workerid+length(levels(factor(d1$workerid)))
#d3$workerid<-d3$workerid+length(levels(factor(d2$workerid)))+length(levels(factor(d1$workerid)))
d3$workerid<-d3$workerid+length(levels(factor(d1$workerid)))

all.experiments<-rbind(d1,d3)

#write.csv(all.experiments, file='cbgR-exp1_exp3_anonymized-trials.csv')
#write.csv(td1, file='cbgR-exp3_anonymized-trials.csv')

```

# Experiment 1: CBG (2010) Experiments 1 and 2

### Experimental conditions


+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False
+ **implied prevalence** = given a sentence (*generic*, *most*, *some*), answer with the percentage of *warfles that have purple feathers*


```{r exp1}
library(ggplot2)
library(plyr)
library(reshape2)
library(ggthemes)
library(gridExtra)
library(bootstrap)
library(lme4)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}

bool.tonum<-function(bool){abs(as.numeric(bool)*1-2)}
bootstrap.ci <- function(x){
  agr = aggregate(subj_prevalence ~ trial_type + stim_determiner, data=x, FUN=mean)
  agr$CILow = aggregate(subj_prevalence ~ trial_type + stim_determiner, data=x, FUN=ci.low)$subj_prevalence
  agr$CIHigh = aggregate(subj_prevalence ~ trial_type + stim_determiner, data=x, FUN=ci.high)$subj_prevalence
  agr$YMin = agr$subj_prevalence - agr$CILow
  agr$YMax = agr$subj_prevalence + agr$CIHigh
  return(agr)
}

bootstrap.ci.tc <- function(x){
  
  agr = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.low)$truth_num
  agr$CIHigh = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.high)$truth_num
  agr$YMin = agr$truth_num - agr$CILow
  agr$YMax = agr$truth_num + agr$CIHigh
  return(agr)
}



setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
turk.data<-read.table('cbgR-exp1_anonymized-trials.tsv',header=T)

turk.data$implied_prevalence <- as.numeric(levels(turk.data$response)[turk.data$response])
turk.data$truth_conditions <- factor(as.logical(levels(turk.data$response)[turk.data$response]), levels=c("TRUE","FALSE"))
turk.data$stim_prevalence <- factor(turk.data$stim_prevalence)
```

Some frequentists inferential statistics
```{r}

truth.conds<- subset(turk.data, trial_type=='truth_conditions')
truth.conds$truth_num <-bool.tonum(truth.conds$truth_conditions)
results<-glmer(truth_num ~ stim_prevalence*stim_determiner + (1 | workerid), data=truth.conds, family='binomial')
summary(results)

summary(aov(truth_num~(stim_prevalence*stim_determiner)+Error(workerid/(stim_prevalence*stim_determiner)),
    data=truth.conds))
```


Number of responses for each prevalence level (for truth conditions task)
```{r resp1Atab, echo=FALSE}
table(turk.data[,c("stim_determiner","stim_prevalence")])
```

Number of responses for implied prevalence task.
```{r resp2Btab, echo=FALSE}
table(subset(turk.data,trial_type=='implied_prevalence')[,c("stim_determiner")])
```


```{r anova1}
df<-ddply(subset(turk.data,trial_type=='truth_conditions' & truth_conditions==TRUE), 
      .(stim_prevalence, stim_determiner), summarise,
      count = sum(as.numeric(truth_conditions))

df<-rbind(df,c(10,'most',0))
df$count<-to.n(df$count)
```

Plot *implied prevalence* (top) and proportion of "true" responses at each stated prevalence level (bottom, replicated figure 3 from CGB 2010)

```{r}
df<-ddply(subset(turk.data,trial_type=='truth_conditions'), 
      .(stim_determiner, stim_prevalence), summarise, 
      true_responses= table(truth_conditions)[["TRUE"]]/length(truth_conditions))

a<-ggplot(subset(turk.data,trial_type=='implied_prevalence'),aes(x=implied_prevalence,fill=stim_determiner))+
  geom_density(alpha=.5)+
  facet_wrap(~stim_determiner)+
  theme_bw()+
  guides(fill=F)

b<-ggplot(df, aes(x=stim_prevalence,y=true_responses,colour=stim_determiner, group=stim_determiner))+
  geom_line(size=1)+
  facet_wrap(~stim_determiner)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  guides(colour=F)

grid.arrange(a,b)
```

Replicate figure 2 of CGB 2010 *asymmetry of truth_conditions and implied_prevalence*
```{r}


turk.data$stim_prevalence <- as.numeric(levels(turk.data$stim_prevalence)[turk.data$stim_prevalence])

df2<-ddply(subset(turk.data, truth_conditions%in%c("TRUE",NA)), 
       .(trial_type, stim_determiner, workerid), summarise, 
       subj_prevalence = mean(implied_prevalence),
       subj_truth_prevalence = mean(stim_prevalence))

df2$subj_prevalence[is.na(df2$subj_prevalence)] <- df2$subj_truth_prevalence[!is.na(df2$subj_truth_prevalence)]
df2.bs<-bootstrap.ci(df2)
df2.bs$trial_type <- factor(df2.bs$trial_type, levels=c("truth_conditions","implied_prevalence"))

ggplot(df2.bs, aes(x=stim_determiner,y=subj_prevalence,fill=trial_type, group=trial_type))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5)+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5),
                colour='black')+
  theme_bw()+
  ylab("average prevalence")+
  scale_fill_brewer(type='qual',palette=1)

```

Replicate figure 3 with CIs

```{r}

tc<-subset(turk.data,trial_type=='truth_conditions')
tc$truth_num <- 1*as.logical(tc$truth_conditions)

tc.bs<-bootstrap.ci.tc(tc[tc$trialNum<15,])
tc.bs<-bootstrap.ci.tc(tc[tc$trialNum>=15,])


tc.bs<-bootstrap.ci.tc(tc)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_determiner, group=stim_determiner))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_line()+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_determiner),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =element_text(size=14,color='black'))+
  guides(colour=F)

```


# Experiment 2 -- prior elicitation 2 ways

### Experimental conditions

**implied prevalence** only, with no quantifier sentence

+ **catprop** - subjects were given evidence that the category and the property were relevant ("recently discovered"); also the cover story was elaborated (you are a zoologist)
+ **plain** is the CBG paradigm without the quantifier/generic sentence for evidence (bare bones)


```{r exp2}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
turk.data<-read.table('cbgR-exp2_anonymized-trials.tsv',header=T)
summary(turk.data)
```


Reaction time histograms

```{r}
ggplot(turk.data,aes(x=rt/60000,fill=trial_prompt))+
  geom_histogram()+
  facet_wrap(~trial_prompt)+
  guides(fill=F)+
  xlab('rt in minutes')+
  theme_bw()
```


Prevalence histograms / densities, broken up by cover story (catprop vs plain)

```{r}
ggplot(turk.data,aes(x=response,fill=trial_prompt))+
  geom_histogram(binwidth=5, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_density()+
  facet_wrap(~trial_prompt)+
  guides(fill=F)+
  theme_bw()
```

Prevalence histograms / densities, collapsed across cover stories

```{r}
ggplot(turk.data,aes(x=response))+
  geom_histogram(binwidth=5, fill='blue', aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_density()+
  guides(fill=F)+
  theme_bw()
```

Histograms by subject, for each condition separately

```{r}
ggplot(subset(turk.data, trial_prompt=='catprop'),
       aes(x=response))+
  geom_histogram(binwidth=10,fill='blue')+
  facet_wrap(~workerid)+
  guides(fill=F)+
  scale_x_continuous(limits=c(0,110),breaks=c(0,25,50,75,100))+
  theme_bw()

ggplot(subset(turk.data, trial_prompt=='plain'),
       aes(x=response))+
  geom_histogram(binwidth=10,fill='red')+
  facet_wrap(~workerid)+
  guides(fill=F)+
  scale_x_continuous(limits=c(0,110),breaks=c(0,25,50,75,100))+
  theme_bw()
```

Average prior prevalence

```{r}

bootstrap.ci <- function(x){
  agr = aggregate(value ~ trial_prompt, data=x, FUN=mean)
  agr$CILow = aggregate(value ~ trial_prompt, data=x, FUN=ci.low)$value
  agr$CIHigh = aggregate(value ~ trial_prompt, data=x, FUN=ci.high)$value
  agr$YMin = agr$value - agr$CILow
  agr$YMax = agr$value + agr$CIHigh
  return(agr)
}
df.m<- melt(turk.data[,c("trial_prompt","response")],id.vars='trial_prompt')
df.b<-bootstrap.ci(df.m)

ggplot(df.b,aes(x=trial_prompt,y=value,fill=trial_prompt))+
  geom_bar(stat='identity',position=position_dodge(),width=0.4)+
    geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.1,
                size=1,
                position=position_dodge(0.5),
                colour='white')+
  guides(fill=F)+
  ylim(0,100)+
  theme_bw()
```


# Experiment 3 -- replicate experiment 4 of CBG

The idea now is to see if the generic theta differs across contexts, thus motivating a lifted variable model from a bayesian data analysis standpoint.

+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False
+ **implied prevalence** = given a sentence (*generic*, *most*, *some*), answer with the percentage of *warfles that have purple feathers*

The sentence is between subjects (subjects see only generics or mosts or somes).

Within-subject is the context:

+ **dangerous**
+ **distinctive**
+ **extra irrelevant**
+ **bare** (from experiment 1, above)

```{r exp3}

library(ggthemes)


setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
td0<-read.table('cbgR-exp1_anonymized-trials.tsv',header=T)

#td0$trialNum<-(1+as.numeric(rownames(td0))) %% 30
#write.csv(td0, file='cbgR-exp1_anonymized-trials.csv')
td1<-read.table('cbgR-exp3_anonymized-trials.tsv',header=T)
#td1$trialNum<-(1+as.numeric(rownames(td1))) %% 30
#write.csv(td1, file='cbgR-exp3_anonymized-trials.csv')
td1$item<-paste(td1$stim_color,td1$stim_part,sep='_')
#levels(factor(subset(td1,stim_type=='danger')$item))

td1$workerid<-td1$workerid+length(levels(factor(td0$workerid)))
td<-rbind(td0,td1)
td$workerid <- factor(td$workerid)
td$rt <- td$rt/1000
td$stim_prevalence <- factor(td$stim_prevalence)


td$implied_prevalence <- to.n(td$response)
td$truth_conditions <- factor(as.logical(levels(td$response)[td$response]), 
                              levels=c("TRUE","FALSE"))

```
Number of responses for each prevalence level (for truth conditions task)
```{r, echo=FALSE}
table(td1[,c("stim_determiner","stim_prevalence")])/6
```

Number of responses for implied prevalence task.
```{r, echo=FALSE}
table(subset(td1,trial_type=='implied_prevalence')[,c("stim_determiner")])/30
```



```{r}
df<-ddply(subset(td,trial_type=='truth_conditions'), 
      .(stim_determiner, stim_prevalence, stim_type), summarise, 
      true_responses= table(truth_conditions)[["TRUE"]]/length(truth_conditions))


a<-ggplot(subset(td,trial_type=='implied_prevalence'),
          aes(x=implied_prevalence,fill=stim_type))+
  geom_histogram(aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]),binwidth=10)+
  facet_grid(stim_type~stim_determiner)+
  theme_bw()+
  guides(fill=F)+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'),
        strip.text.y =       element_text(size=14,color='black'))

b<-ggplot(df, aes(x=stim_prevalence,y=true_responses,colour=stim_type, 
                  group=stim_determiner))+
  geom_line(size=1,alpha=0.90)+
  facet_grid(stim_type~stim_determiner)+
  theme_bw()+
  ylab("proportion of 'true' responses")

grid.arrange(a,b)
```

Replicate figure 3 from CGB 2010 (w CIs)

```{r exp3fig3}

bootstrap.ci.tc <- function(x){
  
  agr = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.low)$truth_num
  agr$CIHigh = aggregate(truth_num ~ stim_prevalence + stim_determiner + stim_type, data=x, FUN=ci.high)$truth_num
  agr$YMin = agr$truth_num - agr$CILow
  agr$YMax = agr$truth_num + agr$CIHigh
  return(agr)
}

tc<-subset(td,trial_type=='truth_conditions')
tc$truth_num <- 1*as.logical(tc$truth_conditions)

tc.bs<-bootstrap.ci.tc(tc[tc$trialNum<15,])
tc.bs<-bootstrap.ci.tc(tc[tc$trialNum>=15,])



tc.bs<-bootstrap.ci.tc(tc)

tc.bs$stim_type<-factor(tc.bs$stim_type,labels=c("exp1-bare","exp3-danger","exp3-distinct", "exp3-irrelevant"))

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =element_text(size=14,color='black'))

```


Replicate figure 2 of CGB 2010
```{r}

bootstrap.ci <- function(x){
  
  agr = aggregate(subj_prevalence ~ trial_type + stim_determiner + stim_type, data=x, FUN=mean)
  agr$CILow = aggregate(subj_prevalence ~ trial_type + stim_determiner + stim_type, data=x, FUN=ci.low)$subj_prevalence
  agr$CIHigh = aggregate(subj_prevalence ~ trial_type + stim_determiner + stim_type, data=x, FUN=ci.high)$subj_prevalence
  agr$YMin = agr$subj_prevalence - agr$CILow
  agr$YMax = agr$subj_prevalence + agr$CIHigh
  return(agr)
}

td$stim_prevalence <- to.n(td$stim_prevalence)

df2<-ddply(subset(td, truth_conditions%in%c("TRUE",NA)), 
       .(trial_type, stim_determiner, stim_type, workerid), summarise, 
       subj_prevalence = mean(implied_prevalence),
       subj_truth_prevalence = mean(stim_prevalence))

df2$subj_prevalence[is.na(df2$subj_prevalence)] <- df2$subj_truth_prevalence[!is.na(df2$subj_truth_prevalence)]

df2.bs<-bootstrap.ci(df2)
df2.bs$trial_type <- factor(df2.bs$trial_type, levels=c("truth_conditions","implied_prevalence"))

ggplot(df2.bs, aes(x=stim_determiner,y=subj_prevalence,fill=trial_type, group=trial_type))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5)+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5),
                colour='black')+
  theme_bw()+
  facet_wrap(~stim_type,nrow=1)+
  ylab("average prevalence")+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))

ggplot(df2.bs, aes(x=trial_type,y=subj_prevalence,fill=stim_type, group=stim_type))+
  geom_bar(stat='identity',position=position_dodge(0.5), width=0.5)+
  geom_errorbar(aes(ymin=YMin,ymax=YMax),
                width=0.2,
                size=1,
                position=position_dodge(0.5),
                colour='black')+
  theme_bw()+
  facet_wrap(~stim_determiner)+
  ylab("average prevalence")+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))
```

# Bayesian data analysis

## Infer thresholds for quantifiers from implied prevalence task

```{r tfbt.ip.1}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis')
d0<-read.csv('post_bare_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d0$quantifier<-'most'
d0$context<-'bare'
d1<-read.csv('post_danger_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d1$quantifier<-'most'
d1$context<-'danger'
d2<-read.csv('post_distinct_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d2$quantifier<-'most'
d2$context<-'distinct'
d3<-read.csv('post_irrelevant_most_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
d3$quantifier<-'most'
d3$context<-'irrelevant'

e0<-read.csv('post_bare_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e0$quantifier<-'some'
e0$context<-'bare'
e1<-read.csv('post_danger_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e1$quantifier<-'some'
e1$context<-'danger'
e2<-read.csv('post_distinct_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e2$quantifier<-'some'
e2$context<-'distinct'
e3<-read.csv('post_irrelevant_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
e3$quantifier<-'some'
e3$context<-'irrelevant'

f0<-read.csv('post_bare_generic_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f0$quantifier<-'generic'
f0$context<-'bare'
f1<-read.csv('post_danger_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f1$quantifier<-'generic'
f1$context<-'danger'
f2<-read.csv('post_distinct_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f2$quantifier<-'generic'
f2$context<-'distinct'
f3<-read.csv('post_irrelevant_some_implied_prevalence_mh10000_100L1norm_f3_alpha2.csv',header=F,col.names='value')
f3$quantifier<-'generic'
f3$context<-'irrelevant'

all.data<-rbind(f0,f1,f2,f3,e0,e1,e2,e3,d0,d1,d2,d3)

all.data$quantifier<- factor(all.data$quantifier)
all.data$context<-factor(all.data$context)

ggplot(data=all.data,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(context~quantifier)+
  theme_bw()

```


## Infer thresholds for quantifiers from truth conditions task

```{r tfbt.tc.1}
tfbt.dir <- '/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis/'

d0<-read.csv(paste(tfbt.dir,'post_bare_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d0$quantifier<-'most'
d0$context<-'bare'
d1<-read.csv(paste(tfbt.dir,'post_danger_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d1$quantifier<-'most'
d1$context<-'danger'
d2<-read.csv(paste(tfbt.dir,'post_distinct_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d2$quantifier<-'most'
d2$context<-'distinct'
d3<-read.csv(paste(tfbt.dir,'post_irrelevant_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d3$quantifier<-'most'
d3$context<-'irrelevant'

e0<-read.csv(paste(tfbt.dir,'post_bare_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e0$quantifier<-'some'
e0$context<-'bare'
e1<-read.csv(paste(tfbt.dir,'post_danger_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e1$quantifier<-'some'
e1$context<-'danger'
e2<-read.csv(paste(tfbt.dir,'post_distinct_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e2$quantifier<-'some'
e2$context<-'distinct'
e3<-read.csv(paste(tfbt.dir,'post_irrelevant_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e3$quantifier<-'some'
e3$context<-'irrelevant'

f0<-read.csv(paste(tfbt.dir,'post_bare_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f0$quantifier<-'generic'
f0$context<-'bare'
f1<-read.csv(paste(tfbt.dir,'post_danger_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f1$quantifier<-'generic'
f1$context<-'danger'
f2<-read.csv(paste(tfbt.dir,'post_distinct_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f2$quantifier<-'generic'
f2$context<-'distinct'
f3<-read.csv(paste(tfbt.dir,'../post_irrelevant_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f3$quantifier<-'generic'
f3$context<-'irrelevant'

all.data<-rbind(f0,f1,f2,f3,e0,e1,e2,e3,d0,d1,d2,d3)

all.data$quantifier<- factor(all.data$quantifier)
all.data$context<-factor(all.data$context)

ggplot(data=all.data,aes(x=value,fill=context))+
  geom_density()+
  facet_grid(context~quantifier)+
  theme_bw()+
  scale_x_continuous(breaks=c(10,30,50,70,90))

ddply(all.data, .(context, quantifier), summarise, mean(value))

```


Chain 2 (replication)

```{r tfbt.tc.2}
tfbt.dir <- '/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis/'

d0<-read.csv(paste(tfbt.dir,'postChain2_bare_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d0$quantifier<-'most'
d0$context<-'bare'
d1<-read.csv(paste(tfbt.dir,'postChain2_danger_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d1$quantifier<-'most'
d1$context<-'danger'
d2<-read.csv(paste(tfbt.dir,'postChain2_distinct_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d2$quantifier<-'most'
d2$context<-'distinct'
d3<-read.csv(paste(tfbt.dir,'postChain2_irrelevant_most_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
d3$quantifier<-'most'
d3$context<-'irrelevant'

e0<-read.csv(paste(tfbt.dir,'postChain2_bare_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e0$quantifier<-'some'
e0$context<-'bare'
e1<-read.csv(paste(tfbt.dir,'postChain2_danger_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e1$quantifier<-'some'
e1$context<-'danger'
e2<-read.csv(paste(tfbt.dir,'postChain2_distinct_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e2$quantifier<-'some'
e2$context<-'distinct'
e3<-read.csv(paste(tfbt.dir,'postChain2_irrelevant_some_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
e3$quantifier<-'some'
e3$context<-'irrelevant'

f0<-read.csv(paste(tfbt.dir,'postChain2_bare_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f0$quantifier<-'generic'
f0$context<-'bare'
f1<-read.csv(paste(tfbt.dir,'postChain2_danger_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f1$quantifier<-'generic'
f1$context<-'danger'
f2<-read.csv(paste(tfbt.dir,'postChain2_distinct_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f2$quantifier<-'generic'
f2$context<-'distinct'
f3<-read.csv(paste(tfbt.dir,'postChain2_irrelevant_generic_truth_conditions_mh1000_100_alpha3.csv',sep=''),header=F,col.names='value')
f3$quantifier<-'generic'
f3$context<-'irrelevant'

all.data2<-rbind(f0,f1,f2,f3,e0,e1,e2,e3,d0,d1,d2,d3)

all.data2$quantifier<- factor(all.data$quantifier)
all.data2$context<-factor(all.data$context)

ggplot(data=all.data2,aes(x=value,fill=context))+
  geom_density()+
  facet_grid(context~quantifier)+
  theme_bw()+
  scale_x_continuous(breaks=c(10,30,50,70,90))

ddply(all.data, .(context, quantifier), summarise, mean(value))

```


# Experiment 4 -- within-subjects effect of context on Generic

The idea now is to see if the generic theta differs across contexts, thus motivating a lifted variable model from a bayesian data analysis standpoint.

+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False

The sentence is between subjects (subjects see only generics or mosts or somes).

Within-subject is the context:

+ **distinctive**
+ **irrelevant**
+ **bare**

```{r exp4}

setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
td4<-read.table('cbgR-exp4-trials.tsv',header=T)
#write.csv(td4, file='cbgR-exp4_anonymized-trials.csv')


td4$rt <- td4$rt/1000
td4$truth_conditions <- factor(as.logical(levels(td4$response)[td4$response]), 
                              levels=c("TRUE","FALSE"))

td4$truth_num <- bool.tonum(td4$truth_conditions)


results<-glmer(truth_num ~ stim_prevalence*stim_type + (1 | workerid) + (1 | stim_category), data=td4, family='binomial')
summary(results)



tc<-subset(td4,trial_type=='truth_conditions')
tc<-subset(td4,workerid<30)
tc$truth_num <- 1*as.logical(tc$truth_conditions)

tc.bs<-bootstrap.ci.tc(tc[tc$trialNum<15,])
tc.bs<-bootstrap.ci.tc(tc[tc$trialNum>=15,])

tc.bs<-bootstrap.ci.tc(tc)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))


Number of responses for each prevalence level (for truth conditions task)
```{r, echo=FALSE}
table(td1[,c("stim_determiner","stim_prevalence")])/6
```

Subject-wise thresholds for generic across 3 contexts

```{r}
df<-ddply(subset(td4,trial_type=='truth_conditions' & truth_conditions==TRUE), 
      .(workerid, stim_type), summarise,
      mean_prev = mean(stim_prevalence),
      min_prev = min(stim_prevalence))

ggplot(data=df, aes(x=min_prev,fill=stim_type,group=stim_type))+
  geom_histogram()+
  facet_wrap(~stim_type)+
  theme_bw()

```


Recreate ANOVA from CBG Exp 4

```{r anova}
df<-ddply(subset(td4,trial_type=='truth_conditions' & truth_conditions==TRUE), 
      .(stim_prevalence, stim_type), summarise,
      count = sum(as.numeric(truth_conditions)))

td4$truth_num<-abs(as.numeric(td4$truth_conditions)*1-2)

results<-glmer(truth_num ~ stim_prevalence*stim_type + (1 | workerid), data=td4, family='binomial')
summary(results)


summary(aov(truth_num~(stim_prevalence*stim_type)+Error(workerid/(stim_prevalence*stim_type)),
    data=td4))

```


# Experiment 5 -- within-subjects effect of context on Generic (Replicate truth conditions of Exp 1 of CBG exactly)

+ **truth conditions** = given a prevalence level (XX% of warfles have purple feathers) and a sentence (*generic*, *most*, *some*), answer if the sentence is True or False

The sentence is between subjects (subjects see only generics or mosts or somes).

Within-subject is the context:

+ **dangerous and distinctive**
+ **nondistinctive control**
+ **bare**

```{r exp5}
td5<-read.table('cbgR-exp5-trials.tsv',header=T)
td5$stim_type<-gsub("danger/distinct","dangerdistinct",td5$stim_type)
#write.csv(td5, file='cbgR-exp5_anonymized-trials.csv')

td5$item<-paste(td5$stim_color,td5$stim_part,sep='_')
levels(factor(subset(td5,stim_type=='bare')$item))

td5$rt <- td5$rt/1000
td5$truth_conditions <- factor(as.logical(levels(td5$response)[td5$response]), 
                              levels=c("TRUE","FALSE"))

td5$truth_num <- bool.tonum(td5$truth_conditions)

#split by first half/second half to look at order effects
#tc.bs<-bootstrap.ci.tc(td5[td5$trialNum>15,])

tc.bs<-bootstrap.ci.tc(td5)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))
```

### frequentist statistics

```{r exp4_5_stats}
cntxt.ef4<-ddply(td4, .(workerid), summarise,
      trialnum = trialNum,
      irrelevant_seen=cumsum(as.numeric(stim_type=='irrelevant')),
      distinct_seen=cumsum(as.numeric(stim_type=='distinct')),
      nonbare_seen=cumsum(as.numeric(stim_type!='bare')),
      context = stim_type,
      response = truth_num,
      prevlev = stim_prevalence,
      item = stim_category)


cntxt.ef5<-ddply(td5, .(workerid), summarise,
      trialnum = trialNum,
      nondistinct_seen=cumsum(as.numeric(stim_type=='nondistinctive')),
      dangdistinct_seen=cumsum(as.numeric(stim_type=='dangerdistinct')),
      nonbare_seen=cumsum(as.numeric(stim_type!='bare')),
      context = stim_type,
      response = truth_num,
      prevlev = stim_prevalence,
      item = stim_category)



rs4.mixed<-glmer(response ~ prevlev*context + (1 | workerid) + (1 | item), data=cntxt.ef4, family = 'binomial')
summary(rs4.mixed)

rs5.simple<-glm(response ~ prevlev*context,data=cntxt.ef5,family='binomial')
summary(rs5.simple)

rs5.mixed<-glmer(response ~ prevlev*context + (1 | workerid) + (1 | item), data=cntxt.ef5, family = 'binomial')
summary(rs5.mixed)


```

### bayesian statistics

## Infer thresholds for quantifiers from truth conditions task

```{r tfbt.tc.exp4.exp5}
tfbt.dir <- '/Users/mht/Documents/research/generics/cbg2010-replication/models/bayesian_analysis/'

f0<-read.csv(paste(tfbt.dir,'post_wPhi_exp5bare_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
f0$quantifier<-'generic'
f0$context<-'bare'
# ggplot(data=f0,aes(x=theta))+geom_histogram()+
#   scale_x_continuous(limits=c(0,100),breaks=c(10,30,50,70,90))
# ggplot(data=f0,aes(x=phi))+geom_histogram()+
#   scale_x_continuous(limits=c(0,1))

f1<-read.csv(paste(tfbt.dir,'post_wPhi_exp5nondistinctive_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
f1$quantifier<-'generic'
f1$context<-'nondistinctive-control'

f2<-read.csv(paste(tfbt.dir,'post_wPhi_exp5dangerdistinct_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
f2$quantifier<-'generic'
f2$context<-'danger-distinct'


all.data<-rbind(f0,f2,f1)
all.data$phi <- all.data$phi*100

all.data$quantifier<- factor(all.data$quantifier)
all.data$context<-factor(all.data$context)

exp5.tfbt<-melt(all.data[,c(1,2,4,5)],id.vars=c('quantifier','context'))
exp5.tfbt$variable<-factor(exp5.tfbt$variable,levels=c("theta","phi"))

ggplot(data=exp5.tfbt,aes(x=value,fill=context))+
  geom_density(alpha=0.8)+
  facet_grid(variable~context)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))


g0<-read.csv(paste(tfbt.dir,'post_wPhi_exp4bare_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
g0$quantifier<-'generic'
g0$context<-'bare'
g1<-read.csv(paste(tfbt.dir,'post_wPhi_exp4irrelevant_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
g1$quantifier<-'generic'
g1$context<-'irrelevant'
g2<-read.csv(paste(tfbt.dir,'post_wPhi_exp4distinct_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,col.names=c('phi','theta','dummmy'))
g2$quantifier<-'generic'
g2$context<-'distinct'

a.data<-rbind(g0,g1,g2)
a.data$phi <- a.data$phi*100
a.data$quantifier<- factor(a.data$quantifier)
a.data$context<-factor(a.data$context)

exp4.tfbt<-melt(a.data[,c(1,2,4,5)],id.vars=c('quantifier','context'))
exp4.tfbt$variable<-factor(exp4.tfbt$variable,levels=c("theta","phi"))

ggplot(data=exp4.tfbt,aes(x=value,fill=context))+
  geom_density(alpha=0.8)+
  facet_grid(variable~context)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))



ddply(all.data, .(context, quantifier), summarise, mean(value))

```

Using a phi common across contexts
```{r tfbt.commonPhi} 
test0<-read.csv(paste(tfbt.dir,'post_wPhi_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,
                col.names=c("nondistinctive_phi","nondistinctive_theta","blank","bare_phi","bare_theta","blank","dangerdistinct_phi","dangerdistinct_theta","blank","blank"))[,c(1,2,4,5,7,8)]

test0$nondistinctive_phi<-test0$nondistinctive_phi*100
test0$bare_phi <- test0$bare_phi*100
test0$dangerdistinct_phi <- test0$dangerdistinct_phi*100
x<-melt(test0)

x1<-cbind(x,ldply(strsplit(as.character(x$variable),"_")))
x1$V2<-factor(x1$V2,levels=c("theta","phi"))


ggplot(data=x1,aes(x=value,fill=V1))+
  geom_density(alpha=0.8)+
  facet_grid(V2~V1)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(10,30,50,70,90),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))

```

### "Kinder" model

```{r tfbt.kinder.exp5}
#d<-read.csv(paste('kinder_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudIsLorch_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudWhoIsIt_exp5all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudUncertain_l0predictivepower_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
#d<-read.csv(paste('kinder_qudUncertain_justPrev_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)
d<-read.csv(paste('kinder_qudUncertain_prevForGen_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F)


d.tidy <- d %>%
  select(V1,V2,V3,V5,V6,V7,V9,V10,V11) %>%
  rename(nondistinct_phi = V1,
         nondistinct_theta = V2,
         nondistinct_other = V3,
         bare_phi = V5,
         bare_theta = V6,
         bare_other = V7,
         distinct_phi = V9, 
         distinct_theta = V10,
         distinct_other= V11) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

d.tidy$variable<-factor(d.tidy$variable,levels=c("theta","other","phi"))

ggplot(d.tidy,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(variable~context)+
  theme_bw()

```

### Listener model w/ beta hyperprior

```{r tfbt.kinder.exp5}
setwd('../models/bayesian_analysis/')
d<-read.csv(paste('listen_betaHyper2_exp5all_generic_truth_conditions_mh10000_3_alpha3.csv',sep=''),header=F)


d.tidy <- d %>%
  select(V1,V2,V3,V5,V6,V7,V9,V10,V11) %>%
  rename(nondistinct_phi = V1,
         nondistinct_gamma = V2,
         nondistinct_delta = V3,
         bare_phi = V5,
         bare_gamma = V6,
         bare_delta = V7,
         distinct_phi = V9, 
         distinct_gamma = V10,
         distinct_delta= V11) %>%
  gather(variable,value) %>%
  separate(variable,into=c('context','variable') ,sep="_")

d.tidy$variable<-factor(d.tidy$variable,levels=c("gamma","delta","phi"))

ggplot(d.tidy,aes(x=value,fill=context))+
  geom_histogram()+
  facet_grid(context~variable,scale='free')+
  theme_bw()

+
  xlim(0,1)

```



Are the alternative contexts having an effect on endorsements? One preliminary way to test this is to look at the endorsements for the bare, as the number of Nondistinct contexts have been seen.

First, I'll code the data for the number of nondistinct contexts seen by the participant.

```{r exp4_5contextEffect}

## effect of nondistinct seen
nondist_seen.df5<- ddply(cntxt.ef5, .(nondistinct_seen, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(nondist_seen.df5,context=='bare'), aes(x=nondistinct_seen,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
  scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10))+
  xlab("number of nondistinct seen")+
  ylab("proportion of true responses")+
  ggtitle("bare generic endorsements by nondistinct contexts seen and prevalence level")

## effect of dangerous and distinct seen
dangdist_seen.df5<- ddply(cntxt.ef5, .(dangdistinct_seen, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(dangdist_seen.df5,context=='bare'), aes(x=dangdistinct_seen,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
  scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10))+
  xlab("number of dangerous/distinct seen")+
  ylab("proportion of true responses")+
  ggtitle("bare generic endorsements by dangerous/distinct contexts seen and prevalence level")

## effect of other contexts seen (collapsed across dd & nd)
nonbare_seen.df5<- ddply(cntxt.ef5, .(nonbare_seen, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(nonbare_seen.df5,context=='bare'), aes(x=nonbare_seen,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("number of non-bare seen")+
  ylab("proportion of true responses")+
  ggtitle("bare generic endorsements vs. non-bare contexts seen and prevalence level")
```

Are there order effects in generic acceptability?

```{r order.effects}
## effect of trial --- exp 5
cntxt.ef5$trialCat<-(cntxt.ef5$trialnum<15)
cntxt.ef5$trialCat<-factor(cntxt.ef5$trialCat,levels=c(TRUE,FALSE),labels=c("early","late"))


rs5<-glm(response ~ prevlev*context*trialCat, data=cntxt.ef5, family='binomial')
summary(rs5)
with(cntxt.ef5,interaction.plot(context,trialCat,response))
with(cntxt.ef5,interaction.plot(prevlev,trialCat,response))


glmer(response ~prevlev*context*trialCat + (context*prevlev*trialCat| workerid), data=cntxt.ef5)

summary(rs5)

trials_seen.df5<- ddply(cntxt.ef5, .(trialnum, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(trials_seen.df5,context=='bare'), aes(x=trialnum,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("proportion of true responses")+
  ggtitle("exp 5 -- bare generic endorsements vs.trials seen and prevalence level")

ggplot(data=subset(trials_seen.df5,context=='bare'), aes(x=trialnum,y=n))+ 
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("number of responses")+
  ggtitle("bare generic endorsements vs.trials seen and prevalence level")


## effect of trial --- exp 4
trials_seen.df4<- ddply(cntxt.ef4, .(trialnum, prevlev, context), 
                  summarise,
                  pr.true=(sum(response) / length(response)),
                  n = length(response))
      
ggplot(data=subset(trials_seen.df4,context=='bare'), aes(x=trialnum,y=pr.true))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("proportion of true responses")+
  ggtitle("exp 4 - bare generic endorsements vs.trials seen and prevalence level")

ggplot(data=subset(trials_seen.df4,context=='bare'), aes(x=trialnum,y=n))+
  facet_wrap(~prevlev,nrow=1)+
  geom_point(color='white')+
 # theme_bw()+
#  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20))+
  xlab("trial num")+
  ylab("number of responses")+
  ggtitle("exp 4-- bare generic endorsements vs.trials seen and prevalence level")
```

# Experiment 6: p(property | any-animal) elicitation


```{r exp6}
setwd('/Users/mht/Documents/research/generics/cbg2010-replication/data/')
turk.data<-read.table('cbgR-exp6-trials.tsv',header=T)
summary(turk.data)
```


Reaction time histograms

```{r}
ggplot(turk.data,aes(x=rt/60000,fill=stim_type))+
  geom_histogram()+
  facet_wrap(~stim_type)+
  guides(fill=F)+
  xlab('rt in minutes')+
  theme_bw()
```


Prevalence histograms / densities, broken up by context

and then by item and context

```{r}
ggplot(turk.data,aes(x=response,fill=stim_type))+
  #geom_histogram(binwidth=1, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  geom_histogram(binwidth=1)+
  #geom_density()+
  facet_wrap(~stim_type)+
  guides(fill=F)+
  theme_bw()


ddply(turk.data, .(stim_type), 
                  summarise,
                  pr.true=mean(response),
                  med = median(response),
                  variance = sqrt(var(response)))


ggplot(turk.data,aes(x=response,fill=stim_type))+
  geom_histogram(binwidth=5, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  #geom_density()+
  facet_grid(stim_type~item)+
  guides(fill=F)+
  theme_bw()

levels(factor(subset(turk.data,stim_type=='bare')$item))

ggplot(turk.data,aes(x=trial_num,y=response,color=stim_type))+
  geom_point()+
  theme_bw()


```

```{r exp6.stats}

turk.data$item<-paste(turk.data$stim_color,turk.data$stim_part,sep="_")

rs6.mixed<-lmer(response ~ trial_num+ stim_type + (1 | workerid) + (1 | item), data=turk.data)

summary(rs6.mixed)

d<-ddply(turk.data, .(stim_type, item), 
                  summarise,
                  mean = mean(response))

ggplot(d,aes(x=mean,fill='bare'))
```

# Experiment 7: finer grain

### Same as Exp 5 but with Prevalence levels = {5, 15, 25, 35, 45}

```{r exp7}
td7<-read.table('cbgR-exp7-trials.tsv',header=T)
td7$stim_type<-gsub("danger/distinct","dangerdistinct",td7$stim_type)
#write.csv(td7, file='cbgR-exp7_anonymized-trials.csv')

td7$rt <- td7$rt/1000
td7$truth_conditions <- factor(as.logical(levels(td7$response)[td7$response]), 
                              levels=c("TRUE","FALSE"))

td7$truth_num <- bool.tonum(td7$truth_conditions)

split by first half/second half to look at order effects
tc.bs<-bootstrap.ci.tc(td7[td7$trialNum<=15,])


tc.bs<-bootstrap.ci.tc(td7)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,colour=stim_type, group=stim_type))+
 # geom_line(size=0.3,position=position_dodge(0.4))+
  geom_point(size=3, position=position_dodge(0.4))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.4))+
  facet_wrap(~stim_determiner,nrow=3)+
  theme_bw()+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x =       element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))
```

Some stats
```{r exp7.stats}

cntxt.ef7<-ddply(td7, .(workerid), summarise,
      trialnum = trialNum,
      nondistinct_seen=cumsum(as.numeric(stim_type=='nondistinctive')),
      dangdistinct_seen=cumsum(as.numeric(stim_type=='dangerdistinct')),
      nonbare_seen=cumsum(as.numeric(stim_type!='bare')),
      context = stim_type,
      response = truth_num,
      prevlev = stim_prevalence,
      item = stim_category)


cntxt.ef7$trialCat<-(cntxt.ef7$trialnum<15)
cntxt.ef7$trialCat<-factor(cntxt.ef7$trialCat,levels=c(TRUE,FALSE),labels=c("early","late"))


rs7<-glm(response ~ prevlev*context*trialCat, data=cntxt.ef7, family='binomial')
summary(rs7)
with(cntxt.ef7,interaction.plot(context,trialCat,response))
with(cntxt.ef7,interaction.plot(prevlev,trialCat,response))


rs7.simple<-glm(response ~ prevlev*context,data=cntxt.ef7,family='binomial')
summary(rs7.simple)

rs7.mixed<-glmer(response ~ prevlev*context + (1 | workerid) + (1 | item), data=cntxt.ef7, family = 'binomial')
summary(rs7.mixed)
```

Using a phi common across contexts
```{r tfbt7.commonPhi} 
test0<-read.csv(paste(tfbt.dir,'post_wPhi_exp7all_generic_truth_conditions_mh1000_3_alpha3.csv',sep=''),header=F,
                col.names=c("nondistinctive_phi","nondistinctive_theta","blank","bare_phi","bare_theta","blank","dangerdistinct_phi","dangerdistinct_theta","blank","blank"))[,c(1,2,4,5,7,8)]

test0$nondistinctive_phi<-test0$nondistinctive_phi*100
test0$bare_phi <- test0$bare_phi*100
test0$dangerdistinct_phi <- test0$dangerdistinct_phi*100
x<-melt(test0)

x1<-cbind(x,ldply(strsplit(as.character(x$variable),"_")))
x1$V2<-factor(x1$V2,levels=c("theta","phi"))


ggplot(data=x1,aes(x=value,fill=V1))+
  geom_density(alpha=0.8)+
  #geom_histogram(alpha=0.8)+
  facet_grid(V2~V1)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(5,15,25,35,45,75),limits=c(0,100))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))
```

## TFBT on the "kinds" model
```{r tfbt7.kinds} 
test0<-read.csv(paste(tfbt.dir,'KindMod_post_wPhi_exp5all_generic_truth_conditions_mh2000_3_alpha3.csv',sep=''),header=F,
                col.names=c("nondistinctive_phi","nondistinctive_theta","nondistinctive_other",
                            "blank","bare_phi","bare_theta","bare_other","blank",
                            "dangerdistinct_phi","dangerdistinct_theta","dangerdistinct_other",
                            "blank","blank"))[,c(1,2,3,5,6,7,9,10,11)]

test0$nondistinctive_theta<-test0$nondistinctive_theta/100
test0$bare_theta <- test0$bare_theta/100
test0$dangerdistinct_theta <- test0$dangerdistinct_theta/100
x<-melt(test0)
x1<-cbind(x,ldply(strsplit(as.character(x$variable),"_")))
x1$V2<-factor(x1$V2,levels=c("theta","other","phi"))

ggplot(data=x1,aes(x=value,fill=V1))+
  #geom_density(alpha=0.8)+
  geom_histogram(alpha=0.8)+
  facet_grid(V2~V1)+
  theme_bw()+
  guides(fill=F)+
  scale_x_continuous(breaks=c(0.1,0.3,0.5,0.70,0.9),limits=c(0,1))+
  scale_fill_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))
```


# Experiment 8 -- frequency elicitation


```{r exp8}
setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp8-trials.tsv',header=T)
d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)

d0<-subset(d,response<50000)
sketchy<-c(6,13,22,29)

d0<-subset(d,!(workerid%in%sketchy))

ggplot(d,aes(x=response,fill=stim_type))+
  geom_histogram()+
  facet_wrap(~workerid)

ggplot(d0,aes(x=response,fill=stim_type))+
  #geom_histogram(binwidth=1, aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  geom_histogram()+
  #geom_density()+
  facet_wrap(~stim_type)+
  guides(fill=F)+
  theme_bw()

ddply(d0, .(stim_type), 
                  summarise,
                  pr.true=mean(response),
                  med = median(response),
                  variance = sqrt(var(response)))


```



# Experiment 9 -- replication (exp 5) with proper randomization


```{r exp9}
setwd("~/Documents/research/generics/cbg2010-replication/data")
d<-read.table('cbgR-exp9-trials.tsv',header=T)
d$item <- paste(d$stim_color,d$stim_part,sep="_")
table(d$stim_type,d$item)
table(d$stim_type,d$stim_part)

levels(factor(subset(d,stim_type=='bare')$item))

d$rt <- d$rt/1000
d$truth_conditions <- factor(as.logical(levels(d$response)[d$response]), 
                              levels=c("TRUE","FALSE"))

d$truth_num <- bool.tonum(d$truth_conditions)

ggplot(d,aes(x=factor(truth_num),fill=stim_type))+
  geom_histogram()+
  facet_wrap(~item)+
  #facet_wrap(~workerid)

#split by first half/second half to look at order effects
#tc.bs<-bootstrap.ci.tc(d[d$trialNum>15,])
)

tc.bs<-bootstrap.ci.tc(d)

ggplot(tc.bs, aes(x=factor(stim_prevalence),y=truth_num,
                  colour=stim_type, group=stim_type))+
  geom_point(size=3, position=position_dodge(0.5))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_type),
              width=0.3,
              size=0.8,
              position=position_dodge(0.5))+
  facet_wrap(~stim_determiner,nrow=3)+
  ylab("proportion of 'true' responses")+
  scale_colour_brewer(type='qual',palette=6)+
  theme(strip.text.x = element_text(size=14,color='black'))+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))


```





