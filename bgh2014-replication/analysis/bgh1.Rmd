---
title: "BGH (2014) Replication"
output: html_document
author: Michael Henry Tessler
---

# Libraries

```{r, message=FALSE}
library(jsonlite)
setwd("~/Documents/research/generics/bgh2014-replication/analysis")
```

# Read in all the JSON strings

```{r comment=NA}
read.file <- function(filename) {
  con <- file(filename, "r", blocking = TRUE)
  lines <- paste(readLines(con, warn = FALSE), collapse = "\n")
  close(con)
  lines
}

#json.dir <- "../mturk/sandbox-results/"
json.dir <- "../mturk/production-results/"

json.filenames <- paste0(json.dir, list.files(json.dir))
json.strings <- Map(read.file, json.filenames)
```

# Convert JSON to a R data frame

Merge all the json strings together, as if they are in a big array, and convert it to an R data frame:

```{r comment=NA}
json.superstring <- paste("[",paste(json.strings, collapse = ","),"]")
assignments <- fromJSON( json.superstring )
```

## Subject information (incl. comments)

```{r}

subj.data <- cbind(data.frame(workerid=assignments$WorkerId,
                              condition = assignments$answers$condition,
                              duration =assignments$answers$time_in_minutes), 
                        assignments$answers$subject_information)

View(subj.data)
```


## Analyze practice trial data

```{r}
catch.data <- Map(function(id, subject.trial.data) { cbind(workerid = id, subject.trial.data) },
                  assignments$WorkerId,
                  assignments$answers$catch_trials)

strip.rownames <- function(x) {
  rownames(x) <- NULL
  x
}

is.tc <- function(x) {
  return(x$trial_type[1]=='practice')
}
is.ip <- function(x) {
  return(x$trial_type[1]!='practice')
}



catch.tc<- strip.rownames(do.call(rbind, Filter(is.tc, catch.data)))
catch.tc$response <- as.numeric(substring(catch.tc$response,1,1))
catch.tc<-catch.tc %>%
  mutate(correct = (correctResponse==response))

catch.tc.subj <- catch.tc %>%
  group_by(workerid) %>%
  summarise(correctTotal = sum(correct),
            exclude = sum(correct)<3)



catch.ip<- strip.rownames(do.call(rbind, Filter(is.ip, catch.data)))
catch.ip 
catch.tc
```

# Trial data


```{r}
trial.data <- Map(function(id, subject.trial.data) { cbind(workerid = id, subject.trial.data) },
                  assignments$WorkerId,
                  assignments$answers$trials)

is.tc <- function(x) {
  return (x$trial_type[1]=='truth_conditions')
}
is.ip <- function(x) {
  return(x$trial_type[1]!='truth_conditions')
}


trial.tc <- strip.rownames(do.call(rbind, Filter(is.tc, trial.data)))
trial.ip <- strip.rownames(do.call(rbind, Filter(is.ip, trial.data)))

```

# Analyze truth conditions task (BGH Exp 1)

```{r}

View(trial.tc)

bootstrap.ci.tc <- function(x){
  agr = aggregate(response ~ stim_prevalence + stim_word, data=x, FUN=mean)
  agr$CILow = aggregate(response ~ stim_prevalence + stim_word, data=x, FUN=ci.low)$response
  agr$CIHigh = aggregate(response ~ stim_prevalence + stim_word, data=x, FUN=ci.high)$response
  agr$YMin = agr$response - agr$CILow
  agr$YMax = agr$response + agr$CIHigh
  return(agr)
}

trial.tc$response <- to.n(trial.tc$response)
trial.tc$stim_prevalence <- factor(trial.tc$stim_prevalence)
trial.tc$stim_word <- factor(trial.tc$stim_word)


# compute proportion endorsement at each prevalence level
tc.tidy <- trial.tc %>% 
  select(workerid,stim_word,stim_prevalence,response) %>%
  group_by(stim_word, stim_prevalence) %>%
  summarise(endorsement=mean(response))

ggplot(tc.tidy, aes(x=stim_prevalence,y=endorsement,color=stim_word,group=stim_word))+
  geom_point()+
  geom_line()+
  theme_black()

### bootstrapped 95 % CI version
tc.bs<- bootstrap.ci.tc(trial.tc)
tc.bs$stim_prevalence<- to.n(tc.bs$stim_prevalence)

ggplot(tc.bs, aes(x=stim_prevalence,y=response,color=stim_word,group=stim_word))+
  geom_point(size=4, position=position_dodge(0.05))+
  geom_line(size=1,position=position_dodge(0.05))+
  geom_errorbar(aes(ymin=YMin,ymax=YMax,colour=stim_word),
              width=0.05,
              size=0.9,
              position=position_dodge(0.05))+
  scale_colour_brewer(type='qual',palette=8)+
  scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(-0.05,1.05))+
  scale_x_continuous(breaks=c(0,0.33,0.66,1),limits=c(-0.05,1.05))+
  theme_blackDisplay()+ 
  guides(color=guide_legend(title="Context"))+
  xlab("\n prevalence (in %)")+
  ylab('proportion "true"\n')+
  coord_fixed(1)+
  theme(legend.key.size=unit(2, "lines"),
        legend.text.align=NULL)

#ggsave("../presentation/tc_data.png",width=10,height=15)


# to compare with "implied prevalence" task
# each subject gets a "truth" score -- the average prevalence at which they endorsed each of the sentences
trial.tc$stim_prevalence <- to.n(trial.tc$stim_prevalence)

tc.subj <- trial.tc %>% 
  select(workerid,stim_word,stim_prevalence,response) %>%
  group_by(workerid, stim_word) %>%
  summarise(truth=sum(response*stim_prevalence)/sum(response))%>%
  ungroup()

tc.stats <- tc.subj %>%
  group_by(stim_word) %>%
  summarise(average = mean(truth),
            sterr = sem(truth),
            task = 'truth')

```

# Analyze implied prevalence task (BGH Exp 2)


```{r}

ip.subj<-trial.ip %>%
  select(workerid, stim_word, response) %>%
  group_by(workerid, stim_word) %>%
  summarise(implied = mean(response)) %>%
  ungroup()


ip.stats<- ip.subj %>%
  group_by(stim_word) %>%
  summarise(average = mean(implied),
            sterr = sem(implied),
            task = 'implied')

final.stats<-bind_rows(ip.stats,tc.stats)
final.stats$task <- factor(final.stats$task, levels=c("truth","implied"))


ggplot(final.stats, aes(x=stim_word, y = average, fill=stim_word, alpha = task))+
  geom_bar(stat='identity',color='white',width=0.6, position=position_dodge(0.6))+
  geom_errorbar(aes(ymin=average-2*sterr, ymax=average+2*sterr),
                color='white',
                position=position_dodge(0.6),
                width=0.3,
                size=2)+
  scale_alpha_manual(values=c(0.5,1))+
  theme_blackDisplay()+
  scale_fill_brewer(type='qual',palette=8)+
  scale_color_brewer(type='qual',palette=8)+
  guides(fill=F,color=F)+
  xlab("")+
  ylab("average prevalence\n")

ggsave("../presentation/asymm_data.png",width=10,height=10)



```

# Stats

```{r}
tc.subj <- tc.subj %>%
  rename(prevalence = truth) %>%
  mutate(task = factor('truth'))

ip.subj <- ip.subj %>%
  rename(prevalence = implied) %>%
  mutate(task = factor('implied'))

final.subj<-bind_rows(tc.subj, ip.subj)

final.subj<-final.subj %>%
  mutate(workerid = factor(workerid),
         stim_word = factor(stim_word),
         task = factor(task))


rs0<-lmer(data = final.subj, prevalence ~ -1 + task*stim_word + (1 | workerid))
summary(rs0)
```
























Let's look at the structure of `assignments`:

```{r comment=NA}
str(assignments)
```

Notice how most of the columns are pretty normal, except `answers`, which is itself a dataframe. To get a clearer picture, let's look at the `answers` column for just the first subject:

```{r comment=NA}
str(assignments[1,]$answers)
```

There are three fields - keyBindings (which tells us whether p = even and q = odd or vice versa), trials (parameters for each trial; empty), and data (recorded data for each trial). We're going to pull out `keyBindings` and `data` as their own top-level data frames and attach columns to them that allow us to cross-reference with particular subjects.

## keyBindings

Looking at `assignment$WorkerId`:

```{r comment=NA}
assignments$WorkerId
```

Very simple - just a vector of three strings.

Looking at `assignments$answers$keyBindings`:

```{r comment=NA}
assignments$answers$keyBindings
```

Also simple - a data frame with two columns (q and p) and three rows (one for each subject telling us what q was for and what p was for). 

Because the number of strings in the vector matches up with the number of rows in the dataframe, we can just use `cbind` to sew these structures together:

```{r comment=NA}
keyBindings <- cbind(workerid = assignments$WorkerId, assignments$answers$keyBindings)
keyBindings
```

## data

We already know what `assignments$WorkerId` looks like, so what does `assignments$answers$data` look like?

```{r comment=NA}
assignments$answers$data
```

This is a little more complicated - a list of three data frames. Thankfully, the data farmes have the same structure, so to combine them we can just use rbind. However, it would then be difficult to figure out which rows belong to which subjects.

But notice that the list contains three data frames and we have three subject ids. So if we can somehow zip together the subject ids with the trials for each subject, we'd be in business. One way we can do this in R is using `Map`, applies a function and an arbitrary number of list/vector arguments (if you don't understand the difference between lists and vectors, you should Google it).

For example, mapping a squaring function over a single list:
```{r comment=NA}
Map(function(x) x^2,
    list(1,2,3))
```

Mapping a sum of squares function over two lists:
```{r comment=NA}
Map(function(x,y) x^2 + y^2,
    list(1,2,3),
    list(4,5,6))
```

(Note that `Map` always returns a list regardless of its input types. If you want to convert the output of `Map` to a vector, use `unlist`)

Here's how we zip together the subject ids and trial dataframes - we just Map over every id-dataframe pair and cbind them together:

```{r comment=NA}
trial.data <- Map(function(id, subject.trial.data) { cbind(workerid = id, subject.trial.data) },
                  assignments$WorkerId,
                  assignments$answers$data)
trial.data
```

Now we can rbind the dataframes together and strip the rownames in the resulting data frame to get what we want:

```{r comment=NA}
strip.rownames <- function(x) {
  rownames(x) <- NULL
  x
}

trial.data <- strip.rownames(do.call(rbind, trial.data))
trial.data
```
