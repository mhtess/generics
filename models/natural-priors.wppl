// time webppl natural-prior.wppl --require-js ./truthutils.js --require-wppl ./natural-cases-prior.wppl 

// var discretizedPriorModel = function(g0, d0, g1, d1){
var discretizedPriorModel = function(hasF, g1, d1){

	var getProbsFromERP = function(myERP, orderedSupport){
		return map(function(s){
			Math.exp(myERP.score([], s))
		}, orderedSupport)
	}

	// var hasF = makeBetaBernoulli([shape_alpha(g0,d0), shape_beta(g0,d0)])()
	// var prevalence = hasF ? beta()
	var kindDoesntHaveF_prevalence = 0
	// var kindDoesntHaveF_prevalence = 0
	// discretization occurs here
	var prevalencePrior = 
		Enumerate(function(){
			// var kindHasF = flip(bins[discrete(discretizeBeta(g0,d0))])
			var kindHasF = flip(hasF)

			var prevalenceGivenK = kindHasF ? bins[discrete(discretizeBeta(g1,d1))] : 
											kindDoesntHaveF_prevalence

			return prevalenceGivenK
		})
		// console.log('after prev')
	return getProbsFromERP(prevalencePrior, [0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99])
}


//var scoreFunction = function(d, prob_hasF, a, b){
// var scoreFunction = function(d, a, b){
// 	// var x1 = (d==0) ? (1-prob_hasF) : 0
// //	var x2 =  (prob_hasF)*Math.exp(betaERP.score([a, b], alignPrevalence(d)))
// 	var x2 =  (prob_hasF + betaERP.score([a, b], alignPrevalence(d)))
// 	// console.log('begin computation of score function')
// 	// console.log('end computation of score function')
// 	return x2
// }


// var priorModel = function(){

// 	foreach(properties, function(p){

// 		var propertyData = subset(df_prior, "Property", p)
// 		var responseData = _.pluck(propertyData, "prevalence")
// 		// console.log(p + ' ' + sum(responseData))
// 		// console.log(propertyData)

// 		// var gamma_across = uniform(0,1)
// 		// var delta_across = uniform(0,20)
// 		// var prob_hasF = beta(shape_alpha(gamma_across, delta_across),
// 		// 					  	   shape_beta(gamma_across, delta_across))
// 		var prob_hasF = beta(1,1)
// 		// console.log(p + ' ' + map(function(x){return x!=0}, responseData))
// 		var scr1 = reduce(function(d, memo) {
// 							// console.log(d)
// 						    return memo + bernoulliERP.score([prob_hasF], d!=0)
// 							}, 0, responseData)
// 		// console.log(scr1)
// 		factor(scr1)

// 		query.add(["prevalencePrior",p,"na","prob_hasF"], prob_hasF)

// 		var gamma = uniform(0,1)
// 		var delta = uniform(0,20)

// 		var discretized_prevalence = discretizedPriorModel(prob_hasF, gamma, delta)
// 		// console.log('after scr2')
// 		// var priorERP = discretizedPriorModel(gamma_across, delta_across, gamma_within, delta_within)
// 		// console.log(propertyData)
// 		// console.log(propertyData)
// 		var scr2 = reduce(function(d, memo) {
// 							// console.log(d)
// 							var x = d==0? 0 : betaERP.score([shape_alpha(gamma, delta), 
// 						    									shape_beta(gamma, delta)], alignPrevalence(d))
// 						    return memo + x
// 							}, 0, responseData)

// 		// // var scr = reduce(function(dataPoint, memo) {
// 		// // 				    return memo + priorERP.score([], alignPrevalence(dataPoint))
// 		// // 					}, 0, propertyData)
// 		factor(scr2)
// 		// // console.log(p+' ' +scr)
// 		var postpred = beta(shape_alpha(gamma, delta), shape_beta(gamma,delta))
// 		// query.add(["prevalencePrior",p,"na","prob_hasF"], prob_hasF)
// 		query.add(["prevalencePrior",p,"na","gamma_within"], gamma)
// 		query.add(["prevalencePrior",p,"na","delta_within"], delta)
// 		// query.add(["prevalencePrior",p,])
// 		// console.log(discretized_prevalence)
// 		query.add(["prevalencePrior",p,"na","beta"], postpred)
// 		// foreach(_.zip(discretized_prevalence, [0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]),
// 		// 	function(x){query.add(['prevalencePrior',p,x[1],"posteriorPredictive"], x[0])}
// 		// )
// 	})
// 	return query
// }

// var mhiter = 50000

// var resultsERP = IncrementalMH(priorModel, mhiter, {"verbose":"true"})
// //resultsERP
// var outfile = 'results/generics-tj-prevalencePrior_hasFUNIF-has0-postpred-incr'+mhiter+'a.csv'
// truthutils.erpWriter(resultsERP, outfile)
// console.log('wrote to... ' + outfile)

// map(function(x){return [x, x==0]}, _.pluck(subset(df_prior, "Property", "have manes"),"prevalence"))
//IncrementalMH(function(){return priorModel("attack swimmers")}, 10)


var priorModel = function(p){

	var propertyData = _.pluck(subset(df_prior, "Property", p),"prevalence")

	// var gamma_across = uniform(0,1)
	// var delta_across = uniform(0,20)
	var prob_hasF = beta(1,1)
	// var prob_hasF = beta(shape_alpha(gamma_across, delta_across),
	// 					  shape_beta(gamma_across, delta_across))

	var scr1 = reduce(function(d, memo) {
					    return memo + bernoulliERP.score([prob_hasF], d!=0)
						}, 0, propertyData)
	// console.log(scr1)
	factor(scr1)

	var gamma = uniform(0,1)
	var delta = uniform(0,20)

	var scr2 = reduce(function(d, memo) {
						var x = d==0? 0 : betaERP.score([shape_alpha(gamma, delta), 
					    								shape_beta(gamma, delta)], 
					    								alignPrevalence(d))
					    return memo + x
						}, 0, propertyData)
	factor(scr2)
	// console.log(scr)
	return discretizedPriorModel(prob_hasF, gamma, delta)
}


// MH(function(){return priorModel("attack swimmers")}, 10)


