---
title: "Generics -- natural cases"
author: "mht"
date: "May 16, 2015"
output: html_document
---



# Prior 2: Prevalence priors for 16 properties


```{r echo=F}
upperFirst <- function(name){
  return (paste(toupper(substr(name, 1, 1)), substr(name, 2, nchar(name)), sep=""))
}

removeS <- function(name.in){
  exceptions = c("Turtles", "Bees", "Horses", "Giraffes","Whales","Beetles","Eagles","Snakes","Moles")
  bluejays =  c("Blue jay","Blue Jay","Bluejay")
  fleas = c("Flea", "Fly")
  name<-removeSpace(name.in)
  last<-substr(name,nchar(name),nchar(name))
  last2<-substr(name,nchar(name)-1,nchar(name))
  if (name%in%exceptions){
    name.singular <- substr(name,1,nchar(name)-1)
  } else if (name%in%bluejays){
    name.singular <- "Bluejay"
  } else if (name%in%fleas){
    name.singular <- "Flea"
  } else if (name=="Wolves") {
    name.singular <- "Wolf"
  } else if (name=='Dolpin') {
    name.singular <- "Dolphin"
  } else if (name=='Giraffs') {
    name.singular <- "Giraffe"
  }  else if (last2=='es') {
    name.singular <- substr(name,1,nchar(name)-2)
  } else if (last=='s') {
    name.singular <- substr(name,1,nchar(name)-1)
  } else {
    name.singular <- name
  }
  
return(name.singular)
}

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

removeSpace <- function(name){
  if (substrRight(name,1)==' ') {
    name.edit <- substr(name,1, nchar(name)-1)
  } else {
    name.edit <- name
  }
  return(name.edit)
}

setwd(dir = '~/Documents/research/generics/analysis/')
generics.of.interest <- data.frame(
  animal=c("Robin","Leopard","Duck","Lion","Mosquito","Shark","Cardinal","Kangaroo","Peacock","Tiger","Tick","Swan"),
  property=c("lay eggs", "have spots","have wings","have manes","carry malaria",
              "attacks swimmers","are red","have pouches","have beautiful feathers","eat people","carry Lyme disease","are white"))

d<-read.csv(file = '../experiments/turk/real-kinds-prior-2/real-kinds-2-trials.csv')
d0<-read.csv(file='../experiments/turk/real-kinds-prior-2/real-kinds-2pilot5/real-kinds-2-trials.csv')

d0$workerid = max(d$workerid) + d0$workerid+1
d<-bind_rows(d,d0)

d[d$property=='are juveline',]$property<-'are juvenile'

d$animal.parsed<- factor(unlist(Map(removeS, upperFirst(as.character(d$animal)))))

```


# Response histogram

```{r}
ggplot(d, aes(x=prevalence))+geom_histogram(binwidth=5)+ggtitle('binwidth=5')
```

For each subject:

```{r}
ggplot(d, aes(x=prevalence))+
  geom_histogram(binwidth=5)+
  facet_wrap(~workerid)+
  scale_x_continuous(breaks=c(0, 50, 100))

```


# Animal production data

```{r exp2.newAnimals, fig.height=25, fig.width=16}

# retrieve novel animals (and count only one instance per subject)
animals.produced<-filter(d,
                         (!(animal.parsed %in% generics.of.interest$animal)&
                            (property_index==0)|(property_index==8)))


anim.free<-animals.produced %>%
  group_by(animal.parsed) %>%
  summarise(n = length(animal.parsed))

anim.free<-anim.free[order(anim.free$n,decreasing=T),]
top5<-anim.free %>% filter(animal.parsed %in% c("Dog","Kangaroo",'Elephant',"Giraffe","Bear"))
sum(top5$n)/300


sort(table(animals.produced$animal.parsed))[sort(table(animals.produced$animal.parsed))>10]
levels(factor(d[!(d$animal.parsed%in%generics.of.interest$animal),]$animal.parsed))
# ggplot(animals.produced, aes(x=animal.parsed))+
#   geom_histogram()+
#   #theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   coord_flip()

```

# Prevalence distributions


## Estimates for each animal.

Some of these animals have very few responses, owing to the fact that they were produced by just one or a few subjects. Ordering is alphabetical by animal name. Light blue bars indicate the category of interest for each property (for the generic).

```{r exp2.estimatesByAnimal, fig.height=15, fig.width=36}

d.tidy<- d %>%
  group_by(property,animal.parsed) %>%
  summarise(prev = mean(prevalence),
            sterr=sem(prevalence)) %>%
  filter(!(is.na(sterr)))

generics.of.interest$combined <- paste(generics.of.interest$property, 
                                       generics.of.interest$animal)
d.tidy$combined <- paste(d.tidy$property, d.tidy$animal.parsed)

d.tidy$interest<-d.tidy$combined %in% generics.of.interest$combined

ggplot(data=d.tidy, aes(x=animal.parsed, y=prev, fill=interest))+
  geom_bar(stat='identity',position=position_dodge())+
  facet_wrap(~property)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Reducing this plot to only the animals that were given to subjects

```{r exp2.estimatesByAnimal.reduced, fig.height=10, fig.width=20}

d.tidy.sub <- d.tidy %>% 
  filter(animal.parsed %in% generics.of.interest$animal)
#   group_by(animal.parsed) %>%
#   mutate(count = length(animal.parsed)) %>%
#   filter(count > 10)

ggplot(data=d.tidy.sub, aes(x=animal.parsed, y=prev, fill=interest))+
  geom_bar(stat='identity',position=position_dodge())+
  geom_errorbar(aes(ymin=prev-2*sterr,ymax=prev+2*sterr),
                position=position_dodge(),width=0.5)+
  facet_wrap(~property)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

d.tidy.sub %>%
  filter(combined %in% generics.of.interest$combined)


```


## Distribution by animal

Here, I plot the distribution of prevalence after summarizing an average prevalence for each animal. Hence, a sample from this distribution is an animal category (with an associated prevalence of the property). Again note:: many of these categories have very few responses.

Green line indicates prevalence for target category.
```{r}
ggplot(data=d.tidy, aes(x=prev))+
  geom_vline(data=filter(d.tidy,interest), aes(xintercept=prev),
             colour='#2ca25f',size=1.3)+
  geom_histogram(binwidth=5)+
  facet_wrap(~property)
```

Binned distributions (for model)

```{r}
d.tidy<- d.tidy %>% mutate(roundval=round(prev/10)*10) 

d.anim.bin<- d.tidy %>%
  group_by(property, roundval) %>%
  summarise(count = length(roundval)) %>%
  ungroup() %>% group_by(property) %>%
  mutate(prob = count/sum(count),
         roundval = to.n(roundval))

ggplot(d.anim.bin, aes(x=roundval, y=prob))+
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~property)+
  xlab("prevalence")+
  ylab("proportion of responses\n")+
  #scale_fill_brewer(palette='Pastel1',type='qual')+
 # scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_discrete(breaks=c(0,20,40,60,80,100))+#,limits=c(-5,105))+
 # theme_blackDisplay()+ 
  guides(fill=guide_legend(title="property"))+
#  theme(legend.key.size=unit(2, "lines"),
#        legend.text.align=NULL)+
  guides(fill=F)

d.anim.bin %>% select(-prob) %>% spread(roundval, count)



```



## Distribution by response

Here, I don't include the intermediate step of summarising by animal kind. Instead, I just plot the density directly from subjects' responses. Again, green line indicates prevalence for target categogry.

```{r}

d.interest<-d.tidy %>% filter(interest)

selection <-c("are female", "have wings", "have manes", "carry malaria")

ggplot(data = filter(d,property%in%selection), aes(x=prevalence))+
  #geom_histogram()+
  geom_density(adjust=0.5, fill='grey')+
  facet_wrap(~property,scales='free')+
  xlim(0,100)

+
 # geom_vline(data=d.interest, aes(xintercept=prev), colour='#2ca25f',size=1.3)
```


Binned distributions (for model)

```{r}
d <- d %>% mutate(roundval=factor(round(prevalence/10)*10))

d.bin<- d %>%
  group_by(property, roundval) %>%
  summarise(count = length(roundval)) %>%
  ungroup() %>% group_by(property) %>%
  mutate(prob = count/sum(count),
         roundval = to.n(roundval))


# Filter out given animals.


#filter(animal.parsed %in% generics.of.interest$animal)

ggplot(d.bin, aes(x=roundval, y=prob))+
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~property)+
  xlab("prevalence")+
  ylab("proportion of responses\n")+
  #scale_fill_brewer(palette='Pastel1',type='qual')+
 # scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_discrete(breaks=c(0,20,40,60,80,100))+#,limits=c(-5,105))+
 # theme_blackDisplay()+ 
  guides(fill=guide_legend(title="property"))+
#  theme(legend.key.size=unit(2, "lines"),
#        legend.text.align=NULL)+
  guides(fill=F)

filter(d, property=='attack swimmers' & prevalence>90)$animal.parsed
```

Looks like "Mosquitos attack swimmers." is probably true.


```{r}
# d.out<-d.bin %>% select(-prob) %>% spread(roundval, count)
# d.out[is.na(d.out)] <- 1 # remove NAs (which are 0s); set to 1 so there is some probability mass...
# write.csv(d.out,file='../cbg2010-replication/models/prevalencePrior_16props.csv')
```




# Truth judgment: Experiment 1






Process for webppl
```{r}
# tj<-read.csv(file = '../experiments/turk/real-kinds-truth-1/real-kinds-truth-1-trials.csv')
# tj$response<-factor(tj$response,levels=c("disagree-key","agree-key"),
#        labels=c("mu","generic is true"))
# tj$sentence <- gsub('&quotechar','', tj$sentence)
# tj$sentence <- gsub('lyme','Lyme', tj$sentence)
# 
# tj.d<-tj%>% select(sentence, response, workerid) %>%
#   spread(workerid, response)
# 
# write.csv(tj.d,'real-kinds-truth-1-trials-n100-webpplfriendly.csv')
```

```{r tj1}

d.path <- "~/Documents/research/generics/data/real-kinds/"
tj <-read.csv(file = paste(d.path,'real-kinds-truth-1-trials.csv',sep=''))
c <- read.csv(file = paste(d.path,'real-kinds-truth-1-catch_trials.csv', sep=''))
s<- read.csv(file = paste(d.path,'real-kinds-truth-1-subject_information.csv', sep=''))
nonenglish<-c(1,4,19,38,39)
catch<-c[c$pass==0,]$workerid

tj <- tj %>% filter(!(workerid %in% c(nonenglish, catch)))

### bootstrap CI
bootstrap.ci <- function(x){
  agr = aggregate(response ~ sentence, data=x, FUN=mean)
  agr$CILow = aggregate(response ~ sentence, data=x, FUN=ci.low)$response
  agr$CIHigh = aggregate(response ~ sentence, data=x, FUN=ci.high)$response
  agr$YMin = agr$response - agr$CILow
  agr$YMax = agr$response + agr$CIHigh
  return(agr)
}


tj.bs<-bootstrap.ci(tj %>% mutate(response = as.numeric(response=='agree-key')))

tj.bs$sentence <- gsub('&quotechar','', tj.bs$sentence)
tj.bs$sentence <- gsub('lyme','Lyme', tj.bs$sentence)

tj.bs$sentence<-with(tj.bs, reorder(sentence, response, function(x) x))


ggplot(data=tj.bs, aes(x=sentence, y=response-0.5))+
  geom_bar(stat='identity',position=position_dodge(), alpha=0.8,
           fill='grey19')+
  geom_errorbar(aes(ymin=YMin-0.5,ymax=YMax-0.5), width=0.5, size = 1.5,
                color='black')+
  #theme_blackDisplay()+
  #theme(axis.text.x = element_text(angle = 45, hjust = 1,
   #                                vjust=1))+
 # ylim(-.5,0.5)+
  xlab("")+
  ylab("\n proportion of subjects who agree")+
  scale_y_continuous(breaks=c(-0.5,0,0.5),labels=c("0","0.5","1"))+
  coord_flip()

ggsave(file='~/Box Sync/talks/esslli-2015-generics/truhtjudge_n100.pdf',
       width=24,height=20)
```



### logisitic regression for the obvious
```{r}


sentence.class<- data.frame(sentence = levels(tj$sentence),
                            class = c("t","t","t","f","i",'t','f','i','t','f','i','t','f','f','t','i',
                                      'f','t','i','t','f','f','i','i','t','t','f','f','t','f'))

tj.s<-left_join(tj, sentence.class, by='sentence')
tj.s$class<-factor(tj.s$class,levels=c('i','t','f'))

rs0<-glmer(data=tj.s, response~ -1 + class + (1  | workerid), family='binomial')
summary(rs0)
```


The 30 generic sentences fell into 3 categories as predicted: definitely true, definitely false, and neither true nor false (Figure \red{fig:tj1b}). We entered participants' agreement judgments into a mixed-effect logistic regression with random by-participant effects of intercept. This \emph{a priori} distinction was a significant predictor of the eventual truth judgments: true generics were significantly more likely to be agreed with than the indeterminate generics ($\beta = 3.14; SE = 0.15; z = -20.9$) and false generics were significantly less likely to be agreed with than the indeterminate generics ($\beta = -2.07; SE = 0.15; z = -14.1$). Rather interesting, indeterminate generics were agreed with \emph{less} likely than chance ($\beta = -0.49; SE = 0.09; z = -5.3$).




Boring renaming of properties, and getting prior estimations for negations by subtracting positive form from 100

Scatterplot of raw prevalence vs. proportion of "agree" responses

```{r}

d.tidy.sub[d.tidy.sub$property == 'attacks swimmers',]$property <- 'attack swimmers'
d.tidy.sub$sentence <- with(d.tidy.sub, paste(paste(animal.parsed,'s',sep=''), paste(property,'.',sep='')))

m.tidy<-left_join(tj.bs,d.tidy.sub, by="sentence")

m.tidy[m.tidy$sentence=='Mosquitos dont carry malaria.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Mosquitos carry malaria.',]$prev

m.tidy[m.tidy$sentence=='Sharks dont attack swimmers.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Sharks attack swimmers.',]$prev

m.tidy[m.tidy$sentence=='Peacocks dont have beautiful feathers.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Peacocks have beautiful feathers.',]$prev

m.tidy[m.tidy$sentence=='Ticks dont carry Lyme disease.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Ticks carry Lyme disease.',]$prev

m.tidy[m.tidy$sentence=='Tigers dont eat people.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Tigers eat people.',]$prev

m.tidy<-m.tidy %>%
  filter(!is.na(prev))

ggplot(m.tidy,aes(x=prev,y=response))+
  geom_point()

with(m.tidy, cor(prev,response))

quantile(m.tidy$prev)

with(filter(m.tidy,(prev > quantile(m.tidy$prev)["25%"] & 
                      prev < quantile(m.tidy$prev)["75%"])), cor(prev,response))
range(filter(m.tidy,(prev > quantile(m.tidy$prev)["25%"] & 
                      prev < quantile(m.tidy$prev)["75%"]))$prev)

```


Truth judgments for these generic sentences were correlated with the prevalence of the property for the target category elicited in Expt.~1a ($r = 0.73$, Figure \ref{fig:scatterprev}). This is, of course, expected given that high-prevalence true generics (e.g. ``Leopards have spots.'') and low-prevalence false generics (e.g. ``Leopards have wings.'') were used. 
However, large deviations from a purely within-category prevalence account remain: Generics with intermediate prevalences (Prevalence quartiles 2 and 3: $ 22\% < prevalence < 62\%$), exhibited no correlation with truth judgments (r_{Q2,3} = -0.08).


## lvRSA model predictions

#### posterior over parameters

```{r}
m.path<-"~/Documents/research/generics/models/results/"
m<-read.csv(paste(m.path, 'generics_truthJudge_rationality-softmax-n100_hashmh1000.csv', sep=''))


m.params<- m %>% filter(Item %in% c("speakerOptimality", "cost", "softmax"))
samples  = 1000
m.params <- data.frame(Item =  rep(m.params$Item, 1+samples*m.params$Probability),
                         Value = rep(m.params$Value, 1+samples*m.params$Probability)
                       )
ggplot(m.params, aes(x=Value))+
  geom_histogram()+
  facet_wrap(~Item, scales='free')

```

#### posterior predictive
```{r}

m.pp<- m %>% filter(!(Item %in% c("speakerOptimality", "cost", "softmax")))

m.pp.exp<- m.pp %>%
  rename(sentence = Item) %>%
  group_by(sentence) %>%
  summarise(posteriorPred = sum(Value*Probability))


combined.model.data<- left_join(m.pp.exp, m.tidy, by='sentence')

with(combined.model.data, cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev>25 & prev < 75)), cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev > quantile(m.tidy$prev)["25%"] & 
            prev < quantile(m.tidy$prev)["75%"])), cor(posteriorPred,response))




with(combined.model.data, cor(posteriorPred, response, method='spearman'))


with(combined.model.data, cor(prev, response))
with(combined.model.data, cor(prev, response, method='spearman'))


combined.model.data$sentence<-with(combined.model.data, reorder(sentence, response, function(x) -x))



qplot(data=combined.model.data,
      x=posteriorPred,y=response,
      color=sentence)+
  geom_point(size=4)+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=1,linetype=2, size=2,color='black')+
  xlab("\n model posterior predictive")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed()
#+
#  theme_blackDisplay()
  
#ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-lvrsa.pdf',
#       width=13,height=13)

```

Doing TFBT with speaker optimality (at the S1 level) as a free parameter

```{r}
model.posteriorpred <-read.csv('../cbg2010-replication/models/model_predictions/generics_truthJudge_3_postpred_n100_mh1000.csv',header=F,
                               col.names=c("sentence","posteriorPred"))

model.posteriorpred <-read.csv('~/Documents/research/generics/cbg2010-replication/models/generics_truthJudge_3_rationality1_n100_hashmh100.csv')


combined.model.data<- left_join(m.pp, m.tidy, by='sentence')

with(combined.model.data, cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev>25 & prev < 75)), cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev > quantile(m.tidy$prev)["25%"] & 
            prev < quantile(m.tidy$prev)["75%"])), cor(posteriorPred,response))




with(combined.model.data, cor(posteriorPred, response, method='spearman'))


with(combined.model.data, cor(prev, response))
with(combined.model.data, cor(prev, response, method='spearman'))


combined.model.data$sentence<-with(combined.model.data, reorder(sentence, response, function(x) -x))



qplot(data=combined.model.data,
      x=posteriorPred,y=response,
      color=sentence)+
  geom_point(size=4)+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=1,linetype=2, size=2,color='black')+
  xlab("\n model posterior predictive")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed()
#+
#  theme_blackDisplay()
  
ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-lvrsa.pdf',
       width=13,height=13)

qplot(data=combined.model.data,
      x=prev,y=response,
      color=sentence)+
  geom_point(size=4)+
    geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=0.01,linetype=2, size =2,color='white')+
  xlab("\n (raw) prevalence")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed(ratio=100)+
  theme_blackDisplay()

ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-prevalence.pdf',
       width=13,height=13)

```


```{r}
m<-read.csv('~/Documents/research/generics/cbg2010-replication/models/generics_truthJudge_3_rationality_n100_mh1000.csv', header =F)
samples  = 1000

# f.params0<- data.frame(Parameter = rep(f.tidy$param, 1+samples*f.tidy$Probability),
#                        Response = rep(f.tidy$Value, 1+samples*f.tidy$Probability))
# f.params.tidy<- f.params0 %>%
#   separate(Parameter, by='.', into=c("Item", "Question", "Parameter"))

f.params <- data.frame(Value = rep(m$V1, 1+samples*m$V2))

qplot(data=f.params, x=Value,geom='histogram')

  ```
