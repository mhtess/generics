---
title: "Generics -- natural cases"
author: "mht"
date: "May 16, 2015"
output: html_document
---



# Prior 2: Prevalence priors for 16 properties


```{r echo=F}
upperFirst <- function(name){
  return (paste(toupper(substr(name, 1, 1)), substr(name, 2, nchar(name)), sep=""))
}

removeS <- function(name.in){
  exceptions = c("Turtles", "Bees", "Horses", "Giraffes","Whales","Beetles","Eagles","Snakes","Moles")
  bluejays =  c("Blue jay","Blue Jay","Bluejay")
  fleas = c("Flea", "Fly")
  name<-removeSpace(name.in)
  last<-substr(name,nchar(name),nchar(name))
  last2<-substr(name,nchar(name)-1,nchar(name))
  if (name%in%exceptions){
    name.singular <- substr(name,1,nchar(name)-1)
  } else if (name%in%bluejays){
    name.singular <- "Bluejay"
  } else if (name%in%fleas){
    name.singular <- "Flea"
  } else if (name=="Wolves") {
    name.singular <- "Wolf"
  } else if (name=='Dolpin') {
    name.singular <- "Dolphin"
  } else if (name=='Giraffs') {
    name.singular <- "Giraffe"
  }  else if (last2=='es') {
    name.singular <- substr(name,1,nchar(name)-2)
  } else if (last=='s') {
    name.singular <- substr(name,1,nchar(name)-1)
  } else {
    name.singular <- name
  }
  
return(name.singular)
}

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

removeSpace <- function(name){
  if (substrRight(name,1)==' ') {
    name.edit <- substr(name,1, nchar(name)-1)
  } else {
    name.edit <- name
  }
  return(name.edit)
}

setwd(dir = '~/Documents/research/generics/analysis/')
generics.of.interest <- data.frame(
  animal=c("Robin","Leopard","Duck","Lion","Mosquito","Shark","Cardinal","Kangaroo","Peacock","Tiger","Tick","Swan"),
  property=c("lay eggs", "have spots","have wings","have manes","carry malaria",
              "attacks swimmers","are red","have pouches","have beautiful feathers","eat people","carry Lyme disease","are white"))

d<-read.csv(file = '../experiments/turk/real-kinds-prior-2/real-kinds-2-trials.csv')
d0<-read.csv(file='../experiments/turk/real-kinds-prior-2/real-kinds-2pilot5/real-kinds-2-trials.csv')

d0$workerid = max(d$workerid) + d0$workerid+1
d<-bind_rows(d,d0)

d[d$property=='are juveline',]$property<-'are juvenile'




d$animal.parsed<- factor(unlist(Map(removeS, upperFirst(as.character(d$animal)))))

```


Resolve differences between coding of prior elicitation and truth judgment task
```{r tj.prior.out}

d.out<-d %>% select(workerid, trial_type, property, prevalence, animal)
d.out[d.out$property == 'attacks swimmers',]$property <- 'attack swimmers'

rexp <- "^(\\w+)\\s?(.*)$"
d.path <- "~/Documents/research/generics/data/real-kinds/"

c <- read.csv(file = paste(d.path,'real-kinds-truth-1-catch_trials.csv', sep=''))

nonenglish<-c(1,4,19,38,39)
catch<-c[c$pass==0,]$workerid

tj <-read.csv(file = paste(d.path,'real-kinds-truth-1-trials.csv',sep=''))
tj <- tj %>% filter(!(workerid %in% c(nonenglish, catch)))

tj<- tj %>% 
  mutate(Category = sub(rexp,"\\1",sentence),
         Property = sub(rexp,"\\2",sentence),
         Property = gsub('&quotechar','',Property),
         Property = gsub('lyme','Lyme',Property)         
         ) %>%
  select(-rt, -sentence) %>%
  mutate(Property = factor(substr(Property,1,nchar(Property)-1)))


d.out <- d.out %>%
  rename(Property = property,
         Category = animal)
write.csv(d.out,file='~/Documents/research/generics/models/data/real-kinds-prior-2-trials-formatted.csv')
write.csv(tj,file='~/Documents/research/generics/models/data/real-kinds-truth-1-trials-formatted.csv')


```




# Response histogram

```{r}
ggplot(d, aes(x=prevalence))+geom_histogram(binwidth=5)+ggtitle('binwidth=5')
```

For each subject:

```{r}
ggplot(d, aes(x=prevalence))+
  geom_histogram(binwidth=5)+
  facet_wrap(~workerid)+
  scale_x_continuous(breaks=c(0, 50, 100))

```


# Animal production data

```{r exp2.newAnimals, fig.height=25, fig.width=16}

# retrieve novel animals (and count only one instance per subject)
animals.produced<-filter(d,
                         (!(animal.parsed %in% generics.of.interest$animal)&
                            (property_index==0)|(property_index==8)))


anim.free<-animals.produced %>%
  group_by(animal.parsed) %>%
  summarise(n = length(animal.parsed))

anim.free<-anim.free[order(anim.free$n,decreasing=T),]
top5<-anim.free %>% filter(animal.parsed %in% c("Dog","Kangaroo",'Elephant',"Giraffe","Bear"))
sum(top5$n)/300


sort(table(animals.produced$animal.parsed))[sort(table(animals.produced$animal.parsed))>10]
levels(factor(d[!(d$animal.parsed%in%generics.of.interest$animal),]$animal.parsed))
# ggplot(animals.produced, aes(x=animal.parsed))+
#   geom_histogram()+
#   #theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   coord_flip()

```

# Prevalence distributions


## Estimates for each animal.

Some of these animals have very few responses, owing to the fact that they were produced by just one or a few subjects. Ordering is alphabetical by animal name. Light blue bars indicate the category of interest for each property (for the generic).

```{r exp2.estimatesByAnimal, fig.height=15, fig.width=36}

d.tidy<- d %>%
  group_by(property,animal.parsed) %>%
  summarise(prev = mean(prevalence),
            sterr=sem(prevalence)) %>%
  filter(!(is.na(sterr)))

generics.of.interest$combined <- paste(generics.of.interest$property, 
                                       generics.of.interest$animal)
d.tidy$combined <- paste(d.tidy$property, d.tidy$animal.parsed)

d.tidy$interest<-d.tidy$combined %in% generics.of.interest$combined

ggplot(data=d.tidy, aes(x=animal.parsed, y=prev, fill=interest))+
  geom_bar(stat='identity',position=position_dodge())+
  facet_wrap(~property)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Reducing this plot to only the animals that were given to subjects

```{r exp2.estimatesByAnimal.reduced, fig.height=10, fig.width=20}

d.tidy.sub <- d.tidy %>% 
  filter(animal.parsed %in% generics.of.interest$animal)
#   group_by(animal.parsed) %>%
#   mutate(count = length(animal.parsed)) %>%
#   filter(count > 10)

ggplot(data=d.tidy.sub, aes(x=animal.parsed, y=prev, fill=interest))+
  geom_bar(stat='identity',position=position_dodge())+
  geom_errorbar(aes(ymin=prev-2*sterr,ymax=prev+2*sterr),
                position=position_dodge(),width=0.5)+
  facet_wrap(~property)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

d.tidy.sub %>%
  filter(combined %in% generics.of.interest$combined)


```


## Distribution by animal

Here, I plot the distribution of prevalence after summarizing an average prevalence for each animal. Hence, a sample from this distribution is an animal category (with an associated prevalence of the property). Again note:: many of these categories have very few responses.

Green line indicates prevalence for target category.
```{r}
ggplot(data=d.tidy, aes(x=prev))+
  geom_vline(data=filter(d.tidy,interest), aes(xintercept=prev),
             colour='#2ca25f',size=1.3)+
  geom_histogram(binwidth=5)+
  facet_wrap(~property)
```

Binned distributions (for model)

```{r}
d.tidy<- d.tidy %>% mutate(roundval=round(prev/10)*10) 

d.anim.bin<- d.tidy %>%
  group_by(property, roundval) %>%
  summarise(count = length(roundval)) %>%
  ungroup() %>% group_by(property) %>%
  mutate(prob = count/sum(count),
         roundval = to.n(roundval))

ggplot(d.anim.bin, aes(x=roundval, y=prob))+
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~property)+
  xlab("prevalence")+
  ylab("proportion of responses\n")+
  #scale_fill_brewer(palette='Pastel1',type='qual')+
 # scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_discrete(breaks=c(0,20,40,60,80,100))+#,limits=c(-5,105))+
 # theme_blackDisplay()+ 
  guides(fill=guide_legend(title="property"))+
#  theme(legend.key.size=unit(2, "lines"),
#        legend.text.align=NULL)+
  guides(fill=F)

d.anim.bin %>% select(-prob) %>% spread(roundval, count)



```



## Distribution by response

Here, I don't include the intermediate step of summarising by animal kind. Instead, I just plot the density directly from subjects' responses. Again, green line indicates prevalence for target categogry.

```{r}

d.interest<-d.tidy %>% filter(interest)

selection <-c("are female", "have wings", "have manes", "carry malaria")

ggplot(data = filter(d,property%in%selection), aes(x=prevalence))+
  #geom_histogram()+
  geom_density(adjust=0.5, fill='grey')+
  facet_wrap(~property,scales='free')+
  xlim(0,100)

+
 # geom_vline(data=d.interest, aes(xintercept=prev), colour='#2ca25f',size=1.3)
```


Binned distributions (for model)

```{r}
d <- d %>% mutate(roundval=factor(round(prevalence/10)*10))

d.bin<- d %>%
  group_by(property, roundval) %>%
  summarise(count = length(roundval)) %>%
  ungroup() %>% group_by(property) %>%
  mutate(prob = count/sum(count),
         roundval = to.n(roundval))


# Filter out given animals.


#filter(animal.parsed %in% generics.of.interest$animal)

ggplot(d.bin, aes(x=roundval, y=prob))+
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~property)+
  xlab("prevalence")+
  ylab("proportion of responses\n")+
  #scale_fill_brewer(palette='Pastel1',type='qual')+
 # scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_discrete(breaks=c(0,20,40,60,80,100))+#,limits=c(-5,105))+
 # theme_blackDisplay()+ 
  guides(fill=guide_legend(title="property"))+
#  theme(legend.key.size=unit(2, "lines"),
#        legend.text.align=NULL)+
  guides(fill=F)

filter(d, property=='attack swimmers' & prevalence>90)$animal.parsed
```

Looks like "Mosquitos attack swimmers." is probably true.


```{r}
# d.out<-d.bin %>% select(-prob) %>% spread(roundval, count)
# d.out[is.na(d.out)] <- 1 # remove NAs (which are 0s); set to 1 so there is some probability mass...
# write.csv(d.out,file='../cbg2010-replication/models/prevalencePrior_16props.csv')
```


# FBT on natural cases priors

```{r}

samples = 10000
d<- read.csv(paste('~/Documents/research/generics/models/results/naturalkinds-priors-flatAcross_incrMH',samples,'.csv',sep=''))
d<- read.csv(paste('~/Documents/research/generics/models/results/naturalkinds-priors-heirarchicalAcross_incrMH',samples,'.csv',sep=''))

d.params <- data.frame(Property = rep(d$Property, 
                                       1+samples*d$Probability),
                       Parameter = rep(d$Parameter, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))
  
d.param.stats <- d.params %>%
  group_by(Property, Parameter) %>%
  summarise(expval = mean(Value),
            credHigh = quantile(Value, probs= 0.975),
            credLow = quantile(Value, probs = 0.025))


# d.param.stats$Property<-with((d.param.stats %>% 
#                                filter(Parameter == 'gamma_within')), 
#                  reorder(Property, expval, function(x) -x))
# 



ggplot(d.param.stats, aes(x=Property, y=expval, fill=Property))+
  geom_bar(stat='identity')+
  geom_errorbar(aes(ymin = credLow, ymax = credHigh))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,
                                   vjust=1))+
  facet_wrap(~Parameter, scales='free')+
  guides(fill=F)



```


Reconstruct prevalence priors

```{r priors2.fbt.prevalencepriors}
d.samples<-data.frame()

shape1 = function(gamma,delta){return (gamma * delta)}
shape2= function(gamma,delta){return ((1-gamma) * delta)}

# for model with "flat" hasProperty levels
for (i in 1:1000){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alph = shape1(gamma_within,delta_within),
           bet = shape2(gamma_within, delta_within))%>%
    group_by(Property) %>%
    mutate(doesHaveF = rbinom(1,1,hasF)) %>%
   select(-gamma_within, -delta_within) %>%
    group_by(Property) %>%
    mutate(prevalence = if(doesHaveF==0) {0} 
              else {rbeta(1, alph, bet)})
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}


# for model with 2 betas
for (i in 1:1000){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alpha0 = shape1(gamma_across,delta_across),
           beta0 = shape2(gamma_across, delta_across),
           alpha1 = shape1(gamma_within,delta_within),
           beta1 = shape2(gamma_within, delta_within))%>%
    group_by(Property) %>%
    mutate(prevAcross = rbeta(1, alpha0, beta0),
           doesHaveF = rbinom(1,1,prevAcross),
           prevWithin = rbeta(1, alpha1, beta1)) %>%
   select(-ends_with("_within"),
          -ends_with("_across")) %>%
    group_by(Property) %>%
    mutate(prevalence = if(doesHaveF==0) {0} 
              else {prevWithin}) %>%
    select(Property, prevalence)
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}




ggplot(d.samples, aes(x=prevalence))+
  geom_histogram()+
  facet_wrap(~Property)
# 
# d.samples$Item<-factor(d.samples$Item,
#                        levels=c("body_parts",
#                                 "vague_parts",
#                                 "color_parts",
#                                 "common_accidental",
#                                 "rare_accidental"))

# a<-ggplot(d.samples, 
#           aes(x=prevalence, color=Property))+
#   geom_density(size=1.1)+
#   scale_color_brewer(palette='Set1')+
#   xlab("Prevalence")+
#   ylab("Posterior density")+
#   theme(legend.position=c(0.7,0.65))+
#   guides(fill=F)+ facet_wrap(~Property)
# 

ggplot(d.samples %>% filter(prevalence!=0), 
          aes(x=prevalence, color=Property))+
  geom_histogram()+
  #scale_color_brewer(palette='Set1')+
  xlab("Prevalence")+
  ylab("Posterior density")+
  theme(legend.position=c(0.7,0.65))+
  guides(color=F)+ 
  facet_wrap(~Property)

a
```



## Infer prevalence of generic cases

```{r generic.case.prevalence}
samples = 10000
d<- read.csv(paste('~/Documents/research/generics/models/results/naturalkinds-prevalence_incrMH',samples,'.csv',sep=''))


d.exp <- d %>% filter(Parameter == 'expectation')
d.exp.params <- data.frame(Property = rep(d$Property, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))
ggplot(d.exp.params, aes(x=Value))+
  geom_histogram()+
  facet_wrap(~Property)


d <- d %>% filter(!(Parameter == 'expectation'))
d.params <- data.frame(Property = rep(d$Property, 
                                       1+samples*d$Probability),
                       Parameter = rep(d$Parameter, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))
  
d.param.stats <- d.params %>%
  group_by(Property, Parameter) %>%
  summarise(expval = mean(Value),
            credHigh = quantile(Value, probs= 0.975),
            credLow = quantile(Value, probs = 0.025))%>%
  filter(Parameter == 'gamma')




d.param.stats$Property<-with(d.param.stats, 
                 reorder(Property, expval, function(x) -x))




ggplot(d.param.stats, aes(x=Property, y=expval, fill=Property))+
  geom_bar(stat='identity')+
  geom_errorbar(aes(ymin = credLow, ymax = credHigh))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,
                                   vjust=1))+
  facet_wrap(~Parameter, scales='free')+
  guides(fill=F)



```

Reconstruct distribution

```{r}
shape1 = function(gamma,delta){return (gamma * delta)}
shape2= function(gamma,delta){return ((1-gamma) * delta)}
d.samples<-data.frame()
  

# for model with "flat" hasProperty levels
for (i in 1:1000){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alph = shape1(gamma,delta),
           bet = shape2(gamma, delta))%>%
    select(-gamma, -delta) %>%
    group_by(Property) %>%
    mutate(prevalence = rbeta(1, alph, bet))
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}

ggplot(d.samples %>% filter(prevalence!=0), 
          aes(x=prevalence, color=Property))+
  geom_histogram()+
  #scale_color_brewer(palette='Set1')+
  xlab("Prevalence")+
  ylab("Posterior density")+
  theme(legend.position=c(0.7,0.65))+
  guides(color=F)+ 
  facet_wrap(~Property)



```



# Truth judgment: Experiment 1






Process for webppl
```{r}
# tj<-read.csv(file = '../experiments/turk/real-kinds-truth-1/real-kinds-truth-1-trials.csv')
# tj$response<-factor(tj$response,levels=c("disagree-key","agree-key"),
#        labels=c("mu","generic is true"))
# tj$sentence <- gsub('&quotechar','', tj$sentence)
# tj$sentence <- gsub('lyme','Lyme', tj$sentence)
# 
# tj.d<-tj%>% select(sentence, response, workerid) %>%
#   spread(workerid, response)
# 
# write.csv(tj.d,'real-kinds-truth-1-trials-n100-webpplfriendly.csv')
```

```{r tj1}

d.path <- "~/Documents/research/generics/data/real-kinds/"
tj <-read.csv(file = paste(d.path,'real-kinds-truth-1-trials.csv',sep=''))
c <- read.csv(file = paste(d.path,'real-kinds-truth-1-catch_trials.csv', sep=''))
s<- read.csv(file = paste(d.path,'real-kinds-truth-1-subject_information.csv', sep=''))
nonenglish<-c(1,4,19,38,39)
catch<-c[c$pass==0,]$workerid

tj <- tj %>% filter(!(workerid %in% c(nonenglish, catch)))

### bootstrap CI
bootstrap.ci <- function(x){
  agr = aggregate(response ~ sentence, data=x, FUN=mean)
  agr$CILow = aggregate(response ~ sentence, data=x, FUN=ci.low)$response
  agr$CIHigh = aggregate(response ~ sentence, data=x, FUN=ci.high)$response
  agr$YMin = agr$response - agr$CILow
  agr$YMax = agr$response + agr$CIHigh
  return(agr)
}


tj.bs<-bootstrap.ci(tj %>% mutate(response = as.numeric(response=='agree-key')))

tj.bs$sentence <- gsub('&quotechar','', tj.bs$sentence)
tj.bs$sentence <- gsub('lyme','Lyme', tj.bs$sentence)

tj.bs$sentence<-with(tj.bs, reorder(sentence, response, function(x) x))


ggplot(data=tj.bs, aes(x=sentence, y=response-0.5))+
  geom_bar(stat='identity',position=position_dodge(), alpha=0.8,
           fill='grey19')+
  geom_errorbar(aes(ymin=YMin-0.5,ymax=YMax-0.5), width=0.5, size = 1.5,
                color='black')+
  #theme_blackDisplay()+
  #theme(axis.text.x = element_text(angle = 45, hjust = 1,
   #                                vjust=1))+
 # ylim(-.5,0.5)+
  xlab("")+
  ylab("\n proportion of subjects who agree")+
  scale_y_continuous(breaks=c(-0.5,0,0.5),labels=c("0","0.5","1"))+
  coord_flip()

# ggsave(file='~/Box Sync/talks/esslli-2015-generics/truhtjudge_n100.pdf',
#        width=24,height=20)
```



### logisitic regression for the obvious
```{r}


sentence.class<- data.frame(sentence = levels(tj$sentence),
                            class = c("t","t","t","f","i",'t','f','i','t','f','i','t','f','f','t','i',
                                      'f','t','i','t','f','f','i','i','t','t','f','f','t','f'))

tj.s<-left_join(tj, sentence.class, by='sentence')
tj.s$class<-factor(tj.s$class,levels=c('i','t','f'))

rs0<-glmer(data=tj.s, response~ -1 + class + (1  | workerid), family='binomial')
summary(rs0)
```


The 30 generic sentences fell into 3 categories as predicted: definitely true, definitely false, and neither true nor false (Figure \red{fig:tj1b}). We entered participants' agreement judgments into a mixed-effect logistic regression with random by-participant effects of intercept. This \emph{a priori} distinction was a significant predictor of the eventual truth judgments: true generics were significantly more likely to be agreed with than the indeterminate generics ($\beta = 3.14; SE = 0.15; z = -20.9$) and false generics were significantly less likely to be agreed with than the indeterminate generics ($\beta = -2.07; SE = 0.15; z = -14.1$). Rather interesting, indeterminate generics were agreed with \emph{less} likely than chance ($\beta = -0.49; SE = 0.09; z = -5.3$).




Boring renaming of properties, and getting prior estimations for negations by subtracting positive form from 100

Scatterplot of raw prevalence vs. proportion of "agree" responses

```{r}

d.tidy.sub[d.tidy.sub$property == 'attacks swimmers',]$property <- 'attack swimmers'
d.tidy.sub$sentence <- with(d.tidy.sub, 
                            paste(paste(animal.parsed,'s',sep=''), 
                                  paste(property,'.',sep='')))

m.tidy<-left_join(tj.bs,d.tidy.sub, by="sentence")

m.tidy[m.tidy$sentence=='Mosquitos dont carry malaria.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Mosquitos carry malaria.',]$prev

m.tidy[m.tidy$sentence=='Sharks dont attack swimmers.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Sharks attack swimmers.',]$prev

m.tidy[m.tidy$sentence=='Peacocks dont have beautiful feathers.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Peacocks have beautiful feathers.',]$prev

m.tidy[m.tidy$sentence=='Ticks dont carry Lyme disease.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Ticks carry Lyme disease.',]$prev

m.tidy[m.tidy$sentence=='Tigers dont eat people.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Tigers eat people.',]$prev

m.tidy<-m.tidy %>%
  filter(!is.na(prev))

ggplot(m.tidy,aes(x=prev,y=response))+
  geom_point()

with(m.tidy, cor(prev,response))

quantile(m.tidy$prev)

with(filter(m.tidy,(prev > quantile(m.tidy$prev)["25%"] & 
                      prev < quantile(m.tidy$prev)["75%"])), cor(prev,response))
range(filter(m.tidy,(prev > quantile(m.tidy$prev)["25%"] & 
                      prev < quantile(m.tidy$prev)["75%"]))$prev)

```


Truth judgments for these generic sentences were correlated with the prevalence of the property for the target category elicited in Expt.~1a ($r = 0.73$, Figure \ref{fig:scatterprev}). This is, of course, expected given that high-prevalence true generics (e.g. ``Leopards have spots.'') and low-prevalence false generics (e.g. ``Leopards have wings.'') were used. 
However, large deviations from a purely within-category prevalence account remain: Generics with intermediate prevalences (Prevalence quartiles 2 and 3: $ 22\% < prevalence < 62\%$), exhibited no correlation with truth judgments (r_{Q2,3} = -0.08).


## lvRSA model predictions

#### posterior over parameters

```{r}
m.path<-"~/Documents/research/generics/models/results/"
#m<-read.csv(paste(m.path, 'generics_truthJudge_rationality-n100_hashmh10000a.csv', sep=''))

prioriter=10000
samples=10000

prefix<-paste('fullBayesian-wPrev-so-priorhash',prioriter,'_hashmh',samples,sep='')
m<-read.csv(paste(m.path, 'generics-tj-',prefix, '.csv', sep=''))

m.prev <- m %>% 
  filter(substring(Item,1,11) == 'prevalence_')

m.prev <- data.frame(Item =  rep(m.prev$Item, 
                                   1+prioriter*m.prev$Probability),
                         Value = rep(m.prev$Value, 
                                     1+prioriter*m.prev$Probability))

ggplot(m.prev, aes(x=Value))+
  geom_histogram(binwidth=0.01,aes(y=..count../sum(..count..)))+
  facet_wrap(~Item, scales='free')+
  xlim(0,1)+
  xlab("Prevalence")+
  ylab("Posterior probability")
  


m.prevPrior <- m %>%
  filter(substring(Item,1,11) == 'prevalenceP') %>%
  separate(Item, into=c("a", "Item","Bin"), sep = "_") %>%
  select(-a)

m.prevPrior <- data.frame(Item =  rep(m.prevPrior$Item, 
                                   1+prioriter*m.prevPrior$Probability),
                          Bin =  rep(m.prevPrior$Bin, 
                                   1+prioriter*m.prevPrior$Probability),
                         Value = rep(m.prevPrior$Value, 
                                     1+prioriter*m.prevPrior$Probability))

m.prevPriorStats <- m.prevPrior %>%
  group_by(Item, Bin) %>%
  summarise(expectation = mean(Value),
            credLo = quantile(Value, probs=0.025),
            credHi = quantile(Value, probs=0.975)) %>%
  mutate(Bin = to.n(Bin))


ggplot(m.prevPriorStats, aes(x=Bin,y = expectation, fill=Item))+
  geom_bar(stat='identity', position = position_dodge())+
  geom_errorbar(aes(ymin=credLo, ymax=credHi), position=position_dodge())+
  facet_wrap(~Item)+
  guides(fill=F)



#m<- bind_rows(m,m0)
#m$Probability <- m$Probability/2

m.params<- m %>% filter(Item %in% c("speakerOptimality", "cost", "softmax"))
m.params <- data.frame(Item =  rep(m.params$Item, 
                                   1+samples*m.params$Probability),
                         Value = rep(m.params$Value, 
                                     1+samples*m.params$Probability))
ggplot(m.params, aes(x=Value))+
  geom_histogram(binwidth=0.05,aes(y=..count../sum(..count..)))+
  #facet_wrap(~Item, scales='free')+
  xlim(0,10)+
  xlab("Speaker Optimality")+
  ylab("Posterior probability")

ggsave(file='~/Box Sync/talks/esslli-2015-generics/posterior-rationality-truthJudge.pdf')


quantile(m.params$Value, probs = c(0.025,0.975))
```

#### posterior predictive
```{r}

m.pp<- m %>% filter(!((Item %in% c("speakerOptimality", "cost", "softmax")) |
                        (substring(Item,1,10) == 'prevalence')))
m.pp <- data.frame(Item =  rep(m.pp$Item, 
                                   1+samples*m.pp$Probability),
                         Value = rep(m.pp$Value, 
                                     1+samples*m.pp$Probability))
m.pp.exp<- m.pp %>%
  rename(sentence = Item) %>%
  group_by(sentence) %>%
  summarise(expectation = mean(Value),
            credHi = quantile(Value, probs = 0.975),
            credLo = quantile(Value, probs = 0.025)) %>%
  mutate(sentence = gsub('&quotechar','', sentence),
         sentence = gsub('lyme','Lyme', sentence))


combined.model.data<- left_join(m.pp.exp, m.tidy, by='sentence')

with(combined.model.data, cor(expectation, response))

with(filter(combined.model.data,
            (prev>25 & prev < 75)), cor(expectation, response))

with(filter(combined.model.data,
            (prev > quantile(m.tidy$prev)["25%"] & 
            prev < quantile(m.tidy$prev)["75%"])), cor(expectation,response))




with(combined.model.data, cor(expectation, response, method='spearman'))


with(combined.model.data, cor(prev, response))
with(combined.model.data, cor(prev, response, method='spearman'))


combined.model.data$sentence<-with(combined.model.data, 
                                   reorder(sentence, response, function(x) -x))



qplot(data=combined.model.data,
      x=expectation,y=response,
      color=sentence)+
  geom_point(size=4)+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =1)+
  geom_errorbarh(aes(xmin = credLo, xmax=credHi),
                 position=position_dodge(), size = 1)+
  geom_abline(intercept=0,slope=1,linetype=2, size=1,color='black')+
  xlab("\n model posterior predictive")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed()
#+
#  theme_blackDisplay()
  
#ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-lvrsa.pdf',
#       width=13,height=13)

```

Doing TFBT with speaker optimality (at the S1 level) as a free parameter

```{r}
model.posteriorpred <-read.csv('../cbg2010-replication/models/model_predictions/generics_truthJudge_3_postpred_n100_mh1000.csv',header=F,
                               col.names=c("sentence","posteriorPred"))

model.posteriorpred <-read.csv('~/Documents/research/generics/cbg2010-replication/models/generics_truthJudge_3_rationality1_n100_hashmh100.csv')


combined.model.data<- left_join(m.pp, m.tidy, by='sentence')

with(combined.model.data, cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev>25 & prev < 75)), cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev > quantile(m.tidy$prev)["25%"] & 
            prev < quantile(m.tidy$prev)["75%"])), cor(posteriorPred,response))




with(combined.model.data, cor(posteriorPred, response, method='spearman'))


with(combined.model.data, cor(prev, response))
with(combined.model.data, cor(prev, response, method='spearman'))


combined.model.data$sentence<-with(combined.model.data, reorder(sentence, response, function(x) -x))



qplot(data=combined.model.data,
      x=posteriorPred,y=response,
      color=sentence)+
  geom_point(size=4)+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=1,linetype=2, size=2,color='black')+
  xlab("\n model posterior predictive")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed()
#+
#  theme_blackDisplay()
  
ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-lvrsa.pdf',
       width=13,height=13)

qplot(data=combined.model.data,
      x=prev,y=response,
      color=sentence)+
  geom_point(size=4)+
    geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=0.01,linetype=2, size =2,color='white')+
  xlab("\n (raw) prevalence")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed(ratio=100)+
  theme_blackDisplay()

ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-prevalence.pdf',
       width=13,height=13)

```


```{r}
m<-read.csv('~/Documents/research/generics/cbg2010-replication/models/generics_truthJudge_3_rationality_n100_mh1000.csv', header =F)
samples  = 1000

# f.params0<- data.frame(Parameter = rep(f.tidy$param, 1+samples*f.tidy$Probability),
#                        Response = rep(f.tidy$Value, 1+samples*f.tidy$Probability))
# f.params.tidy<- f.params0 %>%
#   separate(Parameter, by='.', into=c("Item", "Question", "Parameter"))

f.params <- data.frame(Value = rep(m$V1, 1+samples*m$V2))

qplot(data=f.params, x=Value,geom='histogram')

  ```
