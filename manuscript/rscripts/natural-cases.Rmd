---
title: "Generics -- natural cases"
author: "mht"
date: "May 16, 2015"
output: html_document
---



# Prior 2: Prevalence priors for 16 properties


```{r echo=F}
upperFirst <- function(name){
  return (paste(toupper(substr(name, 1, 1)), substr(name, 2, nchar(name)), sep=""))
}

removeS <- function(name.in){
  exceptions = c("Turtles", "Bees", "Horses", "Giraffes","Whales","Beetles","Eagles","Snakes","Moles")
  bluejays =  c("Blue jay","Blue Jay","Bluejay")
  fleas = c("Flea", "Fly")
  name<-removeSpace(name.in)
  last<-substr(name,nchar(name),nchar(name))
  last2<-substr(name,nchar(name)-1,nchar(name))
  if (name%in%exceptions){
    name.singular <- substr(name,1,nchar(name)-1)
  } else if (name%in%bluejays){
    name.singular <- "Bluejay"
  } else if (name%in%fleas){
    name.singular <- "Flea"
  } else if (name=="Wolves") {
    name.singular <- "Wolf"
  } else if (name=='Dolpin') {
    name.singular <- "Dolphin"
  } else if (name=='Giraffs') {
    name.singular <- "Giraffe"
  }  else if (last2=='es') {
    name.singular <- substr(name,1,nchar(name)-2)
  } else if (last=='s') {
    name.singular <- substr(name,1,nchar(name)-1)
  } else {
    name.singular <- name
  }
  
return(name.singular)
}

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

removeSpace <- function(name){
  if (substrRight(name,1)==' ') {
    name.edit <- substr(name,1, nchar(name)-1)
  } else {
    name.edit <- name
  }
  return(name.edit)
}

setwd(dir = '~/Documents/research/generics/analysis/')
generics.of.interest <- data.frame(
  animal=c("Robin","Leopard","Duck","Lion","Mosquito","Shark","Cardinal","Kangaroo","Peacock","Tiger","Tick","Swan"),
  property=c("lay eggs", "have spots","have wings","have manes","carry malaria",
              "attacks swimmers","are red","have pouches","have beautiful feathers","eat people","carry Lyme disease","are white"))

d<-read.csv(file = '../experiments/turk/real-kinds-prior-2/real-kinds-2-trials.csv')
d0<-read.csv(file='../experiments/turk/real-kinds-prior-2/real-kinds-2pilot5/real-kinds-2-trials.csv')

d0$workerid = max(d$workerid) + d0$workerid+1
d<-bind_rows(d,d0)

d[d$property=='are juveline',]$property<-'are juvenile'


# 

d$animal.parsed<- factor(unlist(Map(removeS, upperFirst(as.character(d$animal)))))

```


Resolve differences between coding of prior elicitation and truth judgment task
```{r tj.prior.out}

d.out<-d %>% select(workerid, trial_type, property, prevalence, animal)
d.out[d.out$property == 'attacks swimmers',]$property <- 'attack swimmers'

rexp <- "^(\\w+)\\s?(.*)$"
d.path <- "~/Documents/research/generics/data/real-kinds/"

c <- read.csv(file = paste(d.path,'real-kinds-truth-1-catch_trials.csv', sep=''))

nonenglish<-c(1,4,19,38,39)
catch<-c[c$pass==0,]$workerid

tj <-read.csv(file = paste(d.path,'real-kinds-truth-1-trials.csv',sep=''))
tj <- tj %>% filter(!(workerid %in% c(nonenglish, catch)))

tj<- tj %>% 
  mutate(Category = sub(rexp,"\\1",sentence),
         Property = sub(rexp,"\\2",sentence),
         Property = gsub('&quotechar','',Property),
         Property = gsub('lyme','Lyme',Property)         
         ) %>%
  select(-rt, -sentence) %>%
  mutate(Property = factor(substr(Property,1,nchar(Property)-1)))


d.out <- d.out %>%
  rename(Property = property,
         Category = animal)


tj$negation <- 0
tj[grepl("dont", tj$Property),]$negation <-1

tj$positiveProperty <- gsub("^.*?dont ","",tj$Property)


negations<- c("dont carry Lyme disease", "dont eat people", 
              "dont attack swimmers", "dont carry malaria", 
              "dont have beautiful feathers")

for (n in negations){
  posprop <- gsub("dont ","",n)
  d.temp<-d.out %>%filter (Property == posprop)
  d.temp$Property<-n
  d.temp$prevalence <- 100-d.temp$prevalence
  d.out<-bind_rows(d.temp, d.out)
}




#write.csv(d.out,file='~/Documents/research/generics/models/data/real-kinds-prior-2-trials-formatted.csv', row.names=F)
#write.csv(tj,file='~/Documents/research/generics/models/data/real-kinds-truth-1-trials-formatted.csv',row.names=F)


```




# Response histogram

```{r}
ggplot(d, aes(x=prevalence))+geom_histogram(binwidth=5)+ggtitle('binwidth=5')
```

For each subject:

```{r}
ggplot(d, aes(x=prevalence))+
  geom_histogram(binwidth=5)+
  facet_wrap(~workerid)+
  scale_x_continuous(breaks=c(0, 50, 100))

```


# Animal production data

```{r exp2.newAnimals, fig.height=25, fig.width=16}

# retrieve novel animals (and count only one instance per subject)
animals.produced<-filter(d,
                         (!(animal.parsed %in% generics.of.interest$animal)&
                            (property_index==0)|(property_index==8)))


anim.free<-animals.produced %>%
  group_by(animal.parsed) %>%
  summarise(n = length(animal.parsed))

anim.free<-anim.free[order(anim.free$n,decreasing=T),]
top5<-anim.free %>% filter(animal.parsed %in% c("Dog","Kangaroo",'Elephant',"Giraffe","Bear"))
sum(top5$n)/300


sort(table(animals.produced$animal.parsed))[sort(table(animals.produced$animal.parsed))>10]
levels(factor(d[!(d$animal.parsed%in%generics.of.interest$animal),]$animal.parsed))
# ggplot(animals.produced, aes(x=animal.parsed))+
#   geom_histogram()+
#   #theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   coord_flip()

```

# Prevalence distributions


## Estimates for each animal.

Some of these animals have very few responses, owing to the fact that they were produced by just one or a few subjects. Ordering is alphabetical by animal name. Light blue bars indicate the category of interest for each property (for the generic).

```{r exp2.estimatesByAnimal, fig.height=15, fig.width=36}

d.tidy<- d %>%
  group_by(property,animal.parsed) %>%
  summarise(prev = mean(prevalence),
            sterr=sem(prevalence)) %>%
  filter(!(is.na(sterr)))

generics.of.interest$combined <- paste(generics.of.interest$property, 
                                       generics.of.interest$animal)
d.tidy$combined <- paste(d.tidy$property, d.tidy$animal.parsed)

d.tidy$interest<-d.tidy$combined %in% generics.of.interest$combined

ggplot(data=d.tidy, aes(x=animal.parsed, y=prev, fill=interest))+
  geom_bar(stat='identity',position=position_dodge())+
  facet_wrap(~property)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Reducing this plot to only the animals that were given to subjects

```{r exp2.estimatesByAnimal.reduced, fig.height=10, fig.width=20}

d.tidy.sub <- d.tidy %>% 
  filter(animal.parsed %in% generics.of.interest$animal)
#   group_by(animal.parsed) %>%
#   mutate(count = length(animal.parsed)) %>%
#   filter(count > 10)

ggplot(data=d.tidy.sub, aes(x=animal.parsed, y=prev, fill=interest))+
  geom_bar(stat='identity',position=position_dodge())+
  geom_errorbar(aes(ymin=prev-2*sterr,ymax=prev+2*sterr),
                position=position_dodge(),width=0.5)+
  facet_wrap(~property)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

d.tidy.sub %>%
  filter(combined %in% generics.of.interest$combined)


```


## Distribution by animal

Here, I plot the distribution of prevalence after summarizing an average prevalence for each animal. Hence, a sample from this distribution is an animal category (with an associated prevalence of the property). Again note:: many of these categories have very few responses.

Green line indicates prevalence for target category.
```{r}
ggplot(data=d.tidy, aes(x=prev))+
  geom_vline(data=filter(d.tidy,interest), aes(xintercept=prev),
             colour='#2ca25f',size=1.3)+
  geom_histogram(binwidth=5)+
  facet_wrap(~property)
```

Binned distributions (for model)

```{r}
d.tidy<- d.tidy %>% mutate(roundval=round(prev/10)*10) 

d.anim.bin<- d.tidy %>%
  group_by(property, roundval) %>%
  summarise(count = length(roundval)) %>%
  ungroup() %>% group_by(property) %>%
  mutate(prob = count/sum(count),
         roundval = to.n(roundval))

ggplot(d.anim.bin, aes(x=roundval, y=prob))+
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~property)+
  xlab("prevalence")+
  ylab("proportion of responses\n")+
  #scale_fill_brewer(palette='Pastel1',type='qual')+
 # scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_discrete(breaks=c(0,20,40,60,80,100))+#,limits=c(-5,105))+
 # theme_blackDisplay()+ 
  guides(fill=guide_legend(title="property"))+
#  theme(legend.key.size=unit(2, "lines"),
#        legend.text.align=NULL)+
  guides(fill=F)

d.anim.bin %>% select(-prob) %>% spread(roundval, count)



```



## Distribution by response

Here, I don't include the intermediate step of summarising by animal kind. Instead, I just plot the density directly from subjects' responses. Again, green line indicates prevalence for target categogry.

```{r}

d.interest<-d.tidy %>% filter(interest)

#selection <-c("are female", "have wings", "have manes", "carry malaria")
ggplot(data = filter(d, prevalence > 0), aes(x=prevalence))+
#ggplot(data = filter(d,property%in%selection), aes(x=prevalence))+
  geom_histogram()+
  #geom_density(adjust=0.5, fill='grey')+
  facet_wrap(~property,scales='free')+
  xlim(0,100)

+
 # geom_vline(data=d.interest, aes(xintercept=prev), colour='#2ca25f',size=1.3)
```


Binned distributions (for model)

```{r}
d <- d %>% mutate(roundval=factor(round(prevalence/10)*10))

d.bin<- d %>%
  group_by(property, roundval) %>%
  summarise(count = length(roundval)) %>%
  ungroup() %>% group_by(property) %>%
  mutate(prob = count/sum(count),
         roundval = to.n(roundval))


# Filter out given animals.


#filter(animal.parsed %in% generics.of.interest$animal)

ggplot(d.bin, aes(x=roundval, y=prob))+
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~property)+
  xlab("prevalence")+
  ylab("proportion of responses\n")+
  #scale_fill_brewer(palette='Pastel1',type='qual')+
 # scale_y_continuous(breaks=c(0,0.25,0.5,0.75,1),limits=c(0,1))+
  scale_x_discrete(breaks=c(0,20,40,60,80,100))+#,limits=c(-5,105))+
 # theme_blackDisplay()+ 
  guides(fill=guide_legend(title="property"))+
#  theme(legend.key.size=unit(2, "lines"),
#        legend.text.align=NULL)+
  guides(fill=F)

filter(d, property=='attack swimmers' & prevalence>90)$animal.parsed
```

Looks like "Mosquitos attack swimmers." is probably true.


```{r}
# d.out<-d.bin %>% select(-prob) %>% spread(roundval, count)
# d.out[is.na(d.out)] <- 1 # remove NAs (which are 0s); set to 1 so there is some probability mass...
# write.csv(d.out,file='../cbg2010-replication/models/prevalencePrior_16props.csv')
```


# FBT on natural cases priors

```{r priors2.fbt.prevalence}

samples = 50000
#d<- read.csv(paste('~/Documents/research/generics/models/results/naturalkinds-priors-flatAcross_incrMH',samples,'.csv',sep=''))

fpath<- '~/Documents/research/generics/models/results/'
prefix <- "generics-tj-prevalence_discreteBeta-delta50-phi-incr"
d<- read.csv(paste(fpath, prefix,samples,'a.csv',sep=''))

d <- d %>%
  rename(blank = Parameter,
         Parameter = Negation) %>%
  unite(Pairing, Category, Property)

d.params <- data.frame(Pairing = rep(d$Pairing, 
                                       1+samples*d$Probability),
                       Parameter = rep(d$Parameter, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))


d.phi<-d.params %>% filter(Parameter=='phi')
ggplot(d.phi,
       aes(x=Value))+
  geom_histogram(binwidth=0.01)+
  xlim(0,1)





ggplot(d.params %>% filter(Parameter=='gamma'),
       aes(x=Value))+
  geom_histogram()+
  facet_wrap(~Pairing, scales='free')+
  xlim(0,1)


  
d.param.stats <- d.params %>%
  group_by(Property, Parameter) %>%
  summarise(expval = mean(Value),
            credHigh = quantile(Value, probs= 0.975),
            credLow = quantile(Value, probs = 0.025))


# d.param.stats$Property<-with((d.param.stats %>% 
#                                filter(Parameter == 'gamma_within')), 
#                  reorder(Property, expval, function(x) -x))
# 



ggplot(d.param.stats, aes(x=Property, y=expval, fill=Property))+
  geom_bar(stat='identity')+
  geom_errorbar(aes(ymin = credLow, ymax = credHigh))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,
                                   vjust=1))+
  facet_wrap(~Parameter, scales='free')+
  guides(fill=F)



d.samples<-data.frame()

shape1 = function(gamma,delta){return (gamma * delta)}
shape2= function(gamma,delta){return ((1-gamma) * delta)}

for (i in 1:100){

  d.samp<-d.params %>%
    group_by(Pairing, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alpha = shape1(gamma,delta),
           beta = shape2(gamma, delta))
  
  for (k in 1:length(d.samp$Pairing)){
    d.iter<-data.frame(
               Pairing = d.samp[k,1],
               Prevalence = rbeta(100, d.samp[[k, "alpha"]], 
                                      d.samp[[k, "beta"]]
                                  )
               )
    d.samples<-bind_rows(d.samples, d.iter)
  }
  
  if ((i %% 10)==0) { print(i) }

}

ggplot(d.samples, aes(x=Prevalence))+
  geom_histogram()+
  facet_wrap(~Pairing, scales='free')+
  xlim(0,1)



```


Reconstruct prevalence priors

```{r priors2.fbt.prevalencepriors}
samples = 50000


fpath<- '~/Documents/research/generics/models/results/'
prefix <- "generics-tj-prevalencePrior_discreteBeta-hasFUNIF-delta50-has0-phi-incr"

d<- read.csv(paste(fpath, prefix,samples,'a.csv',sep=''))

d <- d %>%
  select(-Category, -Parameter) %>%
  rename(
         Parameter = Negation)

d.params <- data.frame(Property = rep(d$Property, 
                                       1+samples*d$Probability),
                       Parameter = rep(d$Parameter, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))
d.phi<-d.params %>% filter(Parameter=='phi')
ggplot(d.phi,
       aes(x=Value))+
  geom_histogram(binwidth=0.01)+
  xlim(0,1)


d.samples<-data.frame()

shape1 = function(gamma,delta){return (gamma * delta)}
shape2= function(gamma,delta){return ((1-gamma) * delta)}

d.params<-d.params %>% filter(!(Parameter=='phi'))


for (i in 1:100){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alpha = shape1(gamma_within,delta_within),
           beta = shape2(gamma_within, delta_within)) %>%
    group_by(Property) %>%
    mutate(doesHaveF = rbinom(1,1,prob_hasF)) %>%
    select(-gamma_within, -delta_within)

  
  for (k in 1:length(d.samp$Property)){
    d.iter<-data.frame(
               Pairing = d.samp[k,1],
               
               Prevalence = if (d.samp[[k,"doesHaveF"]]==1){
                                rbeta(10, d.samp[[k, "alpha"]], 
                                          d.samp[[k, "beta"]]
                                    )
                                } else {rep(0,10)}
               )
    d.samples<-bind_rows(d.samples, d.iter)
  }
  
  if ((i %% 10)==0) { print(i) }
}

#target<- c("are female", "lay eggs", "carry malaria", "have wings")
target<- c("are male", "have manes", "carry malaria", "have wings")
#ggplot(d.samples %>% filter(Prevalence!=0), 
ggplot(d.samples %>% filter(Property %in% target), 
          aes(x=Prevalence))+
  #geom_histogram()+
  geom_density(adjust=1, size=1, fill='grey')+
  geom_density(data = d.samples %>% filter((Prevalence!=0) & 
                                           (Property %in% target)&
                                             (Property!="have wings")), 
               aes(x=Prevalence), color='blue', linetype =2)+
  #scale_color_brewer(palette='Dark2')+
  xlab("Prevalence")+
  ylab("Posterior density")+
  theme(legend.position=c(0.7,0.65))+
  guides(color =F)+ 
  facet_wrap(~Property, scales='free')+
  xlim(0,1)

ggsave(file='~/Documents/research/generics/manuscript/figures/prevalence_priors_inferred-betas.pdf')


ggplot(d.samples %>% filter(Prevalence > 0), aes(x=Prevalence))+
  geom_histogram()+
  facet_wrap(~Property, scales='free')+
  xlim(0,1)















# for model with "flat" hasProperty levels
for (i in 1:1000){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alph = shape1(gamma_within,delta_within),
           bet = shape2(gamma_within, delta_within))%>%
    group_by(Property) %>%
    mutate(doesHaveF = rbinom(1,1,hasF)) %>%
   select(-gamma_within, -delta_within) %>%
    group_by(Property) %>%
    mutate(prevalence = if(doesHaveF==0) {0} 
              else {rbeta(1, alph, bet)})
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}


# for model with 2 betas
for (i in 1:1000){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alpha0 = shape1(gamma_across,delta_across),
           beta0 = shape2(gamma_across, delta_across),
           alpha1 = shape1(gamma_within,delta_within),
           beta1 = shape2(gamma_within, delta_within))%>%
    group_by(Property) %>%
    mutate(prevAcross = rbeta(1, alpha0, beta0),
           doesHaveF = rbinom(1,1,prevAcross),
           prevWithin = rbeta(1, alpha1, beta1)) %>%
   select(-ends_with("_within"),
          -ends_with("_across")) %>%
    group_by(Property) %>%
    mutate(prevalence = if(doesHaveF==0) {0} 
              else {prevWithin}) %>%
    select(Property, prevalence)
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}




ggplot(d.samples, aes(x=prevalence))+
  geom_histogram()+
  facet_wrap(~Property)
# 
# d.samples$Item<-factor(d.samples$Item,
#                        levels=c("body_parts",
#                                 "vague_parts",
#                                 "color_parts",
#                                 "common_accidental",
#                                 "rare_accidental"))

# a<-ggplot(d.samples, 
#           aes(x=prevalence, color=Property))+
#   geom_density(size=1.1)+
#   scale_color_brewer(palette='Set1')+
#   xlab("Prevalence")+
#   ylab("Posterior density")+
#   theme(legend.position=c(0.7,0.65))+
#   guides(fill=F)+ facet_wrap(~Property)
# 

ggplot(d.samples %>% filter(prevalence!=0), 
          aes(x=prevalence, color=Property))+
  geom_histogram()+
  #scale_color_brewer(palette='Set1')+
  xlab("Prevalence")+
  ylab("Posterior density")+
  theme(legend.position=c(0.7,0.65))+
  guides(color=F)+ 
  facet_wrap(~Property)

a
```



## Infer prevalence of generic cases

```{r generic.case.prevalence}
samples = 10000
d<- read.csv(paste('~/Documents/research/generics/models/results/naturalkinds-prevalence_incrMH',samples,'.csv',sep=''))


d.exp <- d %>% filter(Parameter == 'expectation')
d.exp.params <- data.frame(Property = rep(d$Property, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))
ggplot(d.exp.params, aes(x=Value))+
  geom_histogram()+
  facet_wrap(~Property)


d <- d %>% filter(!(Parameter == 'expectation'))
d.params <- data.frame(Property = rep(d$Property, 
                                       1+samples*d$Probability),
                       Parameter = rep(d$Parameter, 
                                       1+samples*d$Probability),
                       Value = rep(d$Value, 
                                      1+samples*d$Probability))
  
d.param.stats <- d.params %>%
  group_by(Property, Parameter) %>%
  summarise(expval = mean(Value),
            credHigh = quantile(Value, probs= 0.975),
            credLow = quantile(Value, probs = 0.025))%>%
  filter(Parameter == 'gamma')




d.param.stats$Property<-with(d.param.stats, 
                 reorder(Property, expval, function(x) -x))




ggplot(d.param.stats, aes(x=Property, y=expval, fill=Property))+
  geom_bar(stat='identity')+
  geom_errorbar(aes(ymin = credLow, ymax = credHigh))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,
                                   vjust=1))+
  facet_wrap(~Parameter, scales='free')+
  guides(fill=F)



```

Reconstruct distribution

```{r}
shape1 = function(gamma,delta){return (gamma * delta)}
shape2= function(gamma,delta){return ((1-gamma) * delta)}
d.samples<-data.frame()
  

# for model with "flat" hasProperty levels
for (i in 1:1000){

  d.samp<-d.params %>%
    group_by(Property, Parameter) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Parameter, Value) %>%
    mutate(alph = shape1(gamma,delta),
           bet = shape2(gamma, delta))%>%
    select(-gamma, -delta) %>%
    group_by(Property) %>%
    mutate(prevalence = rbeta(1, alph, bet))
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}

ggplot(d.samples %>% filter(prevalence!=0), 
          aes(x=prevalence, color=Property))+
  geom_histogram()+
  #scale_color_brewer(palette='Set1')+
  xlab("Prevalence")+
  ylab("Posterior density")+
  theme(legend.position=c(0.7,0.65))+
  guides(color=F)+ 
  facet_wrap(~Property)



```



# Truth judgment: Experiment 1






Process for webppl
```{r}
# tj<-read.csv(file = '../experiments/turk/real-kinds-truth-1/real-kinds-truth-1-trials.csv')
# tj$response<-factor(tj$response,levels=c("disagree-key","agree-key"),
#        labels=c("mu","generic is true"))
# tj$sentence <- gsub('&quotechar','', tj$sentence)
# tj$sentence <- gsub('lyme','Lyme', tj$sentence)
# 
# tj.d<-tj%>% select(sentence, response, workerid) %>%
#   spread(workerid, response)
# 
# write.csv(tj.d,'real-kinds-truth-1-trials-n100-webpplfriendly.csv')
```

```{r tj1}

d.path <- "~/Documents/research/generics/data/real-kinds/"
tj <-read.csv(file = paste(d.path,'real-kinds-truth-1-trials.csv',sep=''))
c <- read.csv(file = paste(d.path,'real-kinds-truth-1-catch_trials.csv', sep=''))
s<- read.csv(file = paste(d.path,'real-kinds-truth-1-subject_information.csv', sep=''))
nonenglish<-c(1,4,19,38,39)
catch<-c[c$pass==0,]$workerid

tj <- tj %>% filter(!(workerid %in% c(nonenglish, catch)))

### bootstrap CI
bootstrap.ci <- function(x){
  agr = aggregate(response ~ sentence, data=x, FUN=mean)
  agr$CILow = aggregate(response ~ sentence, data=x, FUN=ci.low)$response
  agr$CIHigh = aggregate(response ~ sentence, data=x, FUN=ci.high)$response
  agr$YMin = agr$response - agr$CILow
  agr$YMax = agr$response + agr$CIHigh
  return(agr)
}


tj.bs<-bootstrap.ci(tj %>% mutate(response = as.numeric(response=='agree-key')))

tj.bs$sentence <- gsub('&quotechar','', tj.bs$sentence)
tj.bs$sentence <- gsub('lyme','Lyme', tj.bs$sentence)

tj.bs$sentence<-with(tj.bs, reorder(sentence, response, function(x) x))


ggplot(data=tj.bs, aes(x=sentence, y=response-0.5))+
  geom_bar(stat='identity',position=position_dodge(), alpha=0.8,
           fill='grey19')+
  geom_errorbar(aes(ymin=YMin-0.5,ymax=YMax-0.5), width=0.5, size = 1.5,
                color='black')+
  #theme_blackDisplay()+
  #theme(axis.text.x = element_text(angle = 45, hjust = 1,
   #                                vjust=1))+
 # ylim(-.5,0.5)+
  xlab("")+
  ylab("\n proportion of subjects who agree")+
  scale_y_continuous(breaks=c(-0.5,0,0.5),labels=c("0","0.5","1"))+
  coord_flip()

# ggsave(file='~/Box Sync/talks/esslli-2015-generics/truhtjudge_n100.pdf',
#        width=24,height=20)
```



### logisitic regression for the obvious
```{r}


sentence.class<- data.frame(sentence = levels(tj$sentence),
                            class = c("t","t","t","f","i",'t','f','i','t','f','i','t','f','f','t','i',
                                      'f','t','i','t','f','f','i','i','t','t','f','f','t','f'))

tj.s<-left_join(tj, sentence.class, by='sentence')
tj.s$class<-factor(tj.s$class,levels=c('i','t','f'))

rs0<-glmer(data=tj.s, response~ -1 + class + (1  | workerid), family='binomial')
summary(rs0)
```


The 30 generic sentences fell into 3 categories as predicted: definitely true, definitely false, and neither true nor false (Figure \red{fig:tj1b}). We entered participants' agreement judgments into a mixed-effect logistic regression with random by-participant effects of intercept. This \emph{a priori} distinction was a significant predictor of the eventual truth judgments: true generics were significantly more likely to be agreed with than the indeterminate generics ($\beta = 3.14; SE = 0.15; z = -20.9$) and false generics were significantly less likely to be agreed with than the indeterminate generics ($\beta = -2.07; SE = 0.15; z = -14.1$). Rather interesting, indeterminate generics were agreed with \emph{less} likely than chance ($\beta = -0.49; SE = 0.09; z = -5.3$).




Boring renaming of properties, and getting prior estimations for negations by subtracting positive form from 100

Scatterplot of raw prevalence vs. proportion of "agree" responses

```{r}

d.tidy.sub[d.tidy.sub$property == 'attacks swimmers',]$property <- 'attack swimmers'
d.tidy.sub$sentence <- with(d.tidy.sub, 
                            paste(paste(animal.parsed,'s',sep=''), 
                                  paste(property,'.',sep='')))

m.tidy<-left_join(tj.bs,d.tidy.sub, by="sentence")

m.tidy[m.tidy$sentence=='Mosquitos dont carry malaria.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Mosquitos carry malaria.',]$prev

m.tidy[m.tidy$sentence=='Sharks dont attack swimmers.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Sharks attack swimmers.',]$prev

m.tidy[m.tidy$sentence=='Peacocks dont have beautiful feathers.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Peacocks have beautiful feathers.',]$prev

m.tidy[m.tidy$sentence=='Ticks dont carry Lyme disease.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Ticks carry Lyme disease.',]$prev

m.tidy[m.tidy$sentence=='Tigers dont eat people.',]$prev<-100-
  m.tidy[m.tidy$sentence=='Tigers eat people.',]$prev

m.tidy<-m.tidy %>%
  filter(!is.na(prev))

ggplot(m.tidy,aes(x=prev,y=response))+
  geom_point()

with(m.tidy, cor(prev,response))

quantile(m.tidy$prev)

with(filter(m.tidy,(prev > quantile(m.tidy$prev)["25%"] & 
                      prev < quantile(m.tidy$prev)["75%"])), cor(prev,response))
range(filter(m.tidy,(prev > quantile(m.tidy$prev)["25%"] & 
                      prev < quantile(m.tidy$prev)["75%"]))$prev)

```


Truth judgments for these generic sentences were correlated with the prevalence of the property for the target category elicited in Expt.~1a ($r = 0.73$, Figure \ref{fig:scatterprev}). This is, of course, expected given that high-prevalence true generics (e.g. ``Leopards have spots.'') and low-prevalence false generics (e.g. ``Leopards have wings.'') were used. 
However, large deviations from a purely within-category prevalence account remain: Generics with intermediate prevalences (Prevalence quartiles 2 and 3: $ 22\% < prevalence < 62\%$), exhibited no correlation with truth judgments (r_{Q2,3} = -0.08).


## lvRSA model predictions


Inference over prevalence of category-property pairs
###
```{r infer.prevalence}
m.path<-"~/Documents/research/generics/models/results/"

samples = 5000
previter = 5000
prioriter = 5000
prefix<-'generics-tj-so-phi-sequential-discretePriorConditioning-gammaPrevalence-previter' 
m<-read.csv(paste(m.path,
                  prefix, 
                  previter,
                  '_prevprioriter',
                  prioriter,
                  '_mh',
                  samples, '.csv', sep=''))
str(m)


m <- data.frame(Parameter =  rep(m$Parameter, 
                                   1+samples*m$Probability),
                Property =  rep(m$Property, 
                                   1+samples*m$Probability),
                Category =  rep(m$Category, 
                                   1+samples*m$Probability),
                Negation =  rep(m$Negation, 
                                   1+samples*m$Probability),
                Value = rep(m$Value, 
                                   1+samples*m$Probability))


m.phi <- m %>% filter(Parameter=='phi')

ggplot(m.phi, aes(x=Value))+
  geom_histogram()+
  xlim(0,1)

m1 <- m %>% filter(Negation=='gamma')
m1 <- m %>% filter(Negation=='delta')
m1 <- m %>% filter(Negation=='beta')


m %>% filter(Negation == 'gamma') %>%
  group_by(Property, Category) %>%
  summarise(expectation = mean(Value),
            med = median(Value),
            credLow = quantile(Value, probs=0.025),
            credHigh= quantile(Value, probs = 0.975))


m.prev<- m1 %>%
  unite(Pairing, Property, Category) 

ggplot(m.prev, aes(x=Value))+
  #geom_histogram(binwidth=0.01,aes(y=..count../sum(..count..)))+
  geom_histogram(aes(y=..count../sum(..count..)))+
  facet_wrap(~Pairing, scales='free')+
  xlim(0,1)+
  xlab("Prevalence")+
  ylab("Posterior probability")



### discretize and write to file: inferred prevalence
h = data.frame()
bins = c(0, 0.01,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ,0.99, 1)
for (i in levels(factor(m.prev$Pairing))){
  h<-bind_rows(h,
  data.frame(Pairing = i,
               b = bins[1:12],
            h0 = hist(filter(m.prev, Pairing == i)$Value, breaks = bins, 
                      plot=F)$density))
  print(i)
}
h<-h %>% separate(Pairing, into = c("Property", "Category"), sep = "_")  
write.csv(h, file = '~/Documents/research/generics/models/data/inferredPrevalence_betas.csv', row.names = F)




ggsave(file='~/Documents/research/generics/models/results/plots/prevalence-deltass-naturalKinds.pdf',
       width=17,height=13)


# m.prevPrior <- m %>%
#   filter(Parameter== 'prevalencePrior') %>%
#   unite(Pairing, Property, Category) %>%
#   group_by(Pairing, Negation) %>%
#   summarise(expectation = mean(Value),
#             credLo = quantile(Value, probs=0.025),
#             credHi = quantile(Value, probs=0.975)) %>%
#   mutate(Bin = to.n(Negation))
# 
# 
# 
# ggplot(m.prevPrior, aes(x=Bin,y = expectation, fill=Pairing))+
#   geom_bar(stat='identity', position = position_dodge())+
#   geom_errorbar(aes(ymin=credLo, ymax=credHi), position=position_dodge())+
#   facet_wrap(~Pairing)+
#   guides(fill=F)
```



```{r infer.prevalencePriors}
m.path<-"~/Documents/research/generics/models/results/"

samples = 50000
m<-read.csv(paste(m.path,
                  #'generics-tj-prevalencePrior-incr', 
                  #'generics-tj-prevalencePrior_hasFUNIF-has0-incr', 
                  'generics-tj-prevalencePrior_discreteBeta-hasFUNIF-delta50-has0-postpred-incr', 
                  samples, 'a.csv', sep=''))


m <- data.frame(Parameter =  rep(m$Parameter, 
                                   1+samples*m$Probability),
                Property =  rep(m$Property, 
                                   1+samples*m$Probability),
                Category =  rep(m$Category, 
                                   1+samples*m$Probability),
                Negation =  rep(m$Negation, 
                                   1+samples*m$Probability),
                Value = rep(m$Value, 
                                   1+samples*m$Probability))
str(m)

  
m.hasF <- m %>% filter(Negation=='prob_hasF')
ggplot(m.hasF, aes(x=Value))+
  geom_histogram()+
  facet_wrap(~Property)

ggsave(file='~/Documents/research/generics/models/results/plots/prevalencePriors-hasF-naturalKinds.pdf',
       width=17,height=13)


m.gamma <- m %>% filter(Negation=='gamma_within')
ggplot(m.gamma, aes(x=Value))+
  geom_histogram(binwidth=0.01)+
  facet_wrap(~Property)

ggsave(file='~/Documents/research/generics/models/results/plots/prevalencePriors-gammas-naturalKinds.pdf',
       width=17,height=13)


m.delta <- m %>% filter(Negation=='delta_within')
ggplot(m.delta, aes(x=Value))+
  geom_histogram()+
  facet_wrap(~Property)

ggsave(file='~/Documents/research/generics/models/results/plots/prevalencePriors-deltas-naturalKinds.pdf',
       width=17,height=13)




m.beta <- m %>% filter(Negation=='beta')
ggplot(m.beta, aes(x=Value))+
  geom_histogram(binwidth=0.02)+
  facet_wrap(~Property)

ggsave(file='~/Documents/research/generics/models/results/plots/prevalencePriors-postpredBetas-naturalKinds.pdf',
       width=17,height=13)




m.prevPrior <- m %>%
  filter(Negation== 'posteriorPredictive') %>%
  group_by(Property, Category) %>%
  summarise(expectation = mean(Value),
            credLo = quantile(Value, probs=0.025),
            credHi = quantile(Value, probs=0.975)) %>%
  mutate(Bin = to.n(Category))


ggplot(m.prevPrior %>% filter(Bin > 0), aes(x=Bin,y = expectation, fill=Property))+
  geom_bar(stat='identity', position = position_dodge())+
  geom_errorbar(aes(ymin=credLo, ymax=credHi), position=position_dodge())+
  facet_wrap(~Property)+
  guides(fill=F)




```

reconstruct priors
```{r reconstruct.frominferred}
d.samples<-data.frame()

shape1 = function(gamma,delta){return (gamma * delta)}
shape2= function(gamma,delta){return ((1-gamma) * delta)}


m.sansHyper <- m %>% filter((Negation =='prob_hasF') | 
                              (Negation=='beta'))

# for model with "flat" hasProperty levels
for (i in 1:10000){

#   d.samp<-m %>%
#     group_by(Property, Negation) %>%
#     sample_n(1) %>%
#     ungroup() %>%
#     spread(Negation, Value) %>%
#     mutate(alph = shape1(gamma_within,delta_within),
#            bet = shape2(gamma_within, delta_within))%>%
#     group_by(Property) %>%
#     mutate(doesHaveF = rbinom(1,1,prob_hasF)) %>%
#    select(-gamma_within, -delta_within) %     >%
#     group_by(Property) %>%
#     mutate(prevalence = if(doesHaveF==0) {0} 
#               else {rbeta(1, alph, bet)})
  d.samp<-m.sansHyper %>%
    group_by(Property, Negation) %>%
    sample_n(1) %>%
    ungroup() %>%
    spread(Negation, Value) %>%
#     mutate(alph = shape1(gamma_within,delta_within),
#            bet = shape2(gamma_within, delta_within))%>%
    group_by(Property) %>%
    mutate(doesHaveF = rbinom(1,1,prob_hasF)) %>%
  # select(-gamma_within, -delta_within) %>%
  #  group_by(Property) %>%
    mutate(prevalence = if(doesHaveF==0) {0} 
              else {beta})
  
  d.samples<-bind_rows(d.samples, d.samp)
  if ((i %% 100)==0) { print(i) }
}

target<- c("are male", "have manes", "carry malaria", "have wings")
# ggplot(d.samples %>% filter(prevalence!=0), 
ggplot(d.samples %>% filter(Property %in% target), 
          aes(x=prevalence))+
  geom_histogram()+
  #geom_density(adjust=1, size=1, fill='grey')+
  #scale_color_brewer(palette='Dark2')+
  xlab("Prevalence")+
  ylab("Posterior density")+
  theme(legend.position=c(0.7,0.65))+
  guides(color =F)+ 
  facet_wrap(~Property, scales='free')+
  xlim(0,1)


ggsave(file='~/Documents/research/generics/manuscript/figures/prevalence_priors_inferred-gammas.pdf')




### discretize and write to file: inferred prevalence priors
prevprior = data.frame()
bins = c(0, 0.01,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ,0.99, 1)
for (i in levels(d.samples$Property)){
  prevprior<-bind_rows(prevprior,
  data.frame(Property = i,
               b = bins[1:12],
            h0 = hist(filter(d.samples, Property == i)$prevalence, 
                      breaks = bins, 
                      plot=F)$density))
  print(i)
}

ggplot(prevprior %>% filter(b > 0), aes(x= b, y = h0, fill = Property)) +
  geom_bar(stat='identity', position=position_dodge())+
  facet_wrap(~Property, scales='free')+
  guides(fill=F)

write.csv(h, file = '~/Documents/research/generics/models/data/inferredPrevalence_betas.csv', row.names = F)


```


#### posterior over parameters

```{r fullBayesian.postparams}


estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
HPDhi<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
HPDlo<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}




m.path<-"~/Documents/research/generics/models/results/"
#m<-read.csv(paste(m.path, 'generics_truthJudge_rationality-n100_hashmh10000a.csv', sep=''))

# samples=10000
# prioriter<-10000
# #prefix<-paste('fullBayesian-wPrev-so-priorhash',prioriter,'_hashmh',samples,sep='')
# prefix<-paste('fullBayesian-samplePrevfromBeta-so-incrmh',samples,sep='')
# prefix<-paste('fullBayesian-so-priorhash',prioriter,'_hashmh',samples,sep='')
# prefix<-paste('fullBayesian-samplePrev-so-priorhash',prioriter,'_hashmh',samples,sep='')
# prefix<-paste('test_incrmh',samples,sep='')
# prefix<-paste('test_incrmh100000',sep='')
# prefix<-paste('sequential-prevalenceGamma-priors',prioriter,'_mh',samples,sep='')
# 
# prefix<- paste('fullBayesian-prevGamma-so-incrmh',samples, sep='')
# prefix<-paste('sequential-discretePriorConditioning-gammaPrevalence-priors', prioriter, '_mh', samples, sep='')
# 
# m<-read.csv(paste(m.path, 'generics-tj-',prefix, '.csv', sep=''))

samples =10000
previter = 50000
prioriter = 50000
prefix<-'generics-tj-so-phi20-sequential-discretePriorConditioning-gammaPrevalence-explicitNegation-previter' 
m<-read.csv(paste(m.path,
                  prefix, 
                  previter,
                  '_prevprioriter',
                  prioriter,
                  '_mh',
                  samples, '0a.csv', sep=''))
str(m)


m <- data.frame(Parameter =  rep(m$Parameter, 
                                   1+samples*m$Probability),
                Property =  rep(m$Property, 
                                   1+samples*m$Probability),
                Category =  rep(m$Category, 
                                   1+samples*m$Probability),
                Negation =  rep(m$Negation, 
                                   1+samples*m$Probability),
                Value = rep(m$Value, 
                                   1+samples*m$Probability))


# m.phi <- m %>% filter(Parameter=='phi')
# 
# ggplot(m.phi, aes(x=Value))+
#   geom_histogram()+
#   xlim(0,1)





m.prev <- m %>% 
  filter(Parameter == 'prevalence') %>%
  mutate(Negation = gsub(1," dont ", Negation),
         Negation = gsub(0," ", Negation)) %>%
  unite(Property1, Category, Negation, Property,sep='') %>%
  rename(Item = Property1)

ggplot(m.prev, aes(x=Value))+
  geom_histogram(binwidth=0.01,aes(y=..count../sum(..count..)))+
  facet_wrap(~Item, scales='free')+
  xlim(0,1)+
  xlab("Prevalence")+
  ylab("Posterior probability")
  


# m.prevPrior <- m %>%
#   filter(substring(Item,1,11) == 'prevalenceP') %>%
#   separate(Item, into=c("a", "Item","Bin"), sep = "_") %>%
#   select(-a)

m.prevPrior <- m %>%
  filter(Parameter== 'prevalencePrior') %>%
  group_by(Property, Category) %>%
  summarise(expectation = mean(Value),
            credLo = quantile(Value, probs=0.025),
            credHi = quantile(Value, probs=0.975)) %>%
  mutate(Bin = to.n(Category))
# m.prevPrior <- data.frame(Item =  rep(m.prevPrior$Item, 
#                                    1+prioriter*m.prevPrior$Probability),
#                           Bin =  rep(m.prevPrior$Bin, 
#                                    1+prioriter*m.prevPrior$Probability),
#                          Value = rep(m.prevPrior$Value, 
#                                      1+prioriter*m.prevPrior$Probability))

# m.prevPriorStats <- m.prevPrior %>%
#   group_by(Item, Bin) %>%
#   summarise(expectation = mean(Value),
#             credLo = quantile(Value, probs=0.025),
#             credHi = quantile(Value, probs=0.975)) %>%
#   mutate(Bin = to.n(Bin))


ggplot(m.prevPrior, aes(x=Bin,y = expectation, fill=Property))+
  geom_bar(stat='identity', position = position_dodge())+
  geom_errorbar(aes(ymin=credLo, ymax=credHi), position=position_dodge())+
  facet_wrap(~Property, scales='free')+
  guides(fill=F)



#m<- bind_rows(m,m0)
#m$Probability <- m$Probability/2

m.params<- m %>% filter(Parameter 
                        %in% c("speakerOptimality", "cost", "softmax","phi")
                        )
# m.params <- data.frame(Item =  rep(m.params$Item, 
#                                    1+samples*m.params$Probability),
#                          Value = rep(m.params$Value, 
#                                      1+samples*m.params$Probability))
ggplot(m.params, aes(x=Value))+
  #geom_histogram(aes(y=..count../sum(..count..)))+
  geom_density(adjust=2)+
  facet_wrap(~Parameter, scales='free')+
  #xlim(0,10)+
  xlab("Speaker Optimality")+
  ylab("Posterior probability")


m.params %>% 
  group_by(Parameter) %>%
  summarise(postMode = estimate_mode(Value),
            credHi = HPDhi(Value),
            credLo = HPDlo(Value))

#ggsave(file='~/Box Sync/talks/esslli-2015-generics/posterior-rationality-truthJudge.pdf')


quantile(m.params$Value, probs = c(0.025,0.975))
```

#### posterior predictive
```{r fullBayesian.pp}
  
m.pp<- m %>% filter(!((Parameter %in% 
                         c("speakerOptimality", "cost", "softmax", 'gamma',
                           'delta', "phi")) |
                        (substring(Parameter,1,10) == 'prevalence'))) %>%
    mutate(Negation = gsub(1," dont ", Negation),
         Negation = gsub(0," ", Negation)) %>%
    unite(sentence, Category, Negation, Property,sep='') %>%
  filter(Parameter == 'generic_linked')

# 
# m.pp <- data.frame(Item =  rep(m.pp$Item, 
#                                    1+samples*m.pp$Probability),
#                          Value = rep(m.pp$Value, 
#                                      1+samples*m.pp$Probability))

d.robmal<-m.pp %>% filter(sentence == 'Robins carry malaria')



estimate_mode(d.robmal$Value)

estimate_mode(s)



m.pp.exp<- m.pp %>%
  #rename(sentence = Item) %>%
  group_by(sentence) %>%
  summarise(expectation = mean(Value),
            posMode = estimate_mode(Value),
            credHi = HPDhi(Value),
            credLo = HPDlo(Value)) %>%
  mutate(sentence = paste(sentence, '.', sep=''))

# %>%
#   mutate(sentence = gsub('&quotechar','', sentence),
#          sentence = gsub('lyme','Lyme', sentence))


combined.model.data<- left_join(m.pp.exp, m.tidy, by='sentence')

with(combined.model.data, cor(posMode, response))

with(filter(combined.model.data,
            (prev>25 & prev < 75)), cor(posMode, response))

with(filter(combined.model.data,
            (prev > quantile(m.tidy$prev)["25%"] & 
            prev < quantile(m.tidy$prev)["75%"])), cor(posMode,response))




with(combined.model.data, cor(posMode, response, method='spearman'))


with(combined.model.data, cor(prev, response))
with(combined.model.data, cor(prev, response, method='spearman'))


combined.model.data$sentence<-with(combined.model.data, 
                                   reorder(sentence, response, function(x) -x))



qplot(data=combined.model.data,
      x=posMode,y=response,
      color=sentence)+
  geom_point(size=4)+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =1)+
  geom_errorbarh(aes(xmin = credLo, xmax=credHi),
                 position=position_dodge(), size = 1)+
  geom_abline(intercept=0,slope=1,linetype=2, size=1,color='black')+
  xlab("\n model posterior predictive")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  xlim(-0.05,1.05)+
  ylim(-0.05,1.05)+
  coord_fixed()


combined.model.data<- combined.model.data %>%
  mutate(dev = abs(expectation-response))
#+
#  theme_blackDisplay()
ggsave(file='~/Documents/research/generics/manuscript/figures/tj_n100_tjVsPostpred_95hdi.pdf', width=10, height=5)
# ,
# ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-lvrsa.pdf',
#       width=13,height=13)

```

Doing TFBT with speaker optimality (at the S1 level) as a free parameter

```{r}
model.posteriorpred <-read.csv('../cbg2010-replication/models/model_predictions/generics_truthJudge_3_postpred_n100_mh1000.csv',header=F,
                               col.names=c("sentence","posteriorPred"))

model.posteriorpred <-read.csv('~/Documents/research/generics/cbg2010-replication/models/generics_truthJudge_3_rationality1_n100_hashmh100.csv')


combined.model.data<- left_join(m.pp, m.tidy, by='sentence')

with(combined.model.data, cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev>25 & prev < 75)), cor(posteriorPred, response))

with(filter(combined.model.data,
            (prev > quantile(m.tidy$prev)["25%"] & 
            prev < quantile(m.tidy$prev)["75%"])), cor(posteriorPred,response))




with(combined.model.data, cor(posteriorPred, response, method='spearman'))


with(combined.model.data, cor(prev, response))
with(combined.model.data, cor(prev, response, method='spearman'))


combined.model.data$sentence<-with(combined.model.data, reorder(sentence, response, function(x) -x))



qplot(data=combined.model.data,
      x=posteriorPred,y=response,
      color=sentence)+
  geom_point(size=4)+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=1,linetype=2, size=2,color='black')+
  xlab("\n model posterior predictive")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed()
#+
#  theme_blackDisplay()
  
ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-lvrsa.pdf',
       width=13,height=13)

qplot(data=combined.model.data,
      x=prev,y=response,
      color=sentence)+
  geom_point(size=4)+
    geom_errorbar(aes(ymin=YMin, ymax=YMax),
                position=position_dodge(), size =2)+
  geom_abline(intercept=0,slope=0.01,linetype=2, size =2,color='white')+
  xlab("\n (raw) prevalence")+
  ylab("proportion of agree's \n")+
  guides(color=F)+
  coord_fixed(ratio=100)+
  theme_blackDisplay()

ggsave(file='~/Box Sync/talks/esslli-2015-generics/scatter-prevalence.pdf',
       width=13,height=13)

```


```{r}
m<-read.csv('~/Documents/research/generics/cbg2010-replication/models/generics_truthJudge_3_rationality_n100_mh1000.csv', header =F)
samples  = 1000

# f.params0<- data.frame(Parameter = rep(f.tidy$param, 1+samples*f.tidy$Probability),
#                        Response = rep(f.tidy$Value, 1+samples*f.tidy$Probability))
# f.params.tidy<- f.params0 %>%
#   separate(Parameter, by='.', into=c("Item", "Question", "Parameter"))

f.params <- data.frame(Value = rep(m$V1, 1+samples*m$V2))

qplot(data=f.params, x=Value,geom='histogram')

  ```
