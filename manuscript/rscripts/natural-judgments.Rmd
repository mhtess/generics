---
title: "Truth judgments of common generics"
author: "Michael Henry Tessler"
date: "August 16, 2015"
output: html_document
---

```{r helpers}
library(coda)
library(hydroGOF)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
HPDhi<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
HPDlo<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}



bootstrap.ci <- function(x){
  agr = aggregate(response ~ sentence, data=x, FUN=mean)
  agr$CILow = aggregate(response ~ sentence, data=x, FUN=ci.low)$response
  agr$CIHigh = aggregate(response ~ sentence, data=x, FUN=ci.high)$response
  agr$YMin = agr$response - agr$CILow
  agr$YMax = agr$response + agr$CIHigh
  return(agr)
}

```

# Human judgments

```{r human.data}
d.path <- "~/Documents/research/generics/data/real-kinds/"
tj <-read.csv(file = paste(d.path,'real-kinds-truth-1-trials.csv',sep=''))
# catch trials
c <- read.csv(file = paste(d.path,'real-kinds-truth-1-catch_trials.csv', sep=''))
# to find native language
s<- read.csv(file = 
               paste(d.path,'real-kinds-truth-1-subject_information.csv', sep=''))

# excluding the nonenglish native speakers has no effect on results
#nonenglish<-c(1,4,19,38,39)
catch<-c[c$pass==0,]$workerid

#tj <- tj %>% filter(!(workerid %in% c(nonenglish, catch)))
tj <- tj %>% filter(!(workerid %in% catch))

#tj<- read.csv("~/Documents/research/generics/manuscript/data/naturalGenerics-trials-minusCatch-n96-formatted.csv")

### bootstrap CI

tj.bs<-bootstrap.ci(tj %>% 
                      mutate(response = as.numeric(response=='agree-key')))


# adjust naming of sentence to correspond to that used in the prior data
tj.bs$sentence <- gsub('&quotechar','', tj.bs$sentence)
tj.bs$sentence <- gsub('lyme','Lyme', tj.bs$sentence)
tj.bs$sentence<-with(tj.bs, reorder(sentence, response, function(x) x))


ggplot(data=tj.bs, aes(x=sentence, y=response-0.5))+
  geom_bar(stat='identity',position=position_dodge(), alpha=0.8,
           fill='grey19')+
  geom_errorbar(aes(ymin=YMin-0.5,ymax=YMax-0.5), width=0.5, size = 1.5,
                color='black')+
  xlab("")+
  ylab("\n proportion of participants who agree")+
  scale_y_continuous(breaks=c(-0.5,0,0.5),labels=c("0","0.5","1"))+
  coord_flip()

```


## Manipulation check

Do true generics get endorsed more?
```{r manipulation.check}

# MHT's truth judgments of sentences
sentence.class<- data.frame(sentence = levels(tj$sentence),
                            class = c("t","t","t","f","i",'t',
                                      'f','i','t','f','i','t',
                                      'f','f','t','i','f','t',
                                      'i','t','f','f','i','i',
                                      't','t','f','f','t','f'))

tj.s<-left_join(tj, sentence.class, by='sentence')
tj.s$class<-factor(tj.s$class,levels=c('i','t','f'))

rs0<-glmer(data=tj.s, response~ -1 + class + (1  | workerid), family='binomial')
summary(rs0)
```


The 30 generic sentences fell into 3 categories as predicted: definitely true, definitely false, and neither true nor false (Figure \red{fig:tj1b}). We entered participants' agreement judgments into a mixed-effect logistic regression with random by-participant effects of intercept. This \emph{a priori} distinction was a significant predictor of the eventual truth judgments: true generics were significantly more likely to be agreed with than the indeterminate generics ($\beta = 3.14; SE = 0.15; z = -20.9$) and false generics were significantly less likely to be agreed with than the indeterminate generics ($\beta = -2.07; SE = 0.15; z = -14.1$). Rather interesting, indeterminate generics were agreed with \emph{less} likely than chance ($\beta = -0.49; SE = 0.09; z = -5.3$).



## Within-kind prevalence predict truth judgment?



```{r truthJudge.vs.prevalence}

# Load prevalence data
m.path<-"~/Documents/research/generics/manuscript/model-results/"

samples = 50000
prefix<-'generics-naturalPrevalence-n57-incrMH100000_burn50000' 
m1<-read.csv(paste(m.path, prefix, 'a.csv', sep=''))
m2<-read.csv(paste(m.path, prefix, 'b.csv', sep=''))
m3<-read.csv(paste(m.path, prefix, 'c.csv', sep=''))

m<-bind_rows(m1,m2,m3)

str(m)

m <- data.frame(Parameter =  rep(m$Parameter, 
                                   1+samples*m$Probability),
                Property =  rep(m$Property, 
                                   1+samples*m$Probability),
                Category =  rep(m$Category, 
                                   1+samples*m$Probability),
                Negation =  rep(m$Negation, 
                                   1+samples*m$Probability),
                Value = rep(m$Value, 
                                   1+samples*m$Probability))


m.summary<- m %>% filter(Negation == 'gamma') %>%
  group_by(Property, Category) %>%
  summarise(#expectation = mean(Value),
            #med = median(Value),
            map = estimate_mode(Value),
            credLow =HPDlo(Value),
            credHigh= HPDhi(Value)) %>%
  unite(sentence, Category, Property, sep =' ') %>%
  mutate(sentence = paste(sentence, '.', sep=''))




tj.wPrev<-left_join(tj.bs %>% select(-CILow, -CIHigh), 
                    m.summary %>% rename(prev = map, 
                                         prevHigh = credHigh,
                                         prevLow = credLow), by = "sentence")

with(tj.wPrev, cor(response,prev))^2
with(tj.wPrev, mse(response,prev))


qplot(data=tj.wPrev,
      x=prev,y=response,
      color=prev)+
  geom_abline(intercept=0,slope=1,linetype=2, size=1,color='grey39')+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                size =1, position=position_dodge(),
                subset = .(prev >=0.5))+
  geom_errorbarh(aes(xmin = prevLow, xmax=prevHigh),
                  size = 1,
                 subset = .(prev >=0.5))+
  geom_point(size=4, subset = .(prev >=0.5))+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                size =1,  position=position_dodge(),
                 subset = .(prev <0.5))+
  geom_errorbarh(aes(xmin = prevLow, xmax=prevHigh),
                size = 1,  position=position_dodge(),
                 subset = .(prev <0.5))+
  geom_point(size=4,  subset = .(prev <0.5))+
  xlab("\n Within-kind prevalence")+
  ylab("Human judgment \n")+
#  guides()+
  xlim(-0.05,1.05)+
  ylim(-0.05,1.05)+
  coord_fixed()+
  #scale_color_gradient(low='#386cb0', high = '#f0027f')+
  scale_color_gradient(low='black', high ='#addd8e', limits=c(0,1),
                       breaks=c(0,0.5,1))+
  theme(legend.title = element_text(hjust=0))



#ggsave(file='~/Documents/research/generics/manuscript/figures/tj_n100_tjVsPrevalence_95hdi-colorPrev.pdf', width=12, height=6)


#write.csv(tj.wPrev,
#          file='~/Documents/research/generics/manuscript/model-results/natural-judgments-means.csv')


with(tj.wPrev, cor(prev, response))^2
with(tj.wPrev, mse(prev, response))

with(filter(tj.wPrev,
            (prev > quantile(tj.wPrev$prev)["25%"] & 
            prev < quantile(tj.wPrev$prev)["75%"])), 
     cor(prev,response))^2


with(filter(tj.wPrev,
            (prev > quantile(tj.wPrev$prev)["25%"] & 
            prev < quantile(tj.wPrev$prev)["75%"])), 
     mse(prev,response))

with(tj.wPrev, cor(prev, response, method='spearman'))


```




# Pragmatics model predictions

## Posterior over parameters

```{r posterior.parameters}


m.path<-"~/Documents/research/generics/manuscript/model-results/"
samples =50000
previter = 50000
prioriter = 50000


m1<-read.csv(paste(m.path,"generics-truthJudgment-previter50000_prevprioriter50000-priord50Zero-n57_mh100000_burn50000a.csv",sep=''))
m2<-read.csv(paste(m.path,"generics-truthJudgment-previter50000_prevprioriter50000-priord50Zero-n57_mh100000_burn50000b.csv",sep=''))
m3<-read.csv(paste(m.path,"generics-truthJudgment-previter50000_prevprioriter50000-priord50Zero-n57_mh100000_burn50000c.csv",sep=''))

m<- bind_rows(m1,m2,m3)

m <- data.frame(Parameter =  rep(m$Parameter, 
                                   1+samples*m$Probability),
                Property =  rep(m$Property, 
                                   1+samples*m$Probability),
                Category =  rep(m$Category, 
                                   1+samples*m$Probability),
                Negation =  rep(m$Negation, 
                                   1+samples*m$Probability),
                Value = rep(m$Value, 
                                   1+samples*m$Probability))


m.params<- m %>% filter(Parameter 
                        %in% c("speakerOptimality", "cost", "softmax","phi")
                        )

ggplot(m.params %>% filter(Parameter=='speakerOptimality'), aes(x=Value))+
  geom_histogram(aes(y=..count../sum(..count..)), binwidth = 0.4)+
  #geom_density()+
  #facet_wrap(~Parameter, scales='free')+
  #xlim(0,10)+
  xlim(0,20)+
  xlab(expression(lambda))+
  ylab("Posterior probability")

#ggsave(file="~/Documents/research/generics/manuscript/figures/naturalGenerics-speakerOptimality.pdf", width = 8, height =4)


m.params %>% 
  group_by(Parameter) %>%
  summarise(postMode = estimate_mode(Value),
            credHi = HPDhi(Value),
            credLo = HPDlo(Value))

ggplot(m.params, aes(x=Value))+
  geom_histogram(aes(y=..count../sum(..count..)))+
  #geom_density()+
  facet_wrap(~Parameter, scales='free')+
  #xlim(0,10)+
  #xlim(0,20)+
  #xlab(expression(lambda))+
  ylab("Posterior probability")

#ggsave(file='~/Box Sync/talks/esslli-2015-generics/posterior-rationality-truthJudge.pdf')

```

## Posterior predictives

```{r posterior.predictive.scatter}
  
m.pp<- m %>% filter(!((Parameter %in% 
                         c("speakerOptimality", "cost", "softmax", 'gamma',
                           'delta', "phi")) |
                        (substring(Parameter,1,10) == 'prevalence'))) %>%
    mutate(Negation = gsub(1," dont ", Negation),
         Negation = gsub(0," ", Negation)) %>%
    unite(sentence, Category, Negation, Property,sep='') %>%
  filter(Parameter == 'generic_linked')




m.pp.exp<- m.pp %>%
  group_by(sentence) %>%
  summarise(expectation = mean(Value),
            posMode = estimate_mode(Value),
            credHi = HPDhi(Value),
            credLo = HPDlo(Value)) %>%
  mutate(sentence = paste(sentence, '.', sep=''))


combined.model.data<- left_join(m.pp.exp, tj.wPrev, by='sentence')
combined.model.data$sentence<-with(combined.model.data, 
                                   reorder(sentence, response, function(x) -x))


combined.model.data <- combined.model.data %>%
  rename(Prevalence = prev)

qplot(data=combined.model.data,
      x=posMode,y=response,
      fill=Prevalence)+
  geom_abline(intercept=0,slope=1,linetype=2, size=1,color='grey39')+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                size =1, width=.01,  position=position_dodge(),
                subset = .(Prevalence >=0.5))+
  geom_errorbarh(aes(xmin = credLo, xmax=credHi),
                  size = 1, height=.01, 
                 subset = .(Prevalence >=0.5))+
  geom_point(shape=21,size=4, subset = .(Prevalence >=0.5))+
  geom_errorbar(aes(ymin=YMin, ymax=YMax),
                size =1,  width=.01,  position=position_dodge(),
                 subset = .(Prevalence <0.5))+
  geom_errorbarh(aes(xmin = credLo, xmax=credHi),
                size = 1, height=.01, position=position_dodge(),
                 subset = .(Prevalence <0.5))+
  geom_point(shape=21,size=4,  subset = .(Prevalence <0.5))+
  xlab("\n Model posterior predictive")+
  ylab("Human endorsement \n")+
#  guides()+
  xlim(-0.05,1.05)+
  ylim(-0.05,1.05)+
  coord_fixed()+
  #scale_color_gradient(low='#386cb0', high = '#f0027f')+
  scale_fill_gradient(
                       #high='#92c5de', 
                       high = "#fed976",
                       low = "#023858",
                       #low = "#4d9221",
                       #high = "#f1b6da",
                       #high = "black",
                       #low = "white",
                       #high ='#e78ac3',
                       limits=c(0,1),
                       breaks=c(0,0.5,1)
                       )+
  theme(legend.title = element_text(hjust=0))

#ggsave(file='~/Documents/research/generics/manuscript/figures/tj_n96-postpred-colorPrev7.pdf', width=12, height=6)

with(combined.model.data, cor(posMode, response))^2

with(combined.model.data, mse(posMode, response))

with(filter(combined.model.data,
            (Prevalence > quantile(combined.model.data$Prevalence)["25%"] & 
            Prevalence < quantile(combined.model.data$Prevalence)["75%"])), 
     cor(posMode,response))^2

with(filter(combined.model.data,
            (Prevalence > quantile(combined.model.data$Prevalence)["25%"] & 
            Prevalence < quantile(combined.model.data$Prevalence)["75%"])), 
     mse(posMode,response))

with(combined.model.data, cor(posMode, response, method='spearman'))



```


Bar plots

```{r posterior.predictive.barplot}
cmd.tidy <- 
  bind_rows(
    combined.model.data %>% gather(src, value, posMode, response) %>%
          filter(src=='posMode') %>%
          select(sentence, credHi, credLo, src, value),
    combined.model.data %>% gather(src, value, posMode, response) %>%
          filter(src=='response') %>%
          select(sentence, YMin, YMax, src, value) %>%
          rename(credHi = YMax,
                 credLo = YMin))

cmd.tidy <- left_join (cmd.tidy, combined.model.data %>% select(sentence, Prevalence))

cmd.tidy$sentence<-with(cmd.tidy %>% filter(src=='posMode'), 
                        reorder(sentence, Prevalence, function(x) x))

cmd.tidy<- cmd.tidy %>% rename(
  Source = src
  ) %>%
  mutate(Source = factor(Source, levels = c("response", 
                                            "posMode"),
                         labels = c("Human judgments",
                                    "Model predictions")))

ggplot(data=cmd.tidy, aes(x=sentence, y=value-0.5, 
                          fill = Source))+
  geom_bar(stat='identity',
           aes(x=sentence),
           position=position_dodge(1), width=1,
           color='black')+
  geom_errorbar(aes(x=sentence, fill = Source,
                    ymin=credLo-0.5,ymax=credHi-0.5), width=0.5, size = 1,
                color='black',
                position=position_dodge(1))+
  scale_fill_brewer(palette=3, type='qual')+
  xlab("")+
  ylab("Endorsement")+
  scale_y_continuous(breaks=c(-0.5,0,0.5),labels=c("0","0.5","1"))+
  coord_flip()

#ggsave(file="~/Documents/research/generics/manuscript/figures/tj_n100-postPred-byItem.pdf", width = 11, height = 7)


```
