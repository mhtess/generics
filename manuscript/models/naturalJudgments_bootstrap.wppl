// time ~/webppl-infer/webppl naturalJudgments.wppl --require mht --require webppl-json --require naturalUtils

var start_index = mht.wpParseFloat(last(process.argv)) // load index as last command line index
var priors = json.read("../../models/data/realkinds-priors-n57-bootstrapped-1000.json")

var bootstrapIndices = RandomInteger({n:1000})

var Truthdata = mht.readCSV("../../models/data/real-kinds-truth-1-trials-formatted.csv").data
var df_truth0 = dataFrame(Truthdata.slice(0, Truthdata.length - 1), ["negation"] )

var responseDictionary = {
	"agree-key":1,
	"disagree-key":0
}

var df_truth = map(function(d){ 
	return _.extend(d, {"binaryResponse": responseDictionary[d.response]})
},df_truth0)

var properties = _.uniq(_.pluck(df_truth,"Property"))

var prevalenceERPobject = _.object(map(function(p){
	var categories = _.uniq(_.pluck(subset(df_truth, "Property", p), "Category"))
	return [p, _.object(map(function(k){
			var fpath = "../../models/prevalence_results/prevalence_"+p+"_"+k+".csv"
			var df = readQueryERP(fpath)
			return [k, df]
		}, categories))]
},properties))

var guessingLink = function(myERP, phi){
	Infer({method: "enumerate"}, function(){
		var x = flip(1-phi) ? 
					sample(myERP) :
					uniformDraw([1,0])
		return x
	})
}


var makeModel = function(bootstrap_index){

	var s1_optimality = sample(UniformDrift({a:0,b:20,r:2}))
	var s2_optimality = sample(UniformDrift({a:0,b:5,r:0.5}))
	var cost = 1
	// var phi = uniform(0,1)
	var phi = 0.00001

	var bs_prior = subset(priors, "i", bootstrap_index)
	// var p = "are red" 


	foreach(properties,
		function(p){

			var propertyData = subset(df_truth, "Property", p)
			var categories = _.uniq(_.pluck(propertyData, "Category"))

			var property_prior = subset(bs_prior, "Property", p)
			var prior = Categorical({
				vs: map(function(x){return mht.wpParseFloat(x)}, _.pluck(property_prior,"bin")),
				ps: _.pluck(property_prior, "n")})

			foreach(categories,
				function(k){
					var categoryData = subset(propertyData, "Category", k)
					
					var prevalencePropCat = prevalenceERPobject[p][k]
					var pfk = sample(prevalencePropCat).Prevalence

					var responseData = _.pluck(categoryData, "binaryResponse")

			     	// console.log(mht.isNumeric(sample(prior)))

			     	var predictionERP = speaker2(pfk, 
			     		prior, s1_optimality, s2_optimality)

			     	//note, there must be at least a tiny amount of noise, otherwise for the items with 0 prevalence, the model crashes
			     	var linkedERP = guessingLink(predictionERP, phi)

					var scr = sum(map(function(d) {
								    return linkedERP.score(d)
										}, responseData))
					// console.log(p + k + scr)
					factor(scr)

					query.add(["generic",p, k, "0"], expectation(linkedERP) )

				})

		})
	query.add(["s1_optimality","na","na","na"], s1_optimality)
	query.add(["s2_optimality","na","na","na"], s2_optimality)
	return query
}

var mhiter = 10000
var burn = mhiter/2

foreach(_.range(start_index, start_index + 10), function(bootstrap_index){
	console.log("starting index = " + start_index)
	var tfbt = Infer({method: "incrementalMH", samples: mhiter, burn: burn}, 
		function(){return makeModel(bootstrap_index)})
	var header = "Parameter,Property,Category,Extra,Value"
	var outfile = '../model-results/bootstrap/generics-tj-bootstrapPrior-so1-so2-_IncrMH'+ mhiter+'_burn'+burn+'_i'+bootstrap_index+'.csv'
	mht.erpWriter(tfbt, outfile, header)
	console.log('wrote to... ' + outfile )
})





// console.log('doing the full bayesian dance...')
// var tfbt = IncrementalMH(modelAnalysis,mhiter, {"verbose":true,
// 												"burnin":burn,
// 												verboseLag:mhiter/50}
// 												)
// console.log('FBT complete')


