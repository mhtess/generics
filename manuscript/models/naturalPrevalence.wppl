// time webppl naturalPrevalence.wppl --require naturalUtils

var fpath = "/Users/mht/Documents/research/generics/manuscript/data/"
var Priordata = naturalUtils.readCSV(fpath+"naturalGenerics-prior-trials-n57.csv").data
var Truthdata = naturalUtils.readCSV(fpath+"naturalGenerics-trials-minusCatch-n96-formatted.csv").data

// babyparse adds an extra line at the end.
var df_prior = dataFrame(Priordata.slice(0,Priordata.length-1))
var df_truth = dataFrame(Truthdata.slice(0,Truthdata.length-1))


var df_prior_avoidEnds = map(function(x){
	return _.extend(x, {alignedResponse : avoidEnds(x.prevalence/100)})
}, df_prior)


var properties = _.uniq(_.pluck(df_prior,"Property"))

var guessing = 1/bins.length;

var prevalenceModel = function(){

	// var phi = uniform(0,1)
	var phi = 0 

	foreach(properties, function(p){

		var propertyData = subset(df_prior_avoidEnds, "Property", p)
		var categories = _.uniq(_.pluck(subset(df_truth, "Property", p), "Category"))
		// console.log(propertyData)

		foreach(categories, function(k){
			// console.log(k,p)
			var categoryData = _.pluck(subset(propertyData, "Category", k), "alignedResponse")
			var g = uniform(0,1)
			var d = uniform(0,50)

			// pseudocount parameterization
			var a = shape_alpha(g,d)
			var b = shape_beta(g,d)

			//////////
			// some models requite discretization. this is to make sure no substantial differences result.
			//////////
			// var discreteBetaProbs = discretizeBeta(g, d)
			// var discreteBetaProbsNormalized = map(function(x){return x/sum(discreteBetaProbs)}, discreteBetaProbs)
			// var scr = reduce(function(d, memo) {
			// 					var x = Math.log(
			// 							(phi*guessing) + 
			// 							((1-phi) * 
			// 								betaERP.score([g,d])
			// 								discreteBetaProbsNormalized[bins.indexOf(alignPrevalence(d))])
			// 							)
			// 				    return memo + x
			// 					}, 0, categoryData)

			var scr = sum(map(function(di){
				return betaERP.score([a,b], di)
			}, categoryData))

			// console.log(scr)

			factor(scr)

			// for linking with truthJudgments.wppl
			// query.add([k,p], avoidEnds(Math.round(gamma*10)/10))
			// for just doing inference over the prevalence 
			query.add(["prevalence",p, k, "gamma"], g)
			query.add(["prevalence",p, k, "delta"], d)
		})
	})
	
	// for just doing inference over the prevalence 
	// query.add(["prevalence","na", "na", "phi"], phi)
	return query
	// return phi
}

// for just doing inference 
var mhiter = 1000
var burn = mhiter/2
// var resultsERP = IncrementalMH(prevalenceModel, mhiter, {verbose:"true",
// 														burn: burn,
// 														verboseLag: 100})

var steps = 5
var stepSize = 0.0019

var resultsERP = MCMC(prevalenceModel, {
	kernel: {HMC: {
		steps: steps,
		stepSize: stepSize
	}},
	verbose:"true",
	samples: mhiter,
	burn: burn
})

// resultsERP
// var outfile = '../model-results/generics-naturalPrevalence-continuousFactoring-n57-HMC'+mhiter+'_burn'+burn+'.csv'
var outfile = '../model-results/generics-naturalPrevalence-continuousFactoring-n57-HMC'+
	mhiter+'_burn'+burn+'_step'+steps+'stepSize'+stepSize+'.csv'
// var outfile = '../model-results/generics-naturalPrevalence-continuousFactoring-n57-incrMH'+mhiter+'_burn'+burn+'.csv'
naturalUtils.erpWriter(resultsERP, outfile)
console.log('wrote to... ' + outfile)
// resultsERP

