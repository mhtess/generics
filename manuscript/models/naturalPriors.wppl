// time webppl naturalPriors.wppl --require naturalUtils

var priorModel = function(){

	// var phi = uniform(0,1)
	var phi = 0

	foreach(properties, function(p){

		var propertyData = subset(df_prior, "Property", p)
		var responseData = _.pluck(propertyData, "prevalence")

		var prob_hasF = beta(1,1)

		var scr1 = reduce(function(d, memo) {
							// console.log(d)
						    return memo + bernoulliERP.score([prob_hasF], d!=0)
							}, 0, responseData)
		factor(scr1)

		// for just doing inference over the priors 
		query.add(["prevalencePrior",p,"na","prob_hasF"], prob_hasF)

		var gamma = uniform(0,1)
		var delta = uniform(0,50)

		var discreteBetaProbs = discretizeBeta(gamma, delta)
		var discreteBetaProbsNormalized = map(function(x){return x/sum(discreteBetaProbs)}, discreteBetaProbs)

		var scr2 = reduce(function(d, memo) {
							var x = d==0? 0 :  
								Math.log(
									(phi*guessing) + 
									((1-phi) * discreteBetaProbsNormalized[bins.indexOf(alignPrevalence(d))])
									)
						    return memo + x
							}, 0, responseData)

		factor(scr2)
		
		// for linking with truthJudgments.wppl
		// var discretized_prevalence = discretizedPriorModel(prob_hasF, gamma, delta)
		// query.add(p, discretized_prevalence)
		// for just doing inference over the priors 
		query.add(["prevalencePrior",p,"na","gamma"], gamma)
		query.add(["prevalencePrior",p,"na","delta"], delta)

	})
	
	// query.add(["prevalencePrior","na","na","phi"], phi)
	return query
}

// for just doing inference 
var mhiter = 100000
var burn = mhiter/2
var resultsERP = IncrementalMH(priorModel, mhiter, {verbose:"true", burnin: burn})
var outfile = '../model-results/generics-naturalPriors-n57-incrMH'+mhiter+'_burn'+burn+'c.csv'
naturalUtils.erpWriter(resultsERP, outfile)
console.log('wrote to... ' + outfile)

// df_prior
// properties.length
// var p = properties[2]
// var propertyData = subset(df_prior, "Property", p)
// var responseData = _.pluck(propertyData, "prevalence")
// responseData.length